#! /usr/bin/env python3

import argparse
import atexit
import cmd
import csv
import glob
import inspect
import json
import os
import re
import readline
import subprocess
import sys
import textwrap
import traceback
from contextlib import suppress
from typing import Any, Dict, List, Union

from senzing import (
    SzConfigManager,
    SzDiagnostic,
    SzEngine,
    SzEngineFlags,
    SzError,
    SzProduct,
)

from _tool_helpers import Colors, get_engine_config

try:
    from prettytable import ALL as PRETTY_TABLE_ALL
    from prettytable import SINGLE_BORDER, PrettyTable
except ImportError:
    print("\nPlease install the Python prettytable module (e.g. pip install prettytable)")
    sys.exit(1)


class Node(object):

    def __init__(self, node_id):
        self.node_id = node_id
        self.node_desc = node_id
        self.node_text = None
        self.node_data = None
        self.children = []
        self.parents = []

    def add_child(self, obj):
        self.children.append(obj)

    def add_parent(self, obj):
        self.parents.append(obj)

    def render_tree(self, filter_str=None):
        tree = ""
        tree += self.node_desc + "\n"
        if self.node_text:
            tree += self.node_text + "\n"
        parents = [{"node": self, "next_child": 0, "display_children": self.children}]
        while parents:
            if parents[-1]["next_child"] == len(parents[-1]["display_children"]):
                parents.pop()
                continue

            next_node = parents[-1]["display_children"][parents[-1]["next_child"]]
            parents[-1]["next_child"] += 1
            prefix = ""
            for i, _ in enumerate(parents):
                last_child = parents[i]["next_child"] == len(parents[i]["display_children"])
                if i < len(parents) - 1:  # prior level
                    prefix += "    " if last_child else "\u2502   "
                else:
                    prefix += "\u2514\u2500\u2500 " if last_child else "\u251c\u2500\u2500 "

            node_desc = next_node.node_desc
            for line in node_desc.split("\n"):
                tree += prefix + line + "\n"
                if prefix[-4:] == "\u251c\u2500\u2500 ":
                    prefix = prefix[0:-4] + "\u2502   "
                elif prefix[-4:] == "\u2514\u2500\u2500 ":
                    prefix = prefix[0:-4] + "    "

            if next_node.node_text:
                node_text = next_node.node_text
                for line in node_text.split("\n"):
                    tree += prefix + line + "\n"

            if next_node.children:
                prior_parents = []
                for i, _ in enumerate(parents):
                    prior_parents.append(parents[i]["node"].node_id)
                # don't display prior parents in this tree
                display_children = []
                for child in next_node.children:
                    if child.node_id not in prior_parents:
                        display_children.append(child)
                parents.append({"node": next_node, "next_child": 0, "display_children": display_children})

        return tree


class sz_pretty_sdk:
    def __init__(self, config_file_name, debug_trace, show_api_reponse):
        self.show_api_reponse = show_api_reponse
        try:
            sz_api_config = get_engine_config(config_file_name)
            sz_config_mgr = SzConfigManager("sz_explorer_c", sz_api_config, False)
            sz_config_data = json.loads(sz_config_mgr.get_config(sz_config_mgr.get_default_config_id()))
            self.sz_engine = SzEngine("sz_explorer", sz_api_config, debug_trace)
            self.sz_diagnostic = SzDiagnostic("sz_explorer_d", sz_api_config, debug_trace)
        except SzError as err:
            raise Exception(err)

        self.dsrc_lookup = {item["DSRC_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_DSRC"]}
        self.dsrc_code_lookup = {item["DSRC_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_DSRC"]}
        self.errule_lookup = {item["ERRULE_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_ERRULE"]}
        self.errule_code_lookup = {item["ERRULE_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_ERRULE"]}
        self.ftype_lookup = {item["FTYPE_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_FTYPE"]}
        self.ftype_code_lookup = {item["FTYPE_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_FTYPE"]}
        self.felem_code_lookup = {item["FELEM_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_FELEM"]}
        self.cfunc_lookup = {item["CFUNC_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_CFUNC"]}
        self.errule_code_lookup["DISCLOSED"] = {"ERRULE_ID": 0}

        # supplement feature code lookup with attribute details
        for item in sz_config_data["G2_CONFIG"]["CFG_ATTR"]:
            if item.get("FTYPE_CODE"):
                self.ftype_code_lookup[item["FTYPE_CODE"]]["ATTR_CLASS"] = item["ATTR_CLASS"]
                if "ATTRIBUTES" not in self.ftype_code_lookup[item["FTYPE_CODE"]]:
                    self.ftype_code_lookup[item["FTYPE_CODE"]]["ATTRIBUTES"] = {}
                self.ftype_code_lookup[item["FTYPE_CODE"]]["ATTRIBUTES"][item["FELEM_CODE"]] = item

        # supplement feature code lookup with scoring code
        for item in sorted(sz_config_data["G2_CONFIG"]["CFG_CFCALL"], key=lambda k: k["FTYPE_ID"]):
            ftype_code = self.ftype_lookup[item["FTYPE_ID"]]["FTYPE_CODE"]
            cfunc_code = self.cfunc_lookup[item["CFUNC_ID"]]["CFUNC_CODE"]
            self.ftype_code_lookup[ftype_code]["CFUNC_CODE"] = cfunc_code

        # supplement feature code lookup with sort order (scored features first)
        for ftype_code in self.ftype_code_lookup:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            if self.ftype_code_lookup[ftype_code].get("CFUNC_CODE"):
                self.ftype_code_lookup[ftype_code]["SORT_ORDER"] = 10000 + ftype_id
            else:
                self.ftype_code_lookup[ftype_code]["SORT_ORDER"] = 20000 + ftype_id

        self.ambiguous_ftype_id = self.ftype_code_lookup["AMBIGUOUS_ENTITY"]["FTYPE_ID"]
        self.ftype_code_lookup["AMBIGUOUS_ENTITY"]["SORT_ORDER"] = 1

        self.ftype_id_order = {}
        self.ftype_code_order = {}
        for ftype_code in self.ftype_code_lookup:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            sort_order = self.ftype_code_lookup[ftype_code]["SORT_ORDER"]
            self.ftype_id_order[ftype_id] = sort_order
            self.ftype_code_order[ftype_code] = sort_order

        self.match_category_sort = {
            "MATCH": 1,
            "AMBIGUOUS_MATCH": 2,
            "POSSIBLE_MATCH": 3,
            "POSSIBLY_RELATED": 4,
            "DISCLOSED_RELATION": 5,
        }
        self.match_category_desc = {
            "MATCH": "Resolved match",
            "AMBIGUOUS_MATCH": "Ambiguous match",
            "POSSIBLE_MATCH": "Possible match",
            "POSSIBLY_RELATED": "Possibly related",
            "DISCLOSED_RELATION": "Disclosed relation",
        }

    def get_api_version(self):
        sz_product = SzProduct()
        return json.loads(sz_product.get_version())

    def call_sdk(
        self,
        api_name: str,
        flags: List[str],
        parms: Union[List[Union[str, int]], int, str],
    ) -> Dict[str, Any]:
        """# TODO"""
        parms = parms if isinstance(parms, list) else [parms]
        # TODO - Ant - Replace others too
        caller = inspect.stack()[1].function

        try:
            flags_int = SzEngineFlags.combine_flags(flags)
            parms.append(flags_int)
        except SzError as err:
            raise SzError(f"{caller}: {api_name} - {err}") from None

        # TODO - Ant -
        # api_called = f"{api_name}({', '.join(str(x) for x in parm_list)})"

        try:
            api_call = getattr(self.sz_engine, api_name)
            response = api_call(*parms)
            response_data: Dict[str, Any] = json.loads(response)
        except AttributeError:
            raise SzError(f"{caller}: {api_name} not available in") from None
        except SzError as err:
            raise SzError(f"{caller}: {api_name} - {err}") from None

        if self.show_api_reponse:
            print(f"{caller}\n{api_name}\n\t{'/n/t'.join(flags)}\n{json.dumps(response_data, indent=4)}")

        return response_data

    # -------------------
    # sdk reformatters
    # -------------------

    def get_entity_features(self, feature_data):
        features_by_id = {}
        features_by_type = {}
        for ftype_code in feature_data:
            features_by_type[ftype_code] = []
            feat_config = self.ftype_code_lookup[ftype_code]
            for distinct_feat_record in feature_data[ftype_code]:
                distinct_usage_type = distinct_feat_record.get("USAGE_TYPE", "")
                for feat_record in distinct_feat_record["FEAT_DESC_VALUES"]:
                    feat_record["FTYPE_CODE"] = ftype_code
                    feat_record["USAGE_TYPE"] = feat_record.get("USAGE_TYPE", distinct_usage_type)
                    if feat_record["USAGE_TYPE"] == "PRIMARY":
                        feat_record["USAGE_TYPE_SORT"] = "1-PRIMARY"
                    elif feat_record["USAGE_TYPE"]:
                        feat_record["USAGE_TYPE_SORT"] = f"2-{feat_record['USAGE_TYPE']}"
                    else:
                        feat_record["USAGE_TYPE_SORT"] = "3-UNSPECIFIED"
                    features_by_type[ftype_code].append(feat_record)
                    lib_feat_id = feat_record["LIB_FEAT_ID"]
                    if lib_feat_id in features_by_id:  # may be a different usage type
                        usage_type1 = features_by_id.get("USAGE_TYPE", "")
                        usage_type2 = feat_record.get("USAGE_TYPE", "")
                        if usage_type2 and usage_type2 != usage_type1:
                            delim = ", " if usage_type1 else ""
                            features_by_id[lib_feat_id]["USAGE_TYPE"] += delim + usage_type2
                    else:
                        features_by_id[lib_feat_id] = feat_record
        return {"BY_ID": features_by_id, "BY_TYPE": features_by_type}

    def get_record_features(self, entity_features, feature_list):
        features_by_id = {}
        features_by_type = {}
        for feat_record in feature_list:
            lib_feat_id = feat_record["LIB_FEAT_ID"]
            if lib_feat_id in entity_features:
                feature_data = entity_features[lib_feat_id].copy()
                feature_data["USAGE_TYPE"] = feat_record.get("USAGE_TYPE", "")
                if feature_data["USAGE_TYPE"] == "PRIMARY":
                    feature_data["USAGE_TYPE_SORT"] = "1-PRIMARY"
                elif feature_data["USAGE_TYPE"]:
                    feature_data["USAGE_TYPE_SORT"] = f"2-{feature_data['USAGE_TYPE']}"
                else:
                    feature_data["USAGE_TYPE_SORT"] = "3-UNSPECIFIED"
                ftype_code = feature_data["FTYPE_CODE"]
                if ftype_code not in features_by_type:
                    features_by_type[ftype_code] = [feature_data]
                else:
                    features_by_type[ftype_code].append(feature_data)
                if lib_feat_id in features_by_id:  # may be a different usage type
                    usage_type1 = features_by_id.get("USAGE_TYPE", "")
                    usage_type2 = feature_data.get("USAGE_TYPE", "")
                    if usage_type2 and usage_type2 != usage_type1:
                        delim = ", " if usage_type1 else ""
                        features_by_id[lib_feat_id]["USAGE_TYPE"] += delim + usage_type2
                else:
                    features_by_id[lib_feat_id] = feature_data
        return {"BY_ID": features_by_id, "BY_TYPE": features_by_type}

    def regroup_by_type(self, features_by_id):
        features_by_type = {}
        for lib_feat_id in features_by_id:
            ftype_code = features_by_id[lib_feat_id]["FTYPE_CODE"]
            if ftype_code not in features_by_type:
                features_by_type[ftype_code] = [features_by_id[lib_feat_id]]
            else:
                features_by_type[ftype_code].append(features_by_id[lib_feat_id])
        return features_by_type

    def get_unmapped_list(self, unmapped_data):
        if not unmapped_data:
            return []
        else:
            return [{k: v} for k, v in unmapped_data.items()]

    def get_related_entities(self, related_entities):
        relation_list = []
        relations_by_id = {}
        for related_entity in related_entities:
            if related_entity["IS_DISCLOSED"] != 0:
                match_category = "DISCLOSED_RELATION"
            elif related_entity["IS_AMBIGUOUS"] != 0:
                match_category = "AMBIGUOUS_MATCH"
            elif related_entity["MATCH_LEVEL_CODE"] == "POSSIBLY_SAME":
                match_category = "POSSIBLE_MATCH"
            else:
                match_category = "POSSIBLY_RELATED"
            related_id = related_entity["ENTITY_ID"]
            relation = {
                "ENTITY_ID": related_id,
                "ENTITY_NAME": related_entity.get("ENTITY_NAME", "unknown"),
                "MATCH_LEVEL_CODE": related_entity["MATCH_LEVEL_CODE"],
                "MATCH_CATEGORY": match_category,
                "MATCH_CATEGORY_SORT": self.match_category_sort[match_category],
                "MATCH_KEY": related_entity["MATCH_KEY"],
                "ERRULE_CODE": related_entity["ERRULE_CODE"],
                "ERRULE_ID": self.errule_code_lookup[related_entity["ERRULE_CODE"]]["ERRULE_ID"],
                "RECORD_SUMMARY": related_entity.get("RECORD_SUMMARY", []),  # wont have on getNetwork
            }
            relation_list.append(relation)
            relations_by_id[related_id] = relation
        relation_list = sorted(relation_list, key=lambda k: k["MATCH_CATEGORY_SORT"])

        return {"LIST": relation_list, "BY_ID": relations_by_id}

    def get_resolved_entities(self, entity_list):
        entities = {}
        for entity in entity_list:
            entity_id = entity["RESOLVED_ENTITY"]["ENTITY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity["RESOLVED_ENTITY"]["ENTITY_NAME"],
                "RECORD_SUMMARY": entity["RESOLVED_ENTITY"]["RECORD_SUMMARY"],
                "RELATIONSHIPS": self.get_related_entities(entity["RELATED_ENTITIES"])["LIST"],
            }
        return entities

    def get_why_key(self, match_info):
        if "MATCH_KEY" in match_info:
            return match_info
        why_key = {
            "MATCH_KEY": match_info["WHY_KEY"],
            "ERRULE_CODE": match_info["WHY_ERRULE_CODE"],
            "ERRULE_ID": self.errule_code_lookup[match_info["WHY_ERRULE_CODE"]]["ERRULE_ID"],
            "ANY_CANDIDATES": len(match_info["CANDIDATE_KEYS"]),
        }
        return why_key

    def get_why_scores(self, match_info):
        scores_by_id = {}
        for ftype_code in match_info.get("CANDIDATE_KEYS", {}):
            for score_record in match_info["CANDIDATE_KEYS"][ftype_code]:
                lib_feat_id = score_record["FEAT_ID"]
                scores_by_id[lib_feat_id] = {"WAS_CANDIDATE": True, "MATCH_SCORE": 100}
        for ftype_code in match_info["FEATURE_SCORES"]:
            all_scores = match_info["FEATURE_SCORES"][ftype_code]
            best_score = sorted(all_scores, key=lambda x: x["SCORE"])[-1]
            scores_by_id[best_score["INBOUND_FEAT_ID"]] = {
                "MATCHED_FEAT_ID": best_score["CANDIDATE_FEAT_ID"],
                "MATCHED_FEAT_DESC": best_score["CANDIDATE_FEAT_DESC"],
                "MATCH_SCORE": best_score["SCORE"],
                "ALL_SCORES": best_score["ADDITIONAL_SCORES"],
                "SCORE_BUCKET": best_score["SCORE_BUCKET"],
                "SCORE_BEHAVIOR": best_score["SCORE_BEHAVIOR"],
            }
            scores_by_id[best_score["CANDIDATE_FEAT_ID"]] = {
                "MATCHED_FEAT_ID": best_score["INBOUND_FEAT_ID"],
                "MATCHED_FEAT_DESC": best_score["INBOUND_FEAT_DESC"],
                "MATCH_SCORE": best_score["SCORE"],
                "ALL_SCORES": best_score["ADDITIONAL_SCORES"],
                "SCORE_BUCKET": best_score["SCORE_BUCKET"],
                "SCORE_BEHAVIOR": best_score["SCORE_BEHAVIOR"],
            }

        return scores_by_id

    def combine_json(self, records):
        search_json = {}
        for record in records:
            if not search_json:
                search_json = record["JSON_DATA"]
            else:
                root_attributes = {}
                for root_attribute in record["JSON_DATA"]:
                    if not isinstance(record["JSON_DATA"][root_attribute], list):
                        root_attributes[root_attribute] = record["JSON_DATA"][root_attribute]
                    else:
                        if root_attribute not in search_json:
                            search_json[root_attribute] = []
                        for sub_record in record["JSON_DATA"][root_attribute]:
                            search_json[root_attribute].append(sub_record)
                if root_attributes:
                    if "ROOT_ATTRIBUTES" not in search_json:
                        search_json["ROOT_ATTRIBUTES"] = []
                    search_json["ROOT_ATTRIBUTES"].append(root_attributes)

        return search_json

    # ---------------------------
    def get_how_data(self, how_data, entity_data):
        entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
        entity_records = entity_data["RESOLVED_ENTITY"]["RECORDS"]

        how_steps = how_data["HOW_RESULTS"]["RESOLUTION_STEPS"]
        result_key = {}
        steps = {}
        for step in how_steps:
            step_num = step["STEP"]
            result_id = step["RESULT_VIRTUAL_ENTITY_ID"]
            result_key[result_id] = step_num
            entity_list = []
            for ve_num in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]:
                record_list = []
                features = {}
                for member_record in step[ve_num]["MEMBER_RECORDS"]:
                    for record in member_record["RECORDS"]:
                        record_list.append(record)
                        data_source = record["DATA_SOURCE"]
                        record_id = record["RECORD_ID"]
                        entity_record = next(
                            x for x in entity_records if x["DATA_SOURCE"] == data_source and x["RECORD_ID"] == record_id
                        )
                        features.update(self.get_record_features(entity_features, entity_record["FEATURES"])["BY_ID"])
                entity_list.append(
                    {
                        "VIRTUAL_ID": step[ve_num]["VIRTUAL_ENTITY_ID"],
                        "MEMBER_COUNT": len(step[ve_num]["MEMBER_RECORDS"]),
                        "RECORDS": record_list,
                        "FEATURES": features,
                    }
                )
            entity_list = sorted(entity_list, key=lambda k: k["MEMBER_COUNT"])
            if entity_list[0]["MEMBER_COUNT"] + entity_list[1]["MEMBER_COUNT"] == 2:
                step_type = "Create virtual entity"
            elif entity_list[0]["MEMBER_COUNT"] > 1:
                step_type = "Combine virtual entities"
            else:
                step_type = "Add record to virtual entity"
            steps[step_num] = {
                "STEP_TYPE": step_type,
                "ENTITY_LIST": entity_list,
                "MATCH_INFO": step["MATCH_INFO"],
                "RESULT_ID": result_id,
            }

        final_entities = how_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]
        if how_data["HOW_RESULTS"]["FINAL_STATE"]["NEED_REEVALUATION"]:
            reevaluation_msg = f"Needs reevaluation: resulted in {len(final_entities)} entities!"
        else:
            reevaluation_msg = ""

        # start from the end and combine the prior steps that just add another singleton
        root_node = Node("root")
        # root_node.node_desc = self.fmt_entity_desc(entities[root_entity_id])
        parent_nodes = []
        for final_entity in final_entities:
            final_id = final_entity["VIRTUAL_ENTITY_ID"]
            final_node = Node(final_id)
            final_node.node_desc = f"{final_id} is a final entity"
            root_node.add_child(final_node)
            parent_nodes.append(final_node)

        # debug_print(result_key)
        # debug_print(step_data.heys())

        while parent_nodes:
            current_node = parent_nodes[-1]
            result_id = current_node.node_id
            if result_id not in result_key:
                current_node.node_desc += " and was orphaned!"
                parent_nodes.pop()
                continue
            # print('-' * 10)
            # print(current_node.node_desc)
            while True:
                step_num = result_key[result_id]
                step_data = steps[step_num]
                if step_data["STEP_TYPE"] == "Combine virtual entities":
                    parent_nodes.pop()  # done with this parent
                    # must add the other two as interim nodes
                    break
                step_node = Node(step_num)
                step_node.node_desc = f"Step {step_num} is {step_data["STEP_TYPE"]} to create {result_id}"
                # print(step_node.node_desc)
                current_node.add_child(step_node)
                if step_data["STEP_TYPE"] == "Create virtual entity":
                    parent_nodes.pop()  # end of the line
                    break
                else:  # its an add record to virtual ID
                    result_id = step_data["ENTITY_LIST"][1]["VIRTUAL_ID"]
                # input('wait')

        how_data = {
            "REEVALUTION_MSG": reevaluation_msg,
            "FINAL_COUNT": len(final_entities),
            "STEPS": steps,
            "RESULT_KEY": result_key,
        }

        print(root_node.render_tree())
        input("wait")

        return how_data

    # -------------------
    # colorizers
    # -------------------

    def colorize(self, in_string, color_list="None"):
        return Colors.apply(in_string, color_list) if color_list else in_string

    def colorize_attr(self, attr_str, attr_color="attr_color"):
        if ":" in attr_str:
            attr_name = attr_str[0 : attr_str.find(":") + 1]
            attr_value = attr_str[attr_str.find(":") + 1 :].strip()
            return self.colorize(attr_name, attr_color) + " " + attr_value
        return self.colorize(attr_str, attr_color)

    def colorize_dsrc(self, dsrc_str):
        if ":" in dsrc_str:
            return self.self.colorize_attr(dsrc_str, "dsrc_color")
        return self.colorize(dsrc_str, "dsrc_color")

    def colorize_entity(self, entity_str, added_color=None):
        entity_color = "entity_color" + ("," + added_color if added_color else "")
        if ":" in str(entity_str):
            return self.colorize_attr(entity_str, entity_color)
        return self.colorize(entity_str, entity_color)

    def colorize_dsrc1(self, dsrc_str):
        return self.colorize(dsrc_str, "dsrc_color")

    def colorize_match_key(self, match_key):
        if " (Ambiguous)" in match_key:
            match_key = match_key.replace(" (Ambiguous)", "")
            ambiguous_tag = " " + self.colorize("(Ambiguous)", "bad")
        else:
            ambiguous_tag = ""
        plus_keys = []
        minus_keys = []
        rel_keys = []
        prior_key = ""
        for key in re.split(r"(\+|\-)", match_key):
            if key in ("+", ""):
                prior_key = "+"
            elif key == "-":
                prior_key = "-"
            elif prior_key == "-":
                minus_keys.append(key)
            else:
                if "(" in key:
                    rel_keys.append(key)
                else:
                    plus_keys.append(key)
        colored_key = ""
        if plus_keys:
            colored_key += self.colorize("+".join(plus_keys), "good")
        if minus_keys:
            colored_key += self.colorize("-" + "-".join(minus_keys), "bad")
        if rel_keys:
            colored_key += self.colorize("+" + "+".join(rel_keys), "disclosed")

        return colored_key + ambiguous_tag

    def colorize_match_data(self, matchDict):
        if not matchDict["matchKey"]:
            if matchDict.get("anyCandidates", False):
                if matchDict.get("ruleCode"):
                    matchStr = self.colorize(matchDict.get("ruleCode"), "dim")
                else:
                    matchStr = self.colorize("scored too low!", "bad")
            else:
                match_str = self.colorize("no matching keys", "bad")
        else:
            good_segments = []
            bad_segments = []
            prior_key = ""
            key_color = "fg_green"
            for key in re.split(r"(\+|\-)", matchDict["matchKey"]):
                if key in ("+", ""):
                    prior_key = "+"
                elif key == "-":
                    prior_key = "-"
                elif prior_key == "-":
                    bad_segments.append(key)
                else:
                    good_segments.append(key)
            if good_segments:
                match_str = self.colorize("+".join(good_segments), "good")
            else:
                match_str = ""
            if bad_segments:
                match_str += self.colorize("-" + "-".join(bad_segments), "bad")

            if matchDict.get("ruleCode"):
                match_str += f"\n {self.colorize(matchDict['ruleCode'], 'dim')}"
            # else:
            #    matchStr += f"\n {self.colorize('no principles satisfied!', 'bad')}"

        if "entityId" in matchDict and "entityName" in matchDict:
            match_str += f"\n to {self.colorize_entity(matchDict['entityId'])} {matchDict['entityName']}"
        elif "entityId" in matchDict:
            match_str += f" to {self.colorize_entity(matchDict['entityId'])}"

        return match_str

    def wrap_text(self, _str, _width, _color=None):
        if len(_str) < _width:
            return [self.colorize(_str, _color)]
        else:
            _list = []
            wrapper = textwrap.TextWrapper(width=_width - 1)
            for line in wrapper.wrap(text=_str):
                prefix = " " if len(_list) else ""
                _list.append(self.colorize(prefix + line, _color))
            return _list

    # -------------------
    # display formatters
    # -------------------

    def fmt_record_summary(self, record_summary, **kwargs):
        sep = kwargs.get("sep", "\n")
        dsrc_counts = {}
        for record in record_summary:
            count = record.get("RECORD_COUNT", 1)
            if record["DATA_SOURCE"] not in dsrc_counts:
                dsrc_counts[record["DATA_SOURCE"]] = count
            else:
                dsrc_counts[record["DATA_SOURCE"]] += count
        return sep.join([f"{self.colorize_dsrc(k)} ({v})" for k, v in dsrc_counts.items()])

    def fmt_record_list(self, record_list, attr_limit, attr_width):
        source_data = {}
        for record in record_list:
            if record["DATA_SOURCE"] not in source_data:
                source_data[record["DATA_SOURCE"]] = [record["RECORD_ID"]]
            else:
                source_data[record["DATA_SOURCE"]].append(record["RECORD_ID"])
        display_list = []
        for data_source in sorted(source_data.keys()):
            colored_source = self.colorize_dsrc(data_source)
            if attr_limit == 1:
                if len(source_data[data_source]) == 1:
                    display_list.append(f"{colored_source}: {source_data[data_source][0]}")
                else:
                    display_list.append(f"{colored_source}: {len(source_data[data_source])} records")
            else:
                line_cnt = 0
                display_list.append(colored_source)
                for record_id in sorted(source_data[data_source]):
                    display_list.append(record_id)
                    line_cnt += 1
                    if line_cnt == attr_limit:
                        break
                if attr_limit > 0 and len(source_data[data_source]) > attr_limit:
                    display_list.append(f"+{len(source_data[data_source])-attr_limit} more")
        return "\n".join(display_list)

    def fmt_features(self, feature_data, attr_limit, attr_width):
        display_list = []
        include_feature_code = True  # len(feature_data.keys()) > 1
        for ftype_code in sorted(feature_data.keys(), key=lambda k: self.ftype_code_order[k]):
            line_cnt = 0
            for feature in sorted(feature_data[ftype_code], key=lambda k: (k["USAGE_TYPE_SORT"], -len(k["FEAT_DESC"]))):
                usage_type = f' ({feature.get("USAGE_TYPE")})' if feature.get("USAGE_TYPE") else ""
                feat_desc = feature["FEAT_DESC"]
                line_cnt += 1
                if line_cnt == attr_limit:
                    continue
                colored_ftype = self.colorize_attr(ftype_code) + ": " if include_feature_code else ""
                colored_utype = self.colorize(usage_type, "dim, italics")
                if len(ftype_code + feat_desc + usage_type) + 2 < attr_width:
                    display_list.append(f"{colored_ftype}{feat_desc}{colored_utype}")
                elif len(feat_desc + usage_type) + 1 < attr_width - 1:
                    display_list.append(colored_ftype)
                    display_list.append(f" {feat_desc}{colored_utype}")
                else:
                    display_list.append(colored_ftype)
                    wrapper = textwrap.TextWrapper(width=attr_width - 1)
                    for line in wrapper.wrap(text=feat_desc):
                        display_list.append(" " + line)
                    if usage_type:
                        if len(display_list[-1] + usage_type) < attr_width - 1:
                            display_list[-1] += colored_utype
                        else:
                            display_list.append(colored_utype)

            if attr_limit > 0 and line_cnt > attr_limit:
                display_list.append(f"{colored_ftype}: +{line_cnt - attr_limit} more")

        return "\n".join(display_list)

    def fmt_why_features(self, feat_list, attr_limit, attr_width):
        display_list = []
        line_cnt = 0
        for feature in sorted(feat_list, key=lambda k: (-k.get("MATCH_SCORE", 0), k["FEAT_DESC"])):
            # debug_print(feature)
            line_cnt += 1
            if line_cnt == attr_limit:
                continue

            feat_desc = feature["FEAT_DESC"]
            stats = "["
            if feature["CANDIDATE_CAP_REACHED"] == "Y":
                stats += "~"
            if feature["SCORING_CAP_REACHED"] == "Y":
                stats += "!"
            if feature["SUPPRESSED"] == "Y":
                stats += "#"
            stats += str(feature["ENTITY_COUNT"]) + "]"

            feat_color = ""
            if feature.get("MATCH_SCORE", 0) > 0:
                if feature.get("WAS_CANDIDATE"):  # always 100
                    feat_color = "highlight2"
                elif feature.get("SCORE_BUCKET") in ("SAME", "CLOSE"):
                    feat_color = "good"
                elif "E" in feature.get("SCORE_BEHAVIOR", ""):
                    feat_color = "bad"
                else:
                    feat_color = "caution"
            elif feature["FTYPE_CODE"] == "AMBIGUOUS_ENTITY":
                feat_color = "bad"

            if any(x in stats for x in ("~", "!", "#")):
                feat_color += ",dim" if feat_color else "dim"

            display_list.extend(self.wrap_text(f"{feat_desc} {stats}", attr_width, feat_color))

            if feature.get("MATCHED_FEAT_DESC"):
                if feature["FTYPE_CODE"] != "NAME":
                    score = feature.get("MATCH_SCORE", 0)
                elif feature["ALL_SCORES"].get("GNR_ON", -1) != -1:
                    score = f"ORG:{feature["ALL_SCORES"].get("GNR_ON", 0)}"
                else:
                    score_list = []
                    if feature["ALL_SCORES"].get("GNR_FN", -1) != -1:
                        score_list.append(f"FULL:{feature["ALL_SCORES"].get("GNR_FN")}")
                    if feature["ALL_SCORES"].get("GNR_SN", -1) != -1:
                        score_list.append(f"SUR:{feature["ALL_SCORES"].get("GNR_SN")}")
                    if feature["ALL_SCORES"].get("GNR_GN", -1) != -1:
                        score_list.append(f"GIV:{feature["ALL_SCORES"].get("GNR_GN")}")
                    score = "|".join(score_list)
                matched_desc = f"\u2514\u2500\u2500 {feature["MATCHED_FEAT_DESC"]} ({score})"
                display_list.extend(self.wrap_text(matched_desc, attr_width, feat_color))

        if attr_limit > 0 and line_cnt > attr_limit:
            display_list.append(f"{colored_ftype}: +{line_cnt - attr_limit} more")

        return "\n".join(display_list)

        return feature_data

    def fmt_unmapped(self, unmapped_list, attr_limit, attr_width):
        attr_data = {}
        for record in unmapped_list:
            attr, value = list(record.items())[0]
            if attr not in attr_data:
                attr_data[attr] = [str(value)]
            else:
                attr_data[attr].append(str(value))
        display_list = []
        for attr in sorted(attr_data.keys()):
            colored_attr = self.colorize_attr(attr) + ":"
            attr_value_list = sorted(set(attr_data[attr]))

            line_cnt = 0
            for value in attr_value_list:
                if len(attr + value) + 1 < attr_width:
                    display_list.append(f"{colored_attr} {value}")
                else:
                    display_list.append(colored_attr)
                    wrapper = textwrap.TextWrapper(width=attr_width - 1)
                    for line in wrapper.wrap(text=value):
                        display_list.append(" " + line)
                line_cnt += 1
                if line_cnt == attr_limit:
                    continue
            if attr_limit > 0 and line_cnt > attr_limit:
                display_list.append(f"{colored_attr}: +{line_cnt - attr_limit} more")

        return "\n".join(display_list)

    def fmt_match_key(self, match_data, **kwargs):
        sep = kwargs.get("sep", "\n")
        colored_key = ""
        if match_data.get("MATCH_KEY"):
            colored_key = self.colorize_match_key(match_data["MATCH_KEY"])
        colored_rule = ""
        if match_data.get("ERRULE_CODE"):
            rule_id = match_data.get("ERRULE_ID", self.errule_code_lookup[match_data["ERRULE_CODE"]]["ERRULE_ID"])
            colored_rule = self.colorize(f'Principle {rule_id}: {match_data["ERRULE_CODE"]}', "dim")
            if not colored_key:
                colored_key = colored_rule
            else:
                colored_key += f"{sep} {colored_rule}"
        return colored_key

    # ---------------------------
    def fmt_match_group(self, match_category, match_key, **kwargs):
        match_key = match_key.replace(" (Ambiguous)", "")
        rel_keys = []
        plus_keys = []
        minus_keys = []
        key_list = re.split(r"(\+|\-)", match_key)
        i = 1
        while i < len(key_list):
            if key_list[i] in ("-"):
                i += 1
                this_key = key_list[i]
                minus_keys.append(this_key)

            elif key_list[i] in ("+"):
                i += 1
                this_key = key_list[i]
                if "(" not in this_key:
                    plus_keys.append(this_key)
                elif "REL_POINTER(" in this_key:  # kwargs.get("from_database"):
                    # format: REL_POINTER(DOMAIN:|MIN:|MAX:PRINCIPAL)
                    try:
                        l1 = this_key.find("DOMAIN:")
                        l2 = this_key.find("MIN:")
                        l3 = this_key.find("MAX:")
                        domain = this_key[l1 + 7 : l2 - 1]
                        role1 = this_key[l2 + 4 : l3 - 1]
                        role2 = this_key[l3 + 4 : -1]
                        rel_keys.append(f"{domain}({role1}:{role2})")
                    except:
                        print(f"Could not parse: {this_key}")
                else:
                    # format: DOMAIN(ROLE:ROLE) left role is from this entity's point of view
                    roles = this_key[this_key.find("(") + 1 : this_key.find(")")].split(":")
                    if roles[0]:
                        role = roles[0] + " -->"
                    else:
                        role = "<-- " + roles[1]
                    rel_keys.append(role)
            i += 1

        if rel_keys:
            match_group = self.colorize("+".join(sorted(rel_keys)), "disclosed")
        else:
            match_group = self.colorize("+".join(plus_keys), "good") if plus_keys else ""
            if match_category == "POSSIBLE_MATCH":
                match_group += self.colorize("-" + "-".join(minus_keys), "bad") if minus_keys else ""

        return match_group

    def fmt_relation(self, relation):
        colored_key = self.fmt_match_key(relation)
        colored_key += f'\n to {self.colorize_entity(relation.get("ENTITY_ID"))} {relation.get("ENTITY_NAME")}'
        return colored_key

    def fmt_entity_desc(self, entity):
        entity_desc = f'{self.colorize_entity(entity["ENTITY_ID"])}: {entity["ENTITY_NAME"]}'
        if entity.get("RECORD_SUMMARY"):
            entity_desc += " " + self.fmt_record_summary(entity["RECORD_SUMMARY"], sep=" | ")
        return entity_desc

    # ---------------------------
    def render_table(self, tbl_title, tbl_columns, tbl_rows, **kwargs):

        title_color = kwargs.get("titleColor", "table_title")
        # title_justify = kwargs.get("titleJustify", "l")
        # header_color = kwargs.get("headerColor", "column_header")
        combine_headers = kwargs.get("combineHeaders", False)

        table_object = PrettyTable()
        table_object.hrules = PRETTY_TABLE_ALL
        table_object.horizontal_char = "\u2500"
        table_object.vertical_char = "\u2502"
        table_object.junction_char = "\u253C"

        field_name_list = []
        column_header_list = []
        for column_data in tbl_columns:
            field_name_list.append(column_data["name"])
            column_header_list.append(
                "\n".join(self.colorize(str(x), "column_header") for x in str(column_data["name"]).split("\n"))
            )
        table_object.field_names = field_name_list
        table_object.header = False
        table_object.add_row(column_header_list)

        total_row_cnt = 0
        for row in tbl_rows:
            total_row_cnt += 1
            row[0] = "\n".join([i for i in str(row[0]).split("\n")])
            table_object.add_row(row)

        for column_data in tbl_columns:
            table_object.align[column_data["name"]] = column_data["align"][0:1].lower()

        table_str = table_object.get_string()
        if combine_headers:
            table_str = self.combine_table_headers(table_str)
        if tbl_title:
            table_str = f"{self.colorize(tbl_title, title_color)}\n{table_str}"

        return table_str + "\n"

    # -------------------
    # reports
    # -------------------

    def get_features(self, arg_tokens, **kwargs):
        """display an entity's features and internal parsing"""
        feature_filters = kwargs.get("feature_filters")
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
        ]
        try:
            if len(arg_tokens) == 1:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(arg_tokens[0]))
            else:
                json_data = self.call_sdk("get_entity_by_record_id", get_flag_list, arg_tokens)
        except SzError as err:
            print_message(err, "error")
            return 0

        related_entity_count = len(json_data.get("RELATED_ENTITIES", []))
        entity_id = json_data["RESOLVED_ENTITY"]["ENTITY_ID"]
        entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
        entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]

        tbl_title = f"Features of entity {self.colorize_entity(entity_id)}: {entity_name}"
        tbl_columns = [
            {"name": "Feature", "width": 30, "align": "left"},
            {"name": "Description", "width": 100, "align": "left"},
            {"name": "Elements", "width": 100, "align": "left"},
        ]
        tbl_rows = []
        for lib_feat_id in sorted(
            set(entity_features.keys()), key=lambda k: self.ftype_code_order[entity_features[k]["FTYPE_CODE"]]
        ):
            try:
                response = self.sz_diagnostic.get_feature(lib_feat_id)
            except SzError as err:
                print_message(err, "error")
                return 0
            feature_data = json.loads(response)

            if feature_filters and feature_data["FTYPE_CODE"] not in kwargs.get("feature_filters"):
                continue

            felem_values = []
            for felem_data in sorted(
                feature_data["ELEMENTS"], key=lambda k: self.felem_code_lookup[k["FELEM_CODE"]]["FELEM_ID"]
            ):
                felem_code = f'{self.colorize_attr(felem_data["FELEM_CODE"])}'
                felem_value = felem_data["FELEM_VALUE"]
                if felem_data["FELEM_CODE"] == "LIBPOSTAL_PARSE":
                    # with suppress(Exception):
                    # print(felem_value)
                    value_data = json.loads(felem_value)
                    value_list = []
                    for key in sorted(value_data.keys()):
                        value_list.append(f"  {self.colorize(key, "highlight2,dim")}: {json.dumps(value_data[key])}")
                    felem_value = "\n" + "\n".join(value_list)
                felem_values.append(f"{felem_code}: {felem_value}")

            tbl_rows.append(
                [
                    f'{self.colorize_attr(feature_data["FTYPE_CODE"])}\n  {self.colorize("id: " + str(lib_feat_id), "dim")}',
                    entity_features[lib_feat_id]["FEAT_DESC"],
                    "\n".join(felem_values),
                ]
            )

        return self.render_table(tbl_title, tbl_columns, tbl_rows)

    def get_entity(self, arg_tokens, **kwargs):
        show_detail = kwargs.get("show_detail")
        attr_limit = kwargs.get("attr_limit", -1)
        show_relations_on_get = kwargs.get("show_relations_on_get", "grid")
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
        ]
        try:
            if len(arg_tokens) == 1:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(arg_tokens[0]))
            else:
                json_data = self.call_sdk("get_entity_by_record_id", get_flag_list, arg_tokens)
        except SzError as err:
            print_message(err, "error")
            return 0

        related_entity_count = len(json_data.get("RELATED_ENTITIES", []))
        entity_id = json_data["RESOLVED_ENTITY"]["ENTITY_ID"]
        entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
        entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
        self.last_entity_id = entity_id

        attr_width = 80
        report_type = "detail" if show_detail else "summary"
        tbl_title = f"Entity {report_type} for entity {self.colorize_entity(entity_id)}: {entity_name}"
        if args.webapp_url:
            tbl_title += f"  {self.colorize('WebApp:', 'dim')} " + self.colorize(
                f"{args.webapp_url}/graph/{entity_id}", "highlight1,underline"
            )
        tbl_columns = [
            {"name": "Sources", "width": 50, "align": "left"},
            {"name": "Features", "width": attr_width, "align": "left"},
            {"name": "Additional Data", "width": attr_width, "align": "left"},
        ]

        table_data = {}
        for record in sorted(json_data["RESOLVED_ENTITY"]["RECORDS"], key=lambda k: (k["DATA_SOURCE"], k["RECORD_ID"])):
            data_source = record["DATA_SOURCE"]
            record_id = record["RECORD_ID"]
            record_only = {"DATA_SOURCE": data_source, "RECORD_ID": record_id}
            record_features = self.get_record_features(entity_features, record["FEATURES"])["BY_ID"]
            unmapped_items = self.get_unmapped_list(record.get("UNMAPPED_DATA"))
            if report_type == "summary":
                table_key = data_source
            else:
                table_key = data_source + record_id
            if table_key not in table_data:
                table_data[table_key] = {
                    "RECORDS": [record_only],
                    "FEATURES": record_features,
                    "UNMAPPED": unmapped_items,
                }
            else:
                table_data[table_key]["RECORDS"].append(record_only)
                table_data[table_key]["FEATURES"].update(record_features)
                table_data[table_key]["UNMAPPED"].extend(unmapped_items)

        tbl_rows = []
        for table_key in table_data:
            features_by_type = self.regroup_by_type(table_data[table_key]["FEATURES"])
            source_display = self.fmt_record_list(table_data[table_key]["RECORDS"], attr_limit, attr_width)
            feature_display = self.fmt_features(features_by_type, attr_limit, attr_width)
            unmapped_display = self.fmt_unmapped(table_data[table_key]["UNMAPPED"], attr_limit, attr_width)
            tbl_rows.append([source_display, feature_display, unmapped_display])
        report = self.render_table(tbl_title, tbl_columns, tbl_rows)

        if related_entity_count == 0 or show_relations_on_get == "none":
            # rel_count_str = f"{'No' if related_entity_count == 0 else related_entity_count}"
            report += f"\u2514\u2500\u2500 {related_entity_count} related entities\n"

        elif related_entity_count and show_relations_on_get == "tree":
            tree_str = self.get_relationship_tree(entity_id)
            report += tree_str[tree_str.find("\n") + 1 :]

        elif related_entity_count:
            related_entities = self.get_related_entities(json_data["RELATED_ENTITIES"])["LIST"]
            tbl_title = f"{related_entity_count} related entities"
            tbl_columns = []
            tbl_columns.append({"name": "Entity ID", "width": 25, "align": "center"})
            tbl_columns.append({"name": "Entity Name", "width": 100, "align": "left"})
            tbl_columns.append({"name": "Data Sources", "width": 100, "align": "left"})
            tbl_columns.append({"name": "Match Level", "width": 15, "align": "left"})
            tbl_columns.append({"name": "Match Key", "width": 100, "align": "left"})
            tbl_rows = []
            for relationship in sorted(
                related_entities, key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"])
            ):
                tbl_rows.append(
                    [
                        self.colorize_entity(relationship["ENTITY_ID"]),
                        relationship["ENTITY_NAME"],
                        self.fmt_record_summary(relationship["RECORD_SUMMARY"]),
                        self.match_category_desc[relationship["MATCH_CATEGORY"]],
                        self.fmt_match_key(relationship),
                    ]
                )
            report += self.render_table(tbl_title, tbl_columns, tbl_rows)

        return report

    def get_relationship_tree(self, root_entity_id, **kwargs):
        build_out_degree = kwargs.get("build_out_degree", 1)
        max_degree = 0  # really only used for entity paths
        max_entities = 10000  # for safety
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            extra_parms = [[root_entity_id], max_degree, build_out_degree, max_entities]
            json_data = self.call_sdk("find_network_by_entity_id", get_flag_list, extra_parms)
        except SzError as err:
            print_message(err, "error")
            return
        entities = self.get_resolved_entities(json_data["ENTITIES"])

        if build_out_degree == 1:  # categorize and group
            category_counts = {}
            categories = {}
            related_entities = entities[root_entity_id]["RELATIONSHIPS"]
            for relation in sorted(
                related_entities, key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"])
            ):
                match_category = relation["MATCH_CATEGORY"]
                match_key = relation["MATCH_KEY"]
                if match_category not in categories:
                    categories[match_category] = {}
                    category_counts[match_category] = 1
                else:
                    category_counts[match_category] = 1
                match_group = self.fmt_match_group(match_category, match_key)
                if match_group not in categories[match_category]:
                    categories[match_category][match_group] = [relation]
                else:
                    categories[match_category][match_group].append(relation)

            root_node = Node(root_entity_id)
            root_node.node_desc = self.fmt_entity_desc(entities[root_entity_id])
            for category in categories:
                category_node = Node(category)
                category_desc = f"{self.match_category_desc[category]} ({category_counts[category]})"
                category_node.node_desc = category_desc
                root_node.add_child(category_node)
                for group in categories[category]:
                    group_node = Node(group)
                    group_desc = f"{group} ({len(categories[category][group])})"
                    group_node.node_desc = group_desc
                    category_node.add_child(group_node)
                    for relation in categories[category][group]:
                        related_id = relation["ENTITY_ID"]
                        rel_node = Node(related_id)
                        rel_desc = self.fmt_entity_desc(entities[related_id])
                        rel_desc += " " + self.fmt_match_key({"MATCH_KEY": relation["MATCH_KEY"]})
                        rel_node.node_desc = rel_desc
                        group_node.add_child(rel_node)
        else:
            tree_nodes = {}
            for entity_id in entities:
                if entity_id not in tree_nodes:
                    tree_nodes[entity_id] = Node(entity_id)
                    tree_nodes[entity_id].node_desc = self.fmt_entity_desc(entities[entity_id])
                related_entities = entities[entity_id]["RELATIONSHIPS"]
                for relation in sorted(
                    related_entities, key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"])
                ):
                    related_id = relation["ENTITY_ID"]
                    if related_id not in entities:
                        continue
                    if related_id not in tree_nodes:
                        tree_nodes[related_id] = Node(related_id)
                        node_desc = self.fmt_entity_desc(entities[related_id])
                        node_desc += " " + self.fmt_match_key({"MATCH_KEY": relation["MATCH_KEY"]})
                        tree_nodes[related_id].node_desc = node_desc

                    if related_id not in tree_nodes[entity_id].children:
                        tree_nodes[entity_id].add_child(tree_nodes[related_id])
                    else:
                        print("Tell Jeff: related_id was already added to child list!!!!!")

            root_node = tree_nodes[root_entity_id]
        return root_node.render_tree()

        if False:  # candidate to replace both above
            # problem is category and group nodes displayed for prior tree entities
            tree_nodes = {}
            for entity_id in entities:
                if entity_id not in tree_nodes:
                    tree_nodes[entity_id] = Node(entity_id)
                    tree_nodes[entity_id].node_desc = self.fmt_entity_desc(entities[entity_id])

                category_counts = {}
                categories = {}
                related_entities = entities[entity_id]["RELATIONSHIPS"]
                for relation in sorted(
                    related_entities, key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"])
                ):
                    match_category = relation["MATCH_CATEGORY"]
                    match_key = relation["MATCH_KEY"]
                    if match_category not in categories:
                        categories[match_category] = {}
                        category_counts[match_category] = 1
                    else:
                        category_counts[match_category] = 1
                    match_group = self.fmt_match_group(match_category, match_key)
                    if match_group not in categories[match_category]:
                        categories[match_category][match_group] = [relation]
                    else:
                        categories[match_category][match_group].append(relation)

                for category in categories:
                    category_node = Node(f"{entity_id}-{category}")
                    category_desc = f"{self.match_category_desc[category]} ({category_counts[category]})"
                    category_node.node_desc = category_desc
                    tree_nodes[entity_id].add_child(category_node)
                    for group in categories[category]:
                        group_node = Node(f"{entity_id}-{category}-{group}")
                        group_desc = f"{group} ({len(categories[category][group])})"
                        group_node.node_desc = group_desc
                        category_node.add_child(group_node)
                        for relation in categories[category][group]:
                            related_id = relation["ENTITY_ID"]
                            if related_id not in entities:
                                continue
                            if related_id not in tree_nodes:
                                rel_desc = self.fmt_entity_desc(entities[related_id])
                                rel_desc += " " + self.fmt_match_key({"MATCH_KEY": relation["MATCH_KEY"]})
                                tree_nodes[related_id] = Node(related_id)
                                tree_nodes[related_id].node_desc = rel_desc
                            group_node.add_child(tree_nodes[related_id])
            root_node = tree_nodes[root_entity_id]

        return root_node.render_tree()

    def compare_relationships(self, entity_id, **kwargs):
        """compare an entity's relationships side by side"""
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            raise Exception(err)
        entity_list = [entity_id]
        related_entities = self.get_related_entities(json_data["RELATED_ENTITIES"])["LIST"]
        entity_list.extend([str(x["ENTITY_ID"]) for x in related_entities])
        kwargs["compare_to_1"] = True
        return self.compare_entities(entity_list, **kwargs)

    def compare_entities(self, entity_list, **kwargs):
        """compare a list of entities side by side"""
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
        ]

        attr_limit = kwargs.get("attr_limit", 20)
        attr_width = 80
        if kwargs.get("compare_to_1"):
            tbl_title = "Comparison of relationships"
        else:
            tbl_title = "Comparison of listed entities"
        tbl_columns = [{"name": "Entity", "width": 15, "align": "left"}]
        tbl_rows = []
        ftype_codes = []
        entities = {}
        source_row = ["DATA_SOURCES"]
        for entity_id in entity_list:
            try:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                raise Exception(err)

            records = json_data["RESOLVED_ENTITY"]["RECORDS"]
            features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_TYPE"]
            relations = self.get_related_entities(json_data["RELATED_ENTITIES"])["BY_ID"]

            source_row.append(self.fmt_record_list(records, 1, attr_width))
            entities[entity_id] = {"RECORDS": records, "FEATURES": features, "RELATIONS": relations}
            column_header = f"{self.colorize_entity(entity_id)}"
            tbl_columns.append({"name": column_header, "width": attr_width, "align": "left"})
            ftype_codes.extend(list(features.keys()))
        tbl_rows.append(source_row)

        if kwargs.get("compare_to_1"):
            cross_row = ["RELATIONSHIP"]
        else:
            cross_row = ["CROSS_RELATIONS"]
        common_row = ["COMMON_RELATIONS"]
        any_cross_rels = False
        any_common_rels = False
        entity_id1 = entity_list[0]
        for entity_id in entity_list:
            common_rels = []
            cross_rels = []
            for related_id in entities[entity_id]["RELATIONS"]:
                relation = entities[entity_id]["RELATIONS"][related_id]
                if kwargs.get("compare_to_1"):
                    if entity_id != entity_id1 and str(related_id) == entity_id1:
                        cross_rels.append(self.fmt_relation(relation))
                        any_cross_rels = True
                else:
                    if str(related_id) in entity_list:
                        cross_rels.append(self.fmt_relation(relation))
                        any_cross_rels = True

                common_count = 0
                for entity_id2 in entity_list:
                    if entity_id2 == entity_id:
                        continue
                    if related_id in entities[entity_id2]["RELATIONS"]:
                        common_count += 1
                if common_count == len(entity_list) - 1:
                    common_rels.append(self.fmt_relation(relation))
                    any_common_rels = True
            cross_row.append("\n".join(cross_rels))
            common_row.append("\n".join(common_rels))

        if any_cross_rels:
            tbl_rows.append(cross_row)
        if any_common_rels:
            tbl_rows.append(common_row)

        for ftype_code in sorted(set(ftype_codes), key=lambda k: self.ftype_code_order[k]):
            feat_row = [ftype_code]
            for entity_id in entity_list:
                feat_list = entities[entity_id]["FEATURES"].get(ftype_code)
                if feat_list:
                    feat_row.append(self.fmt_features({ftype_code: feat_list}, attr_limit, attr_width))
                else:
                    feat_row.append("")
            tbl_rows.append(feat_row)

        any_unmapped = False
        unmapped_row = ["ADDITIONAL_DATA"]
        for entity_id in entity_list:
            unmapped_list = []
            for record in entities[entity_id]["RECORDS"]:
                unmapped_list.extend(self.get_unmapped_list(record.get("UNMAPPED_DATA")))
                any_unmapped = True
            unmapped_row.append(self.fmt_unmapped(unmapped_list, attr_limit, attr_width))
        if any_unmapped:
            tbl_rows.append(unmapped_row)

        return self.render_table(tbl_title, tbl_columns, tbl_rows)

    def why_display(self, entity_data, row1_title, report_title):
        caller = sys._getframe().f_back.f_code.co_name
        attr_width = 80
        attr_limit = 20
        tbl_title = report_title
        tbl_columns = [{"name": row1_title, "width": 15, "align": "left"}]
        tbl_rows = []
        source_row = ["DATA_SOURCES"]
        why_row = ["WHY_RESULT"]
        entity_list = entity_data.keys()

        ftype_codes_used = []
        for _id in entity_list:
            records = entity_data[_id]["RECORDS"]
            source_row.append(self.fmt_record_list(records, 1, attr_width))

            if "MATCH_INFO_LIST" in entity_data[_id]:  # for why not many
                scores_by_id = {}
                why_list = []
                for match_info in entity_data[_id]["MATCH_INFO_LIST"]:
                    scores_by_id.update(self.get_why_scores(match_info))
                    why_list.append(self.fmt_relation(match_info))
                why_row.append("\n".join(why_list))

            else:
                match_info = entity_data[_id]["MATCH_INFO"]
                why_key = self.get_why_key(match_info)
                scores_by_id = self.get_why_scores(match_info)
                why_row.append(self.fmt_match_key(why_key))

            features_by_id = entity_data[_id]["FEATURES"]
            for lib_feat_id in features_by_id:
                ftype_codes_used.append(features_by_id[lib_feat_id]["FTYPE_CODE"])
                if lib_feat_id in scores_by_id:
                    if scores_by_id[lib_feat_id].get("MATCH_SCORE"):
                        features_by_id[lib_feat_id].update(scores_by_id[lib_feat_id])
            entity_data[_id]["FEATURES"] = self.regroup_by_type(features_by_id)

            column_header = self.colorize(_id, "dim" if row1_title == "Internal ID" else "entity_color")
            tbl_columns.append({"name": column_header, "width": attr_width, "align": "left"})
        tbl_rows.append(source_row)
        tbl_rows.append(why_row)

        cross_row = ["CROSS_RELATIONS"]
        any_cross_rels = False
        for entity_id in entity_list:
            cross_rels = []
            for related_id in entity_data[entity_id].get("RELATIONS", {}):
                if related_id in entity_list:
                    relation = entity_data[entity_id]["RELATIONS"][related_id]
                    cross_rels.append(self.fmt_relation(relation))
                    any_cross_rels = True
            cross_row.append("\n".join(cross_rels))
        if any_cross_rels:
            tbl_rows.append(cross_row)

        for ftype_code in sorted(set(ftype_codes_used), key=lambda k: self.ftype_code_order[k]):
            feat_row = [ftype_code]
            for _id in entity_list:
                feat_list = entity_data[_id]["FEATURES"].get(ftype_code)
                if feat_list:
                    feat_row.append(self.fmt_why_features(feat_list, attr_limit, attr_width))
                else:
                    feat_row.append("")
            tbl_rows.append(feat_row)

        return self.render_table(tbl_title, tbl_columns, tbl_rows)

    # ---------------------------
    def why_records(self, entity_list):
        whyFlagList = [
            "SZ_WHY_ENTITIES_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]
        try:
            parms = [entity_list[0], entity_list[1], entity_list[2], entity_list[3]]
            json_data = self.call_sdk("why_records", whyFlagList, parms)
        except SzError as err:
            print_message(err, "error")
            return

        entities = {}
        for entity_data in json_data["ENTITIES"]:
            entity_id = entity_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = entity_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(entity_data["RELATED_ENTITIES"])["BY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
            }

        why_result = json_data["WHY_RESULTS"][0]  # only 1 result for whyRecord
        match_info = why_result["MATCH_INFO"]
        entity_data = {}
        entity_fields = (
            ("INTERNAL_ID", "ENTITY_ID", "FOCUS_RECORDS"),
            ("INTERNAL_ID_2", "ENTITY_ID_2", "FOCUS_RECORDS_2"),
        )
        for internal_field, entity_field, record_field in entity_fields:
            internal_id = why_result[internal_field]
            entity_id = why_result[entity_field]
            entity_features = entities[entity_id]["FEATURES"]
            entity_records = entities[entity_id]["RECORDS"]
            features = {}
            for record in why_result[record_field]:
                data_source = record["DATA_SOURCE"]
                record_id = record["RECORD_ID"]
                record = next(
                    x for x in entity_records if x["DATA_SOURCE"] == data_source and x["RECORD_ID"] == record_id
                )
                features.update(self.get_record_features(entity_features, record["FEATURES"])["BY_ID"])
            entity_data[internal_id] = {
                "RECORDS": why_result[record_field],
                "FEATURES": features,
                "RELATIONS": [],
                "MATCH_INFO": match_info,
            }
        tbl_title = f"Why for listed records"
        row1_title = "INTERNAL_ID"
        return self.why_display(entity_data, row1_title, tbl_title)

    # ---------------------------
    def why_not(self, entity_list):
        entity_list = [int(x) for x in entity_list]
        why_flag_list = ["SZ_WHY_ENTITIES_DEFAULT_FLAGS"]
        try:
            parms = [entity_list[0], entity_list[1]]
            json_data = self.call_sdk("why_entities", why_flag_list, parms)
        except SzError as err:
            print_message(err, "error")
            return

        match_info = json_data["WHY_RESULTS"][0]["MATCH_INFO"]
        entities = {}
        for entity_data in json_data["ENTITIES"]:
            entity_id = entity_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = entity_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(entity_data["RELATED_ENTITIES"])["BY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
                "MATCH_INFO": match_info,
            }
        tbl_title = "Why not for listed entities"
        row1_title = "ENTITY_ID"
        return self.why_display(entities, row1_title, tbl_title)

    def why_not_many(self, entity_list):
        entity_list = [int(x) for x in entity_list]
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
        ]
        entities = {}
        for entity_id in entity_list:
            try:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                return
            entity_id = json_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = json_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(json_data["RELATED_ENTITIES"])["BY_ID"]

            search_str = json.dumps(self.combine_json(records))
            search_flag_list = [
                "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
                "SZ_INCLUDE_FEATURE_SCORES",
                "SZ_ENTITY_INCLUDE_FEATURE_STATS",
                "SZ_ENTITY_INCLUDE_ENTITY_NAME",
                "SZ_ENTITY_INCLUDE_RECORD_DATA",
            ]
            try:
                json_data2 = self.call_sdk("search_by_attributes", search_flag_list, search_str)
            except SzError as err:
                print_message(err, "error")
                return
            match_info_list = []
            for matched_entity in json_data2["RESOLVED_ENTITIES"]:
                matched_id = matched_entity["ENTITY"]["RESOLVED_ENTITY"]["ENTITY_ID"]
                if matched_id in entity_list and matched_id != entity_id:
                    match_info = matched_entity["MATCH_INFO"]
                    match_info["ENTITY_ID"] = matched_id
                    match_info["ENTITY_NAME"] = matched_entity["ENTITY"]["RESOLVED_ENTITY"]["ENTITY_NAME"]
                    match_info_list.append(match_info)

            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
                "MATCH_INFO_LIST": match_info_list,
            }

        tbl_title = "Why not for listed entities"
        row1_title = "ENTITY_ID"
        return self.why_display(entities, row1_title, tbl_title)

    def why_how(self, entity_id):
        entity_id = int(entity_id)
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]
        try:
            entity_json = self.call_sdk("get_entity_by_entity_id", get_flag_list, entity_id)
        except SzError as err:
            print_message(err, "error")
            return
        how_flag_list = ["SZ_HOW_ENTITY_DEFAULT_FLAGS"]
        try:
            how_json = self.call_sdk("how_entity_by_entity_id", how_flag_list, entity_id)
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0
        how_data = self.get_how_data(how_json, entity_json)
        entities = {}
        step_data = how_data["STEPS"]
        for step_num in sorted(step_data.keys()):
            for entity in step_data[step_num]["ENTITY_LIST"]:
                if entity["MEMBER_COUNT"] == 1:
                    virtual_id = f'Step {step_num}-{entity["VIRTUAL_ID"]}'
                    entities[virtual_id] = {
                        "ENTITY_ID": virtual_id,
                        "ENTITY_NAME": "foo",
                        "FEATURES": entity["FEATURES"],
                        "RECORDS": entity["RECORDS"],
                        "MATCH_INFO": step_data[step_num]["MATCH_INFO"],
                    }
        #entities, how_data = self.why_how(entity_id)
        tbl_title = f"How for entity: {self.colorize_entity(entity_id)}"
        row1_title = "VIRTUAL_ID"
        tbl_title += f' resulted in {how_data["FINAL_COUNT"]} entities!'

        return self.why_display(entities, row1_title, tbl_title)


# -----------------------
# colorizers
# -----------------------


def colorize_prompt(prompt_str, auto_scroll="off"):
    # this is effectively off until the auto scroll parameter gets passed
    #  otherwise colorized tags causes word wrapping
    # example prompt: (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (Q)uit
    if auto_scroll == "on":
        for str1 in "PNGDHWEQCFSO":
            prompt_str = prompt_str.replace(f"({str1})", f"({Colors.apply(str1, 'bold')})")
    return prompt_str


class G2CmdShell(cmd.Cmd):

    # ---------------------------
    def __init__(self, args, sz_pretty, sz_dbo):
        cmd.Cmd.__init__(self)
        self.__hidden_methods = "do_shell"
        self.dsrc_record_sep = "~|~"

        self.intro = "\nType help or ? to list commands.\n"
        self.prompt = "(sz) "

        self.valid_match_level_parameters = {
            "0": "SINGLE_SAMPLE",
            "1": "DUPLICATE_SAMPLE",
            "2": "AMBIGUOUS_MATCH_SAMPLE",
            "3": "POSSIBLE_MATCH_SAMPLE",
            "4": "POSSIBLY_RELATED_SAMPLE",
            "S": "SINGLE_SAMPLE",
            "D": "DUPLICATE_SAMPLE",
            "M": "DUPLICATE_SAMPLE",
            "A": "AMBIGUOUS_MATCH_SAMPLE",
            "P": "POSSIBLE_MATCH_SAMPLE",
            "R": "POSSIBLY_RELATED_SAMPLE",
            "SINGLE": "SINGLE_SAMPLE",
            "DUPLICATE": "DUPLICATE_SAMPLE",
            "MATCH": "DUPLICATE_SAMPLE",
            "AMBIGUOUS": "AMBIGUOUS_MATCH_SAMPLE",
            "POSSIBLE": "POSSIBLE_MATCH_SAMPLE",
            "POSSIBLY": "POSSIBLY_RELATED_SAMPLE",
            "RELATED": "POSSIBLY_RELATED_SAMPLE",
        }

        self.settings_file_name = f"{os.path.expanduser("~")}{os.path.sep}.sz_explorer_settings"
        if self.settings_file_name:
            self.current_settings = json.load(open(self.settings_file_name))
        else:
            self.current_settings = {}

        # default settings for data and cross sources summary reports
        self.configurable_settings_list = [
            {
                "setting": "color_scheme",
                "values": ["default", "light", "dark"],
                "description": "light works better on dark backgrounds and vice-versa",
            },
            {
                "setting": "data_source_suppression",
                "values": ["off", "on"],
                "description": "restricts the data and crossSourceSummary reports to only applicable data sources",
            },
            {
                "setting": "show_relations_on_get",
                "values": ["tree", "grid", "none"],
                "description": "display relationships on get in tree or grid or not at all",
            },
            {
                "setting": "audit_measure",
                "values": ["pairwise", "legacy"],
                "description": "show official pairwise or legacy (record based) statistics",
            },
            {
                "setting": "auto_scroll",
                "values": ["off", "on"],
                "description": "automatically go into scrolling mode if table larger than screen",
            },
        ]
        for setting_data in self.configurable_settings_list:
            self.current_settings[setting_data["setting"]] = self.current_settings.get(
                setting_data["setting"], setting_data["values"][0]
            )
        self.do_set(f"color_scheme {self.current_settings['color_scheme']}")

        self.last_entity_id = 0
        self.last_search_result = []
        self.current_review_list = None
        self.current_report = None

        readline.set_completer_delims(" ")
        self.histCheck()

        if args.snapshot_json_file:
            self.current_settings["snapshot_json_file"] = args.snapshot_json_file
        if self.current_settings.get("snapshot_json_file") and os.path.exists(
            self.current_settings["snapshot_json_file"]
        ):
            self.do_load(self.current_settings["snapshot_json_file"])
        else:
            self.snapshot_file = None
            self.snapshot_data = {}

        if args.audit_json_file:
            self.current_settings["audit_json_file"] = args.audit_json_file
        if self.current_settings.get("audit_json_file") and os.path.exists(self.current_settings["audit_json_file"]):
            self.do_load(self.current_settings["audit_json_file"])
        else:
            self.audit_file = {}
            self.audit_data = {}

        self.audit_colors = {
            "MERGE": "good",
            "SPLIT": "bad",
            "SPLIT+MERGE": "fg_red,bg_green",
            "unknown": "bg_red,fg_white",
        }

    def get_names(self):
        """hides functions from available list of Commands. Seperate help sections for some"""
        return [n for n in dir(self.__class__) if n not in self.__hidden_methods]

    def completenames(self, text, *ignored):
        dotext = "do_" + text
        return [a[3:] for a in self.get_names() if a.lower().startswith(dotext.lower())]

    def emptyline(self):
        return

    def colorize(self, in_string, color_list="None"):
        return Colors.apply(in_string, color_list) if color_list else in_string

    def do_quit(self, arg):
        # remove_from_history()
        return True

    def do_exit(self, arg):
        self.do_quit(self)
        return True

    def cmdloop(self):
        while True:
            try:
                cmd.Cmd.cmdloop(self)
                break
            except KeyboardInterrupt:
                ans = input("\n\nAre you sure you want to exit? ")
                if ans.upper().startswith("Y"):
                    break
            except TypeError as ex:
                print_message(str(ex), "error")
                _, _, traceback_ = sys.exc_info()
                for item in traceback.format_tb(traceback_):
                    print(item)

    def postloop(self):
        try:
            with open(self.settings_file_name, "w", encoding="utf-8") as f:
                json.dump(self.current_settings, f)
        except:
            pass

    # --------------------
    # general commands
    # --------------------

    def do_help(self, help_topic):
        if not help_topic:
            print(
                textwrap.dedent(
                    f"""\

            {self.colorize('Adhoc entity commands:', 'highlight2')}
                search {self.colorize('- search for entities by name and/or other attributes.', 'dim')}
                get {self.colorize('- get an entity by entity ID or record_id.', 'dim')}
                compare {self.colorize('- place two or more entities side by side for easier comparison.', 'dim')}
                how {self.colorize('- get a step by step replay of how an entity came together.', 'dim')}
                why {self.colorize('- see why entities or records either did or did not resolve.', 'dim')}
                tree {self.colorize("- see a tree view of an entity's relationships through 1 or 2 degrees.", 'dim')}
                export {self.colorize("- export the json records for an entity for debugging or correcting and reloading.", 'dim')}

            {self.colorize('Snapshot reports:', 'highlight2')} {self.colorize('(requires a json file created with G2Snapshot)', 'italics')}
                dataSourceSummary {self.colorize(' shows how many duplicates were detected within each data source, as well as ', 'dim')}
                {self.colorize('the possible matches and relationships that were derived. For example, how many duplicate customers ', 'dim')}
                {self.colorize('there are, and are any of them related to each other.', 'dim')}
                crossSourceSummary {self.colorize(' shows how many matches were made across data sources.  For example, how many ', 'dim')}
                {self.colorize('employees are related to customers.', 'dim')}
                entitySizeBreakdown {self.colorize(" shows how many entities of what size were created.  For instance, some entities ", 'dim')}
                {self.colorize("are singletons, some might have connected 2 records, some 3, etc.  This report is primarily used to", 'dim')}
                {self.colorize("ensure there are no instances of over matching.   For instance, its ok for an entity to have hundreds", 'dim')}
                {self.colorize("of records as long as there are not too many different names, addresses, identifiers, etc.", 'dim')}

            {self.colorize('Audit report:', 'highlight2')} {self.colorize('(requires a json file created with G2Audit)', 'italics')}
                auditSummary {self.colorize("- shows the precision, recall and F1 scores with the ability to browse the entities that", 'dim')}
                {self.colorize("were split or merged.", 'dim')}

            {self.colorize('Other commands:', 'highlight2')}
                quickLook {self.colorize("- show the number of records in the repository by data source without a snapshot.", 'dim')}
                load {self.colorize("- load a snapshot or audit report json file.", 'dim')}
                score {self.colorize("- show the scores of any two names, addresses, identifiers, or combination thereof.", 'dim')}
                set {self.colorize("- various settings affecting how entities are displayed.", 'dim')}

            {self.colorize('Senzing Knowledge Center:', 'dim')} {self.colorize('https://senzing.zendesk.com/hc/en-us', 'highlight2, underline')}
            {self.colorize('Senzing Support Request:', 'dim')} {self.colorize('https://senzing.zendesk.com/hc/en-us/requests/new', 'highlight2, underline')}

             """
                )
            )
        else:
            cmd.Cmd.do_help(self, help_topic)

    # ---------------------------
    def help_knowledgeCenter(self):
        print(
            f"\nSenzing Knowledge Center: {self.colorize('https://senzing.zendesk.com/hc/en-us', 'highlight2, underline')}\n"
        )

    # ---------------------------
    def help_support(self):
        print(
            f"\nSenzing Support Request: {self.colorize('https://senzing.zendesk.com/hc/en-us/requests/new', 'highlight2, underline')}\n"
        )

    # ---------------------------
    # TODO - Ant - Use from helpers
    def histCheck(self):

        self.history_file_name = f"{os.path.expanduser("~")}{os.path.sep}.sz_explorer_history"
        self.hist_disable = args.hist_disable

        self.histFileError = None
        self.histAvail = False

        if not self.hist_disable:

            if readline:

                # Try and open history in users home first for longevity
                try:
                    open(self.history_file_name, "a").close()
                except IOError as e:
                    self.histFileError = f"{e} - Couldn't use home, trying /tmp/..."

                # Can't use users home, try using /tmp/ for history useful at least in the session
                if self.histFileError:

                    self.history_file_name = f"/tmp/{tmpHist}"
                    try:
                        open(self.history_file_name, "a").close()
                    except IOError as e:
                        self.histFileError = f"{e} - User home dir and /tmp/ failed!"
                        return

                hist_size = 2000
                readline.read_history_file(self.history_file_name)
                readline.set_history_length(hist_size)
                atexit.register(readline.set_history_length, hist_size)
                atexit.register(readline.write_history_file, self.history_file_name)

                self.history_file_name = self.history_file_name
                self.histFileError = None
                self.histAvail = True

    # ---------------------------
    # TODO - Ant - Use from helpers
    def do_history(self, arg):

        if self.histAvail:
            print()
            for i in range(readline.get_current_history_length()):
                print(readline.get_history_item(i + 1))
            print()
        else:
            print_message("History isn't available in this session", "warning")

    # ---------------------------
    # TODO - Ant - Use from helpers
    def do_shell(self, line):
        """\nRun OS shell commands: !<command>\n"""
        if line:
            output = os.popen(line).read()
            print(f"\n{output}\n")

    # ---------------------------
    def help_set(self):
        print(
            textwrap.dedent(
                f"""\

        {self.colorize('Syntax:', 'highlight2')}
            set <setting> <value>

        {self.colorize('settings:', 'highlight2')} 
        """
            )
        )

        print(self.colorize(f"    {'setting':<23} {'[possible values]':<22} {'current':<13} {'description'}", "dim"))
        for setting_data in self.configurable_settings_list:
            current_value = self.colorize(self.current_settings[setting_data["setting"]], "bold")
            print(
                f"    {setting_data['setting']:<23} {'[' + ', '.join(setting_data['values']) + ']':<22} {current_value:<22} {self.colorize(setting_data['description'], 'dim')}"
            )
        print()

    # ---------------------------
    def complete_set(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        arg = line[before_arg + 1 : endidx]
        possibles = []
        spaces = line.count(" ")
        if spaces <= 1:
            possibles = [x["setting"] for x in self.configurable_settings_list]
        elif spaces == 2:
            setting = line.split()[1]
            for setting_data in self.configurable_settings_list:
                if setting_data["setting"] == setting:
                    possibles = setting_data["values"]
        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_set(self, arg):
        if not arg:
            self.help_set()
            return

        settings_dict = {}
        for setting_data in self.configurable_settings_list:
            settings_dict[setting_data["setting"]] = setting_data["values"]

        if settings_dict:
            arg_list = arg.split()
            if (
                len(arg_list) != 2
                or (arg_list[0] not in settings_dict)
                or (arg_list[1] not in settings_dict[arg_list[0]])
            ):
                print_message("Invalid setting", "error")
                return

        self.current_settings[arg_list[0]] = arg_list[1]
        if arg_list[0] == "color_scheme":
            Colors.set_theme(arg_list[1])

    # ---------------------------
    def do_version(self, arg):
        api_version = sz_pretty.get_api_version()
        print(f"\nSenzing api version is: {api_version['BUILD_VERSION']}\n")

    # ---------------------------
    def help_load(self):
        print(
            textwrap.dedent(
                f"""\

        {self.colorize('Syntax:', 'highlight2')}
            load <snapshotFile.json>  {self.colorize('loads a snapshot file for review', 'dim')}
            load <auditFile.json>     {self.colorize('loads an audit file for review', 'dim')}

        """
            )
        )

    # ---------------------------
    def do_load(self, arg):
        statpack_file_name = arg
        if not os.path.exists(statpack_file_name):
            print_message(f"{statpack_file_name} not found!", "error")
            return
        try:
            json_data = json.load(open(statpack_file_name))
        except Exception as ex:
            print_message(f"{stat_pack_file_name}: {ex}", "error")
            return
        if json_data.get("SOURCE", "unknown") == "sz_snapshot":
            self.current_settings["snapshot_json_file"] = statpack_file_name
            self.snapshot_file = statpack_file_name
            self.snapshot_data = json_data

        elif json_data.get("SOURCE", "unknown") == "sz_audit":
            self.current_settings["audit_json_file"] = statpack_file_name
            self.audit_file = statpack_file_name
            self.audit_data = json_data
        else:
            print_message(f"{statpack_file_name} not created by sz_snapshot or sz_audit", "error")
            return
        print_message(f"successfully loaded {statpack_file_name}", "info")

    # ---------------------------
    def complete_load(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        if before_arg == -1:
            return  # arg not found
        fixed = line[before_arg + 1 : begidx]  # fixed portion of the arg
        arg = line[before_arg + 1 : endidx]
        pattern = arg + "*"
        completions = []
        for path in glob.glob(pattern):
            path = _append_slash_if_dir(path)
            completions.append(path.replace(fixed, "", 1))
        return completions

    # ---------------------------
    def help_quickLook(self):
        print("\nDisplays current data source stats without a snapshot\n")

    # ---------------------------
    def do_quickLook(self, arg):
        if not sz_dbo:
            print_message(f"Direct database access is required, database drivers must be installed", "error")
            return
        tbl_title = "Data source counts"
        tbl_columns = [
            {"name": "id", "width": 5, "align": "center"},
            {"name": "DataSource", "width": 30, "align": "left"},
            {"name": "ActualRecordCount", "width": 20, "align": "right"},
            {"name": "DistinctRecordCount", "width": 20, "align": "right"},
        ]
        sql = """
              select DSRC_ID, count(*) as RECORD_COUNT, count(distinct ENT_SRC_KEY) as UNIQUE_COUNT 
              from DSRC_RECORD GROUP BY DSRC_ID
              """
        tbl_rows = []
        actual_count = distinct_count = 0
        for row in sz_dbo.fetchAllDicts(sz_dbo.sqlExec(sql)):
            tbl_rows.append(
                [
                    self.colorize(row["DSRC_ID"], "row_title"),
                    self.colorize_dsrc(self.dsrc_lookup[row["DSRC_ID"]]["DSRC_CODE"]),
                    "{:,}".format(row["RECORD_COUNT"]),
                    "{:,}".format(row["UNIQUE_COUNT"]),
                ]
            )
            actual_count += row["RECORD_COUNT"]
            distinct_count += row["UNIQUE_COUNT"]
        if len(tbl_rows) > 1:
            tbl_rows.append(
                [
                    "",
                    self.colorize("  Totals", "row_title"),
                    self.colorize("{:,}".format(actual_count), "row_title"),
                    self.colorize("{:,}".format(distinct_count), "row_title"),
                ]
            )
        self.show_report2(self.render_table2(tbl_title, tbl_columns, tbl_rows))

    # ---------------------------
    # support for reports
    # ---------------------------

    def move_pointer(self, reply, current_item, max_items):
        """moves the sample record pointer for all reports"""
        if reply.upper().startswith("P"):  # previous
            if current_item == 0:
                input("\nNo prior records, press enter to continue")
            else:
                return current_item - 1
        elif reply.upper().startswith("N"):  # next
            if current_item == max_items - 1:
                input("\nno more records, press enter to continue")
            else:
                return current_item + 1
        elif reply.upper().startswith("G"):  # goto
            reply = reply[1:]
            if not reply:
                reply = input("\nSample item number to go to? ")
                if reply:
                    remove_from_history()
            if reply:
                if reply.isnumeric() and int(reply) > 0 and int(reply) <= max_items:
                    return int(reply) - 1
                else:
                    print_message("Invalid sample item number for this sample set!", "warning")
        return current_item

    def export_report_sample(self, reply, currentRecords, fileName):
        if "TO " in reply.upper():
            fileName = reply[reply.upper().find("TO") + 2 :].strip()
        if fileName:
            self.do_export(",".join(currentRecords) + " to " + fileName)

    # ---------------------------
    # audit summary report
    # ---------------------------

    def help_auditSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays audit statistics and examples.

        {self.colorize('Syntax:', 'highlight2')}
            auditSummary                        {self.colorize('with no parameters displays the overall stats', 'dim')}
            auditSummary merge                  {self.colorize('shows a list of merge sub-categories', 'dim')}
            auditSummary merge 1                {self.colorize('shows examples of merges in sub-category 1', 'dim')}
            auditSummary split                  {self.colorize('shows a list of split sub-categories', 'dim')}
            auditSummary split 1                {self.colorize('shows examples of splits in sub-category 1', 'dim')}
            auditSummary save to <filename.csv> {self.colorize('saves the entire audit report to a csv file', 'dim')}

        """
            )
        )

    # ---------------------------
    def complete_auditSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        arg = line[before_arg + 1 : endidx]
        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.audit_data:
                for category in self.audit_data["AUDIT"]:
                    possibles.append(category)
        else:
            possibles = []
        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_auditSummary(self, arg):
        if not self.audit_data:
            print_message("Please load a json file created with sz_audit to view this report", "warning")
            return
        elif not self.audit_data["ENTITY"].get("PRIOR_COUNT"):
            print_message(
                "Prior version audit file detected.  Please review with the prior version or re-create for this one.",
                "warning",
            )
            return
        if not arg:
            self.audit_summary_stats()
        elif arg.upper().startswith("SAVE"):
            self.audit_summary_save(arg)
        else:
            self.audit_summary_category(arg)

    def audit_summary_stats(self):
        audit_categories = []
        category_order = {"MERGE": 0, "SPLIT": 1, "SPLIT+MERGE": 2}
        for category in sorted(
            self.audit_data["AUDIT"].keys(), key=lambda x: category_order[x] if x in category_order else 9
        ):
            category_color = self.audit_colors.get(category, self.audit_colors.get("unknown"))
            category_data = [
                self.colorize(category, category_color),
                self.colorize(fmt_statistic(self.audit_data["AUDIT"][category]["COUNT"]), "bold"),
            ]
            audit_categories.append(category_data)
        while len(audit_categories) < 3:
            audit_categories.append(["", 0])

        # show records or pairs
        if self.current_settings["audit_measure"] == "pairwise":
            audit_measure = "PAIRS"
            audit_header = "Pairs"
        else:
            audit_measure = "RECORDS"
            audit_header = "Matches"

        tbl_title = f"Audit Summary from {self.audit_file}"
        tbl_columns = [
            {"name": "Statistic1", "width": 25, "align": "left"},
            {"name": "Entities", "width": 25, "align": "right"},
            {"name": audit_header, "width": 25, "align": "right"},
            {"name": self.colorize("-", "invisible"), "width": 5, "align": "center"},
            {"name": "Statistic2", "width": 25, "align": "left"},
            {"name": "Accuracy", "width": 25, "align": "right"},
        ]
        tbl_rows = []
        tbl_rows.append(
            [
                self.colorize("Prior Count", "highlight2"),
                fmt_statistic(self.audit_data["ENTITY"].get("PRIOR_COUNT", -1)),
                fmt_statistic(self.audit_data[audit_measure].get("PRIOR_COUNT", -1)),
                "",
                self.colorize("Same Positives", "highlight2"),
                self.colorize(fmt_statistic(self.audit_data[audit_measure]["SAME_POSITIVE"]), None),
            ]
        )
        tbl_rows.append(
            [
                self.colorize("Newer Count", "highlight2"),
                fmt_statistic(self.audit_data["ENTITY"].get("NEWER_COUNT", -1)),
                fmt_statistic(self.audit_data[audit_measure].get("NEWER_COUNT", -1)),
                "",
                self.colorize("New Positives", self.audit_colors["MERGE"]),
                self.colorize(fmt_statistic(self.audit_data[audit_measure]["NEW_POSITIVE"]), None),
            ]
        )
        tbl_rows.append(
            [
                self.colorize("Common Count", "highlight2"),
                fmt_statistic(self.audit_data["ENTITY"].get("COMMON_COUNT", -1)),
                fmt_statistic(self.audit_data[audit_measure].get("COMMON_COUNT", -1)),
                "",
                self.colorize("New Negatives", self.audit_colors["SPLIT"]),
                self.colorize(fmt_statistic(self.audit_data[audit_measure]["NEW_NEGATIVE"]), None),
            ]
        )
        tbl_rows.append(
            [
                audit_categories[0][0],
                audit_categories[0][1],
                "",
                "",
                self.colorize("Precision", "highlight2"),
                self.colorize(self.audit_data[audit_measure]["PRECISION"], None),
            ]
        )
        tbl_rows.append(
            [
                audit_categories[1][0],
                audit_categories[1][1],
                "",
                "",
                self.colorize("Recall", "highlight2"),
                self.colorize(self.audit_data[audit_measure]["RECALL"], None),
            ]
        )
        tbl_rows.append(
            [
                audit_categories[2][0],
                audit_categories[2][1],
                "",
                "",
                self.colorize("F1 Score", "highlight2"),
                self.colorize(self.audit_data[audit_measure]["F1-SCORE"], None),
            ]
        )
        # add any extra categories (which will occur if there were missing records)
        if len(audit_categories) > 3:
            i = 3
            while i < len(audit_categories):
                tbl_rows.append([audit_categories[i][0], audit_categories[i][1], "", "", "", ""])
                i += 1
        self.render_table(tbl_title, tbl_columns, tbl_rows)

    def audit_summary_save(self, arg):
        if not " " in arg:
            print_message("Please specify a file name and path", "error")
            return
        file_name = arg.split()[-1]

        file_headers = ["category", "sub_category", "audit_id"]
        file_rows = []
        row_cnt = 0
        for category in self.audit_data["AUDIT"]:
            for sub_category in self.audit_data["AUDIT"][category]["SUB_CATEGORY"]:
                for sample_records in self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["SAMPLE"]:
                    table_columns, table_data = self.showAuditSample(sample_records, False)
                    record_headers = []
                    for column_dict in table_columns:
                        column_name = column_dict["name"].lower()
                        if column_name not in record_headers:
                            record_headers.append(column_name)
                        if column_name not in file_headers:
                            file_headers.append(column_name)
                    for record_data in table_data:
                        row_data = dict(zip(record_headers, record_data))
                        row_data["category"] = category
                        row_data["sub_category"] = sub_category
                        row_data["audit_id"] = sample_records[0]["audit_id"]
                        file_rows.append(row_data)
                        row_cnt += 1
                        if row_cnt % 1000 == 0:
                            print(f"{row_cnt} records processed")

        with open(file_name, "w", encoding="utf-8") as f:
            w = csv.DictWriter(f, file_headers, dialect=csv.excel, quoting=csv.QUOTE_ALL)
            w.writeheader()
            w.writerows(file_rows)
        print_message(f"{row_cnt} records written to {file_name}!", "success")

    def audit_summary_category(self, arg):
        arg_list = arg.upper().split()
        if arg_list[0] not in self.audit_data["AUDIT"]:
            print_message(f"{arg} not found, please choose a valid split or merge category", "error")
            return

        category = arg_list[0]
        category_color = self.audit_colors.get(category, self.audit_colors.get("unknown"))
        i = 0
        sub_category_list = []
        for sub_category in sorted(
            self.audit_data["AUDIT"][category]["SUB_CATEGORY"],
            key=lambda x: self.audit_data["AUDIT"][category]["SUB_CATEGORY"][x]["COUNT"],
            reverse=True,
        ):

            i += 1
            if i <= 10:
                sub_category_list.append(
                    {
                        "INDEX": i,
                        "NAME": sub_category,
                        "LIST": [sub_category],
                        "COUNT": self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["COUNT"],
                    }
                )
            elif i == 11:
                sub_category_list.append(
                    {
                        "INDEX": i,
                        "NAME": "OTHERS",
                        "LIST": [sub_category],
                        "COUNT": self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["COUNT"],
                    }
                )
            else:
                sub_category_list[10]["LIST"].append(sub_category)
                sub_category_list[10]["COUNT"] += self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category][
                    "COUNT"
                ]

        if len(arg_list) == 1:
            tbl_title = category + " Categories"
            tbl_columns = [
                {"name": "Index", "width": 10, "align": "center"},
                {"name": "Category", "width": 25, "align": "left"},
                {"name": "Sub-category", "width": 75, "align": "left"},
                {"name": "Count", "width": 25, "align": "right"},
            ]
            tbl_rows = []
            for sub_category_row in sub_category_list:
                tbl_rows.append(
                    [
                        self.colorize(sub_category_row["INDEX"], "row_title"),
                        self.colorize(category, category_color),
                        sub_category_row["NAME"],
                        fmt_statistic(sub_category_row["COUNT"]),
                    ]
                )
            self.render_table(tbl_title, tbl_columns, tbl_rows)
            return

        # find the detail records to display
        index_categories = []
        if arg_list[1].isdigit():
            for sub_category_row in sub_category_list:
                if sub_category_row["INDEX"] == int(arg_list[1]):
                    index_categories = sub_category_row["LIST"]
                    break
        if not index_categories:
            print_message(f"Invalid subcategory for {arg_list[0].lower()}", "error")
            return

        sample_records = []
        for sub_category in self.audit_data["AUDIT"][category]["SUB_CATEGORY"]:
            if sub_category in index_categories:
                sample_records += self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["SAMPLE"]

        current_sample = 0
        while True:
            current_records = list(set([x["newer_id"] for x in sample_records[current_sample]]))
            self.current_review_list = f"Item {current_sample + 1} of {len(sample_records)} for {arg_list[0]} category {arg_list[1]} - {sub_category_row['NAME']}"
            self.showAuditSample(sample_records[current_sample], self.audit_colors)
            while True:
                if len(current_records) == 1:
                    reply = input(
                        self.colorize_prompt(
                            "Select (P)revious, (N)ext, (G)oto, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ... "
                        )
                    )
                    special_actions = "HWE"
                else:
                    reply = input(
                        self.colorize_prompt(
                            "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ... "
                        )
                    )
                    special_actions = "WE"
                if reply:
                    remove_from_history()
                else:
                    reply = "N"
                if reply.upper().startswith("Q"):
                    break
                elif reply.upper() == ("S"):
                    self.do_scroll("")
                elif reply.upper()[0] in "PNG":  # previous, next, goto
                    current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                    break
                elif reply.upper()[0] in special_actions:
                    if reply.upper().startswith("W2"):
                        self.do_why(",".join(current_records) + " old")
                    elif reply.upper().startswith("W"):
                        self.do_why(",".join(current_records))
                    elif reply.upper().startswith("H"):
                        self.do_how(",".join(current_records))
                        break
                    elif reply.upper().startswith("E"):
                        self.export_report_sample(
                            reply, current_records, f"auditSample-{sample_records[current_sample][0]['audit_id']}.json"
                        )
            if reply.upper().startswith("Q"):
                break
        self.current_review_list = None

    # ---------------------------
    def showAuditSample(self, arg, use_color=True):
        audit_records = arg
        entity_list = list(set([x["newer_id"] for x in audit_records]))
        get_flag_list = ["SZ_ENTITY_INCLUDE_ALL_FEATURES", "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS"]
        ftypes_used = []
        record_list = []
        entity_list = set([x["newer_id"] for x in audit_records])
        for entity_id in entity_list:
            if entity_id == "unknown":  # bypass missing
                continue
            try:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                continue

            entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            for record in json_data["RESOLVED_ENTITY"]["RECORDS"]:
                record["FEATURES_BY_TYPE"] = self.get_record_features(entity_features, record["FEATURES"])["BY_TYPE"]
                record_list.append(record)
                ftypes_used.extend(list(record["FEATURES_BY_TYPE"].keys()))
        ftypes_used = sorted(set(ftypes_used))

        tbl_title = f'Audit Result ID {audit_records[0]["audit_id"]} {audit_records[0]["audit_category"]}'
        tbl_columns = [
            {"name": "DataSource", "width": 30, "align": "left"},
            {"name": "Record ID", "width": 30, "align": "left"},
            {"name": "Prior ID", "width": 20, "align": "left"},
            {"name": "Prior Score", "width": 75, "align": "left"},
            {"name": "Newer ID", "width": 20, "align": "left"},
            {"name": "Newer Score", "width": 75, "align": "left"},
            {"name": "Audit result", "width": 10, "align": "left"},
        ]
        for ftype_id in ftypes_used:
            ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
            tbl_columns.append({"name": ftype_code, "width": 50, "align": "left"})

        sort_order = {"same": 1, "new negative": 3, "new positive": 2, "missing": 4}
        local_colors = {
            "DSRC_COLOR": "dsrc_color" if use_color else None,
            "ENTITY_COLOR": "entity_color" if use_color else None,
            "NEW POSITIVE": self.audit_colors["MERGE"] if use_color else None,
            "NEW NEGATIVE": self.audit_colors["SPLIT"] if use_color else None,
            "MISSING": self.audit_colors["unknown"] if use_color else None,
        }

        tbl_rows = []
        for audit_record in sorted(
            audit_records, key=lambda k: [sort_order[k["audit_result"]], str(k["prior_id"]), k["newer_id"]]
        ):
            result_color = local_colors.get(audit_record["audit_result"].upper(), "bold") if use_color else None
            row = [
                self.colorize(audit_record.get("data_source", ""), local_colors["DSRC_COLOR"]),
                audit_record["record_id"],
                audit_record["prior_id"],
                audit_record["prior_score"],
                self.colorize(audit_record["newer_id"], local_colors["ENTITY_COLOR"]),
                audit_record["newer_score"],
                self.colorize(audit_record["audit_result"], result_color),
            ]

            if audit_record.get("DATA_SOURCE"):
                matching_records = [
                    x
                    for x in record_list
                    if x["RECORD_ID"] == audit_record["record_id"] and x["DATA_SOURCE"] == audit_record["data_source"]
                ]
            else:
                matching_records = [x for x in record_list if x["RECORD_ID"] == audit_record["record_id"]]
            matching_features = matching_records[0]["FEATURES_BY_TYPE"] if len(matching_records) == 1 else {}

            for ftype_id in ftypes_used:
                if matching_features.get(ftype_id):
                    row.append("\n".join([x["FEAT_DESC"] for x in matching_features[ftype_id]]))
                else:
                    row.append("")
            tbl_rows.append(row)

        if not use_color:  # if exporting report
            return tbl_columns, tbl_rows
        self.render_table(tbl_title, tbl_columns, tbl_rows)

    # ---------------------------
    def help_entitySizeBreakdown(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the number of entities by how many records they contain.

        {self.colorize('Syntax:', 'highlight2')}
            entitySizeBreakdown                    {self.colorize('with no parameters displays the overall stats', 'dim')}
            entitySizeBreakdown = 3                {self.colorize('use =, > or < # to select examples of entities of a certain size', 'dim')}
            entitySizeBreakdown > 10 review        {self.colorize('to just browse the review items of entities greater than size 10', 'dim')}
            entitySizeBreakdown = review name+addr {self.colorize('to just browse the name+addr review items of any size', 'dim')}

        {self.colorize('review items:', 'highlight2')}
            Review items are suggestions of records to look at because they contain multiple names, addresses, dobs, etc.
            They may be overmatches or they may just be large entities with lots of values.

        """
            )
        )

    # ---------------------------
    def do_entitySizeBreakdown(self, arg):

        if not self.snapshot_data:
            print_message("Please load a json file created with sz_snaphot to access this report", "warning")
            return
        if not self.snapshot_data.get("ENTITY_SIZE_BREAKDOWN"):
            self.compute_entitySizeBreakdown()

        if not arg:
            tbl_title = "Entity Size Breakdown from %s" % self.snapshot_file
            tbl_columns = []
            tbl_columns.append({"name": "Entity Size", "width": 10, "align": "center"})
            tbl_columns.append({"name": "Entity Count", "width": 10, "align": "center"})
            tbl_columns.append({"name": "Review Count", "width": 10, "align": "center"})
            tbl_columns.append({"name": "Review Features", "width": 75, "align": "left"})
            tbl_rows = []
            for entity_size_data in sorted(
                self.snapshot_data["ENTITY_SIZE_BREAKDOWN"], key=lambda k: k["ENTITY_SIZE"], reverse=True
            ):
                row = []
                row.append(self.colorize(entity_size_data["ENTITY_SIZE_GROUP"], "row_title"))
                row.append(fmt_statistic(entity_size_data["ENTITY_COUNT"]))
                row.append(fmt_statistic(entity_size_data["REVIEW_COUNT"]))
                row.append(" | ".join(self.colorize(x, "caution") for x in sorted(entity_size_data["REVIEW_FEATURES"])))
                tbl_rows.append(row)
            self.render_table(tbl_title, tbl_columns, tbl_rows)

        else:
            sign = "="
            size = 0
            review_tag = False
            review_features = []
            arg_list = arg.split()
            for token in arg_list:
                if token[0:2] in (">=", "<="):
                    sign = token[0:2]
                    if len(token) > 2 and token[2:].isnumeric():
                        size = int(token[2:])
                elif token[0:1] in (">", "<", "="):
                    sign = token[0:1]
                    if len(token) > 1 and token[1:].isnumeric():
                        size = int(token[1:])
                elif token.isnumeric():
                    size = int(token)
                elif token.upper() == "REVIEW":
                    review_tag = True
                else:
                    review_features.append(token.upper())
            if not size:
                size = 1
                sign = ">"

            sample_records = []
            for entity_size_data in self.snapshot_data["ENTITY_SIZE_BREAKDOWN"]:
                if sign in ("=", ">=", "<=") and entity_size_data["ENTITY_SIZE"] == size:
                    these_records = entity_size_data["SAMPLE_ENTITIES"]
                elif sign in ("<", "<=") and entity_size_data["ENTITY_SIZE"] <= size:
                    these_records = entity_size_data["SAMPLE_ENTITIES"]
                elif sign in (">", ">=") and entity_size_data["ENTITY_SIZE"] >= size:
                    these_records = entity_size_data["SAMPLE_ENTITIES"]
                else:
                    continue

                if review_tag or review_features:
                    review_records = []
                    for entity_info in these_records:
                        if "REVIEW_FEATURES" not in entity_info:
                            continue
                        if review_features:
                            review_criteria_not_met = False
                            for ftype_code in review_features:
                                if ftype_code not in entity_info["REVIEW_FEATURES"]:
                                    review_criteria_not_met = True
                                    break
                            if review_criteria_not_met:
                                continue
                        review_records.append(entity_info)
                    these_records = review_records

                sample_records.extend(these_records)

            if len(sample_records) == 0:
                print_message("No records found", "warning")
            else:

                current_sample = 0
                while True:
                    self.current_review_list = f"Item {current_sample + 1} of {len(sample_records)} for Entity Size {sample_records[current_sample]['ENTITY_SIZE']}"
                    if "REVIEW_FEATURES" in sample_records[current_sample]:
                        review_items = []
                        for ftype_code in sample_records[current_sample]["REVIEW_FEATURES"]:
                            review_items.append(f"{ftype_code} ({sample_records[current_sample][ftype_code]})")
                        self.current_review_list += ", review for: " + ", ".join(review_items)

                    current_records = [str(sample_records[current_sample]["ENTITY_ID"])]
                    return_code = self.do_get(current_records[0])
                    if return_code != 0:
                        print_message("This entity no longer exists", "error")
                    while True:
                        reply = input(
                            self.colorize_prompt(
                                "Select (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                            )
                        )
                        if reply:
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply.upper().startswith("Q"):
                            break
                        elif reply.upper() == ("S"):
                            self.do_scroll("")
                        elif reply.upper()[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply.upper()[0] in "DHWE":
                            if reply.upper().startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply.upper().startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply.upper().startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply.upper().startswith("E"):
                                self.export_report_sample(reply, current_records, f"{'-'.join(current_records)}.json")
                    if reply.upper().startswith("Q"):
                        break
                self.current_review_list = None

    # ---------------------------
    def compute_entitySizeBreakdown(self):
        print_message("Reviewing examples ...", "info")
        esb_data = {}
        for str_entity_size in sorted(self.snapshot_data["TEMP_ESB_STATS"].keys()):
            entity_size = int(str_entity_size)
            if entity_size <= 3:  # super small
                max_exclusive_cnt = 1
                max_name_cnt = 2
                max_addr_cnt = 2
            elif entity_size <= 10:  # small
                max_exclusive_cnt = 1
                max_name_cnt = 3
                max_addr_cnt = 3
            elif entity_size <= 50:  # medium
                max_exclusive_cnt = 1
                max_name_cnt = 10
                max_addr_cnt = 10
            else:  # large
                max_exclusive_cnt = 1  # large
                max_name_cnt = 25
                max_addr_cnt = 25

            # setup for the entity size
            if entity_size < 10:
                entity_size_level = entity_size
            elif entity_size < 100:
                entity_size_level = int(entity_size / 10) * 10
            else:
                entity_size_level = int(entity_size / 100) * 100
            if entity_size_level not in esb_data:
                esb_data[entity_size_level] = {
                    "ENTITY_COUNT": 0,
                    "SAMPLE_ENTITIES": [],
                    "REVIEW_COUNT": 0,
                    "REVIEW_FEATURES": [],
                }
            esb_data[entity_size_level]["ENTITY_COUNT"] += self.snapshot_data["TEMP_ESB_STATS"][str_entity_size][
                "COUNT"
            ]

            # review each entity
            for sample_record in self.snapshot_data["TEMP_ESB_STATS"][str_entity_size]["SAMPLE"]:
                review_features = []
                for raw_attr in sample_record.keys():
                    if raw_attr in ("ENTITY_ID", "ENTITY_SIZE"):
                        continue
                    ftype_code = raw_attr
                    ftype_excl = self.ftype_code_lookup[ftype_code]["FTYPE_EXCL"]
                    distinct_feature_count = sample_record[ftype_code]
                    if ftype_code == "NAME" and distinct_feature_count > max_name_cnt:
                        review_features.append(ftype_code)
                    elif ftype_code == "ADDRESS" and distinct_feature_count > max_addr_cnt:
                        review_features.append(ftype_code)
                    elif ftype_excl == "Yes" and distinct_feature_count > max_exclusive_cnt:
                        review_features.append(ftype_code)
                if review_features:
                    sample_record["REVIEW_FEATURES"] = review_features
                    esb_data[entity_size_level]["REVIEW_FEATURES"] = list(
                        set(esb_data[entity_size_level]["REVIEW_FEATURES"] + review_features)
                    )
                    esb_data[entity_size_level]["REVIEW_COUNT"] += 1
                esb_data[entity_size_level]["SAMPLE_ENTITIES"].append(sample_record)

        self.snapshot_data["ENTITY_SIZE_BREAKDOWN"] = []
        for entity_size_level in sorted(esb_data.keys()):
            entity_size_record = esb_data[entity_size_level]
            entity_size_record["ENTITY_SIZE"] = entity_size_level
            entity_size_record["ENTITY_SIZE_GROUP"] = str(entity_size_level) + (
                "+" if int(entity_size_level) >= 10 else ""
            )
            self.snapshot_data["ENTITY_SIZE_BREAKDOWN"].append(entity_size_record)

        try:
            with open(self.snapshot_file, "w", encoding="utf-8") as f:
                json.dump(self.snapshot_data, f)
        except IOError as err:
            print_message(f"{err} writing to {self.snapshot_file}", "error")

    # ---------------------------
    def help_multiSourceSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the different match levels within each data source.

        {self.colorize('Syntax:', 'highlight2')}
            multiSourceSummary                               {self.colorize('with no parameters displays all the combinations', 'dim')}
            multiSourceSummary <dataSourceCode>              {self.colorize('displays the stats for a particular data source', 'dim')}
        """
            )
        )

    # ---------------------------
    def complete_multSourceSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        # if before_arg == -1:
        #    return # arg not found

        arg = line[before_arg + 1 : endidx]

        possibles = []
        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    # TODO - Ant - Auto complete doesn't work for data source
    def do_multiSourceSummary(self, arg):
        if not self.snapshot_data or not self.snapshot_data.get("MULTI_SOURCE"):
            print_message(
                "Please create a new snapshot with the latest G2Snapshot.py to access this report",
                "error",
            )
            return
        if len(self.snapshot_data["MULTI_SOURCE"]) == 0:
            print_message("No multi-source entities exist!", "warning")
            return

        filter_str = arg
        while True:
            filter_display = f', filtered for "{filter_str}"' if filter_str else ""
            tbl_title = f"Multi Source Summary from {self.snapshot_file}{filter_display}"
            tbl_columns = []
            tbl_columns.append({"name": "Index", "width": 5, "align": "center"})
            tbl_columns.append({"name": "Data Sources", "width": 100, "align": "left"})
            tbl_columns.append({"name": "Records", "width": 15, "align": "right"})

            report_rows = []
            for data_sources_list in sorted(self.snapshot_data["MULTI_SOURCE"]):
                if filter_str and filter_str.upper() not in data_sources_list:
                    continue
                report_rows.append(
                    [
                        data_sources_list,
                        self.snapshot_data["MULTI_SOURCE"][data_sources_list]["COUNT"],
                        self.snapshot_data["MULTI_SOURCE"][data_sources_list]["SAMPLE"],
                    ]
                )
            if not report_rows:
                print_message(f"No records found for {filter_str}", "error")
                input("press any key to continue ... ")
                filter_str = None
                continue

            report_rows = sorted(report_rows, key=lambda k: k[1], reverse=True)
            tbl_rows = []
            for row in report_rows:
                tbl_rows.append(
                    [
                        len(tbl_rows) + 1,
                        self.colorize(" | ", "dim").join(self.colorize_dsrc(x) for x in row[0].split("|")),
                        fmt_statistic(row[1]),
                    ]
                )

            self.render_table(tbl_title, tbl_columns, tbl_rows)

            sample_records = None
            prompt = self.colorize_prompt("Select Index # to review, data source filter expression, (Q)uit ... ")
            reply = input(prompt)
            if reply:
                remove_from_history()
                if reply.upper().startswith("Q"):
                    return
                if reply.isdigit() and int(reply) > 0 and int(reply) <= len(tbl_rows):
                    data_sources_list = tbl_rows[int(reply) - 1][1]
                    sample_records = report_rows[int(reply) - 1][2]

                else:
                    filter_str = reply.upper()
            else:
                filter_str = None

            if not sample_records:
                continue

            current_sample = 0
            while True:
                self.current_review_list = (
                    f"Sample {current_sample + 1} of {len(sample_records)} for {data_sources_list}"
                )
                current_records = str(sample_records[current_sample]).split()
                return_code = self.do_get(str(sample_records[current_sample]))
                if return_code != 0:
                    print_message("This entity no longer exists", "error")

                while True:
                    reply = input(
                        self.colorize_prompt(
                            "Select (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                        )
                    )
                    special_actions = "DHWE"
                    if reply:
                        remove_from_history()
                    else:
                        reply = "N"

                    if reply.upper().startswith("Q"):
                        break
                    elif reply.upper() == "S":
                        self.do_scroll("")
                    elif reply.upper()[0] in "PNG":  # previous, next, goto
                        current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                        break
                    elif reply.upper()[0] in special_actions:
                        if reply.upper().startswith("D"):
                            self.do_get("detail " + ",".join(current_records))
                        elif reply.upper().startswith("W"):
                            self.do_why(",".join(current_records))
                        elif reply.upper().startswith("H"):
                            self.do_how(",".join(current_records))
                            break
                        elif reply.upper().startswith("E"):
                            self.export_report_sample(
                                reply,
                                current_records,
                                f"{'-'.join(current_records)}.json",
                            )

                if reply.upper().startswith("Q"):
                    break

            self.current_review_list = None

    # ---------------------------
    def select_matching_category(self, principle_data, prior_header):
        all_rows = []
        for principle in principle_data.keys():
            for match_key in principle_data[principle].keys():
                all_rows.append(
                    [
                        principle,
                        match_key,
                        principle_data[principle][match_key]["COUNT"],
                        principle_data[principle][match_key]["SAMPLE"],
                    ]
                )
        max_rows = 10
        filter_str = None
        while True:
            cnt = 0
            report_rows = []
            for row in sorted(all_rows, key=lambda k: k[2], reverse=True):
                if filter_str and filter_str not in str([row[0].upper(), row[1].upper()]):
                    continue
                if cnt < max_rows or not max_rows:
                    cnt += 1
                    report_rows.append([cnt] + row)
                else:
                    report_rows[-1][1] = "remaining principles"
                    report_rows[-1][2] = "remaining match keys"
                    report_rows[-1][3] += row[2]
                    report_rows[-1][4].extend(row[3])

            filter_display = f', filtered for "{filter_str}"' if filter_str else ""
            tbl_title = f"{prior_header}{filter_display}"
            tbl_columns = []
            tbl_columns.append({"name": "Index", "width": 5, "align": "center"})
            tbl_columns.append({"name": "Match key", "width": 50, "align": "left"})
            tbl_columns.append({"name": "Count", "width": 10, "align": "right"})
            tbl_rows = []
            for row in report_rows:
                if row[1] != "remaining principles":
                    color_match_key = self.colorize_match_data({"matchKey": row[2], "ruleCode": row[1]})
                else:
                    color_match_key = f"{len(all_rows)-max_rows} more match keys"
                tbl_rows.append([row[0], color_match_key, fmt_statistic(row[3])])

            self.render_table(tbl_title, tbl_columns, tbl_rows)
            if len(report_rows) < len(all_rows):
                prompt = self.colorize_prompt(
                    "Select Index # to review, show (A)ll matchkeys, matchkey filter expression, (Q)uit... "
                )
            else:
                prompt = self.colorize_prompt("Select Index # to review, matchkey filter expression, (Q)uit ... ")
            reply = input(prompt)
            if reply:
                remove_from_history()
                if reply.upper() in ("Q", "QUIT"):
                    return None
                if reply.isdigit() and int(reply) > 0 and int(reply) <= len(tbl_rows):
                    return report_rows[int(reply) - 1]
                if reply.upper() == "A":
                    max_rows = 0
                    filter_str = None
                else:
                    filter_str = reply.upper()
            # else:
            #    filter_str = None

    # ---------------------------
    # TODO - Ant - Fix help for 100/principle name
    # TODO - Ant - If rule code/name used and not found improve help to say not found, it's
    # TODO confusing to say invalid
    def help_principlesUsed(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the principles used.

        {self.colorize('Syntax:', 'highlight2')}
            principlesUsed                    {self.colorize('with no parameters displays the stats by category', 'dim')}
            principlesUsed <category>         {self.colorize('displays the matchkey stats for a certain category such as match, possible_match, etc', 'dim')}
            principlesUsed principles         {self.colorize('displays the stats for all principles', 'dim')}
            principlesUsed 100                {self.colorize('displays the matchkey stats for a certain rule', 'dim')}

        """
            )
        )

    # ---------------------------
    # TODO - Ant - Fix
    def complete_principlesUsed(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        # if before_arg == -1:
        #    return # arg not found

        arg = line[before_arg + 1 : endidx]

        possibles = list(self.match_category_sort.keys())
        possibles.append("PRINCIPLES")
        if hasattr(self, "statsByPrinciple"):
            # TODO - Ant - statsByPrinciples not defined
            possibles.extend(list(statsByPrinciple.keys()))

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_principlesUsed(self, arg: str) -> None:

        arg_upper = arg.upper().strip() if arg else arg

        if not self.snapshot_data or not self.snapshot_data.get("PRINCIPLES_USED"):
            # TODO - Ant - sz_snapshot for V4
            print_message(
                "Please create a new snapshot with the latest G2Snapshot.py to access this report",
                "error",
            )
            return

        self.audit_colors = {
            "MATCH": "MATCH",
            "POSSIBLE_MATCH": "POSSIBLE",
            "AMBIGUOUS_MATCH": "AMBIGUOUS",
            "POSSIBLY_RELATED": "RELATED",
            "DISCLOSED_RELATION": "DISCLOSED",
        }

        principles_by_id = {}
        principles_by_name = {}
        stats_by_category = {}
        stats_by_principle = {}

        # , key=lambda k: self.categorySortOrder[k]):
        # TODO - Ant - Why doing this happen every time called?
        for category in self.snapshot_data["PRINCIPLES_USED"].keys():
            if category not in stats_by_category:
                stats_by_category[category] = {"COUNT": 0}

            for principle in self.snapshot_data["PRINCIPLES_USED"][category].keys():
                stats_by_principle[principle] = {"COUNT": 0, "CATEGORY": category}
                ppart = principle.partition(":")
                # Build lookup dicts to enable using either a principle ID or name
                # principle can contain just 'DISCLOSURE with no ID, usually:
                # '120: SF1_PNAME_CSTAB'
                # If there is no : to split on, DISCLOSE is in ppart[0]
                if not ppart[1] and not ppart[2]:
                    principles_by_name[ppart[0]] = -1
                    principles_by_id[-1] = ppart[0]
                else:
                    principles_by_name[ppart[2].strip()] = ppart[0]
                    principles_by_id[ppart[0]] = ppart[2].strip()

                for matchkey in self.snapshot_data["PRINCIPLES_USED"][category][principle].keys():
                    stats_by_category[category]["COUNT"] += self.snapshot_data["PRINCIPLES_USED"][category][principle][
                        matchkey
                    ]["COUNT"]
                    stats_by_principle[principle]["COUNT"] += self.snapshot_data["PRINCIPLES_USED"][category][
                        principle
                    ][matchkey]["COUNT"]

        report_data = ""
        if not arg:
            tbl_columns = []
            tbl_rows = []
            tbl_title = f"Principles Used Report from {self.snapshot_file}"
            tbl_columns.append({"name": "Category", "width": 25, "align": "left"})
            tbl_columns.append({"name": "Count", "width": 25, "align": "right"})
            for category in sorted(stats_by_category.keys(), key=lambda k: self.match_category_sort[k]):
                tbl_rows.append(
                    [
                        self.colorize(category, self.audit_colors[category]),
                        fmt_statistic(stats_by_category[category]["COUNT"]),
                    ]
                )
            self.render_table(tbl_title, tbl_columns, tbl_rows)

        elif arg_upper.startswith("PRIN"):
            tbl_columns = []
            tbl_rows = []
            tbl_title = f"Principles Used Report from {self.snapshot_file}"
            tbl_columns.append({"name": "Principle", "width": 50, "align": "left"})
            tbl_columns.append({"name": "Category", "width": 25, "align": "left"})
            tbl_columns.append({"name": "Count", "width": 25, "align": "right"})
            for principle in sorted(stats_by_principle.keys()):
                category = stats_by_principle[principle]["CATEGORY"]
                tbl_rows.append(
                    [
                        self.colorize(principle, self.audit_colors[category]),
                        self.colorize(category, self.audit_colors[category]),
                        fmt_statistic(stats_by_principle[principle]["COUNT"]),
                    ]
                )
            self.render_table(tbl_title, tbl_columns, tbl_rows)

        # TODO - Ant - Autocomplete categories?
        elif arg_upper in stats_by_category:
            category = arg_upper
            header = f"Principles used for {category} across all data sources"
            report_data = self.snapshot_data["PRINCIPLES_USED"][category]

        elif (
            # Stats principle or principle ID or name
            arg_upper in stats_by_principle  # '120: SF1_PNAME_CSTAB'
            or ":" in arg_upper  # '120:SF1_PNAME_CSTAB'
            or arg_upper in principles_by_id  # '120'
            or arg_upper in principles_by_name  # 'SF1_PNAME_CSTAB'
        ):
            if arg_upper in stats_by_principle:
                principle = arg_upper
            elif ":" in arg_upper:
                argpart = arg_upper.partition(":")
                principle = f"{argpart[0]}: {argpart[2].strip()}"
            elif arg_upper.isdigit():
                principle = f"{arg_upper}: {principles_by_id[arg_upper]}"
            else:
                principle = f"{principles_by_name[arg_upper]}: {arg_upper}"

            try:
                category = stats_by_principle[principle]["CATEGORY"]
                header = f"Principles used for {principle} across all data sources"
                report_data = {principle: self.snapshot_data["PRINCIPLES_USED"][category][principle]}
            except KeyError:
                print_message(f"Invalid parameter: {arg}", "error")
                self.help_principlesUsed()
                return

        else:
            print_message(f"Invalid parameter: {arg}", "error")
            self.help_principlesUsed()
            return

        # clean up the disclosure match keys
        if report_data and category == "DISCLOSED_RELATION":
            principle = "DISCLOSURE"
            new_report_data = {principle: {}}
            for matchkey in report_data[principle]:
                count = report_data[principle][matchkey]["COUNT"]
                sample = report_data[principle][matchkey]["SAMPLE"]
                disclosures, plus_keys, minus_keys = self.fmt_match_group(matchkey, from_database=True)
                for disclosure in disclosures:
                    if disclosure not in new_report_data[principle]:
                        new_report_data[principle][disclosure] = {
                            "COUNT": count,
                            "SAMPLE": sample,
                        }
                    else:
                        new_report_data[principle][disclosure]["COUNT"] += count
                        new_report_data[principle][disclosure]["SAMPLE"].extend(sample)
            report_data = new_report_data

        if report_data:
            matchlevel_code = category + "_SAMPLE"
            while True:
                report_row = self.select_matching_category(report_data, header)
                if not report_row:
                    break

                current_sample = 0
                sample_records = report_row[4]
                color_matchkey = self.colorize_match_data({"matchKey": report_row[2]})
                while True:
                    self.current_review_list = (
                        f"Sample {current_sample + 1} of {len(sample_records)} for {category} on {color_matchkey}"
                    )
                    current_records = str(sample_records[current_sample]).split()
                    if matchlevel_code == "MATCH_SAMPLE":
                        return_code = self.do_get("detail " + current_records[0])
                    else:
                        if matchlevel_code == "AMBIGUOUS_MATCH_SAMPLE":
                            for this_entity_id in current_records:
                                ambiguous_list = self.get_ambiguous_entity_set(
                                    this_entity_id
                                )  # returns all the relationships for the truly ambiguous entity
                                if ambiguous_list:
                                    current_records = ambiguous_list
                                    break
                            return_code = self.do_compare(",".join(current_records))
                        else:
                            if len(current_records) > 2:
                                self.current_review_list += self.colorize(
                                    f"\n(showing 1 of {len(current_records)} qualifying relationships for entity {current_records[0]})",
                                    "reset,dim,italics",
                                )
                                current_records = current_records[:2]
                            return_code = self.do_compare(",".join(current_records))

                    if return_code != 0:
                        # TODO - Ant - Which entity?
                        print_message("This entity no longer exists", "error")

                    while True:
                        if matchlevel_code in ("SINGLE_SAMPLE", "DUPLICATE_SAMPLE"):
                            # TODO - Ant - Doesn't get color?
                            reply = input(
                                self.colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "DHWE"
                        else:
                            reply = input(
                                self.colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "WE"

                        if reply:
                            reply_upper = reply.upper()
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply_upper.startswith("Q"):
                            break
                        elif reply_upper == "S":
                            self.do_scroll("")
                        # TODO - Ant - Does this work?!
                        elif reply_upper[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        # TODO - Ant - Does this work?!
                        elif reply_upper[0] in special_actions:
                            if reply_upper.startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply_upper.startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply_upper.startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply_upper.startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )

                    if reply_upper.startswith("Q"):
                        break

            self.current_review_list = None

    # ---------------------------
    def help_dataSourceSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the different match levels within each data source.

        {self.colorize('Syntax:', 'highlight2')}
            dataSourceSummary                               {self.colorize('with no parameters displays the overall stats', 'dim')}
            dataSourceSummary <dataSourceCode> <matchLevel> {self.colorize('where 0=Singletons, 1=Matches, 2=Ambiguous, 3=Possibles, 4=Relationships', 'dim')}
        """
            )
        )

    # ---------------------------
    def complete_dataSourceSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        # if before_arg == -1:
        #    return # arg not found

        arg = line[before_arg + 1 : endidx]

        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)
        elif spaces == 2:
            possibles = [
                "singles",
                "duplicates",
                "matches",
                "ambiguous",
                "possibles",
                "relationships",
            ]
        else:
            possibles = []

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_dataSourceSummary(self, arg):
        if not self.snapshot_data or "DATA_SOURCES" not in self.snapshot_data:
            print_message(
                "Please load a json file created with G2Snapshot.py to use this command",
                "warning",
            )
            return

        # display the summary if 0 arguments (all datasources) or 1 argument signifying a single data source
        if not arg or " " not in arg:

            tbl_title = "Data Source Summary from %s" % self.snapshot_file
            tbl_columns = []
            tbl_columns.append({"name": "\nData Source", "width": 25, "align": "left"})
            tbl_columns.append({"name": "\nRecords", "width": 15, "align": "right"})
            tbl_columns.append({"name": "\nEntities", "width": 15, "align": "right"})
            tbl_columns.append({"name": "\nCompression", "width": 15, "align": "right"})
            # tbl_columns.append({'name': 'Records\nUnmatched', 'width': 15, 'align': 'right'})
            tbl_columns.append({"name": "Matched\nRecords", "width": 15, "align": "right"})
            tbl_columns.append({"name": "Matched\nEntities", "width": 15, "align": "right"})
            tbl_columns.append(
                {
                    "name": "Related Entities\nAmbiguous Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Related Entities\nPossible Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Related Entities\nPossible Relationships",
                    "width": 15,
                    "align": "right",
                }
            )

            tbl_rows = []
            for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                if arg and not data_source.startswith(arg.upper()):
                    continue
                report_segment = self.snapshot_data["DATA_SOURCES"][data_source]
                row = []
                row.append(self.colorize_dsrc(data_source))
                row.append(fmt_statistic(report_segment.get("RECORD_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("ENTITY_COUNT", 0)))
                row.append(report_segment.get("COMPRESSION", 0))
                # row.append(fmtStatistic(report_segment.get('SINGLE_COUNT', 0)))
                row.append(fmt_statistic(report_segment.get("DUPLICATE_RECORD_COUNT", 0)))
                # row.append(fmtStatistic(report_segment.get('RECORD_COUNT', 0)-report_segment.get('ENTITY_COUNT', 0)))
                row.append(fmt_statistic(report_segment.get("DUPLICATE_ENTITY_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("AMBIGUOUS_MATCH_RELATION_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("POSSIBLE_MATCH_RELATION_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("POSSIBLY_RELATED_RELATION_COUNT", 0)))
                tbl_rows.append(row)

            self.render_table(tbl_title, tbl_columns, tbl_rows, combineHeaders=True)
        else:
            arg_tokens = arg.split()
            if len(arg_tokens) != 2:
                print_message(
                    "Arguments missing: data source and match level are required",
                    "warning",
                )
                return

            data_source = arg_tokens[0].upper()
            if data_source not in self.snapshot_data["DATA_SOURCES"]:
                print_message("Invalid data source", "error")
                return

            match_level = arg_tokens[1].upper()
            match_level_code = None
            for match_level_parm in self.valid_match_level_parameters:
                if match_level.startswith(match_level_parm):
                    match_level_code = self.valid_match_level_parameters[match_level_parm]
                    break
            if not match_level_code:
                print_message("Invalid match level", "error")
                return

            try:
                sample_records = sorted(
                    self.snapshot_data["DATA_SOURCES"][data_source][match_level_code],
                    key=lambda x: int(str(x).split()[0]),
                )
            except:
                sample_records = []
            if len(sample_records) == 0:
                print_message("No records found", "warning")
                return

            match_level_base = match_level_code.replace("_SAMPLE", "")
            if not self.snapshot_data["DATA_SOURCES"][data_source].get(
                match_level_code.replace("_SAMPLE", "_PRINCIPLES")
            ):
                print_message(
                    "Outdated snapshot, please create a new one using the latest G2Snapshot.py",
                    "error",
                )
                return

            while True:
                header = f"Matching statistics for {match_level_base} in {data_source}"
                report_row = self.select_matching_category(
                    self.snapshot_data["DATA_SOURCES"][data_source][match_level_code.replace("_SAMPLE", "_PRINCIPLES")],
                    header,
                )
                if not report_row:
                    break

                current_sample = 0
                sample_records = report_row[4]
                color_match_key = self.colorize_match_data({"matchKey": report_row[2]})
                while True:
                    self.current_review_list = f"Sample {current_sample + 1} of {len(sample_records)} for {match_level_base} on {color_match_key} in {data_source}"
                    current_records = str(sample_records[current_sample]).split()
                    if match_level_code in ("SINGLE_SAMPLE", "DUPLICATE_SAMPLE"):
                        return_code = self.do_get(
                            "detail " + current_records[0],
                            dataSourceFilter=[data_source],
                        )
                    else:
                        if match_level_code == "AMBIGUOUS_MATCH_SAMPLE":
                            for this_entity_id in current_records:
                                ambiguous_list = self.get_ambiguous_entity_set(
                                    this_entity_id
                                )  # returns all the relationships for the truly ambiguous entity
                                if ambiguous_list:
                                    current_records = ambiguous_list
                                    break
                            return_code = self.do_compare(
                                ",".join(current_records),
                                dataSourceFilter=[data_source],
                            )
                        else:
                            if len(current_records) > 2:
                                self.current_review_list += self.colorize(
                                    f"\n(showing 1 of {len(current_records)} qualifying relationships for entity {current_records[0]})",
                                    "reset,dim,italics",
                                )
                                current_records = current_records[:2]
                            return_code = self.do_compare(
                                ",".join(current_records),
                                dataSourceFilter=[data_source],
                            )

                    if return_code != 0:
                        print_message("This entity no longer exists", "error")

                    while True:
                        if match_level_code in ("SINGLE_SAMPLE", "DUPLICATE_SAMPLE"):
                            reply = input(
                                self.colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "DHWE"
                        else:
                            reply = input(
                                self.colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "WE"
                        if reply:
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply.upper().startswith("Q"):
                            break
                        elif reply.upper() == "S":
                            self.do_scroll("")
                        elif reply.upper()[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply.upper()[0] in special_actions:
                            if reply.upper().startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply.upper().startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply.upper().startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply.upper().startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )

                    if reply.upper().startswith("Q"):
                        break

            self.current_review_list = None

    # ---------------------------
    def help_crossSourceSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the different match levels across data sources.

        {self.colorize('Syntax:', 'highlight2')}
            crossSourceSummary                                           {self.colorize('with no parameters displays the overall stats', 'dim')}
            crossSourceSummary <dataSource1>                             {self.colorize('displays the cross matches for that data source only', 'dim')}
            crossSourceSummary <dataSource1> <dataSource2> <matchLevel>  {self.colorize('where 1=Matches, 2=Ambiguous, 3=Possibles, 4=Relationships', 'dim')}
        """
            )
        )

    # ---------------------------
    def complete_crossSourceSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        if before_arg == -1:
            return  # arg not found

        arg = line[before_arg + 1 : endidx]

        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)
        elif spaces == 2:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)
        elif spaces == 3:
            possibles = [
                "singles",
                "duplicates",
                "matches",
                "ambiguous",
                "possibles",
                "relationships",
            ]
        else:
            possibles = []

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    # TODO - Ant - Auto complete doesn't work for data source
    def do_crossSourceSummary(self, arg):

        if not self.snapshot_data or "DATA_SOURCES" not in self.snapshot_data:
            print_message(
                "Please load a json file created with G2Snapshot.py to use this command",
                "warning",
            )
            return

        # display the summary if no arguments
        if not arg or len(arg.split()) == 1:
            tbl_title = f"Cross Source Summary from {self.snapshot_file}"
            tbl_columns = []
            tbl_columns.append({"name": "From\nData Source", "width": 25, "align": "center"})
            tbl_columns.append({"name": "To\nData Source", "width": 25, "align": "center"})
            tbl_columns.append({"name": "Matched\nRecords", "width": 15, "align": "right"})
            tbl_columns.append({"name": "Matched\nEntities", "width": 15, "align": "right"})
            tbl_columns.append(
                {
                    "name": "Entities with\nAmbiguous Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Entities with\nPossible Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Entities with\nPossible Relationships",
                    "width": 15,
                    "align": "right",
                }
            )

            tbl_rows = []
            for data_source_1 in sorted(self.snapshot_data["DATA_SOURCES"]):
                if arg and data_source_1 != arg.upper():
                    continue
                for data_source_2 in sorted(self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"]):
                    report_segment = self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2]
                    row = []
                    row.append(self.colorize_dsrc(data_source_1))
                    row.append(self.colorize_dsrc(data_source_2))
                    row.append(fmt_statistic(report_segment.get("MATCH_RECORD_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("MATCH_ENTITY_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("AMBIGUOUS_MATCH_ENTITY_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("POSSIBLE_MATCH_ENTITY_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("POSSIBLY_RELATED_ENTITY_COUNT", 0)))
                    tbl_rows.append(row)

            self.render_table(tbl_title, tbl_columns, tbl_rows, combineHeaders=True)
        else:
            arg_tokens = arg.split()
            if len(arg_tokens) != 3:
                print_message(
                    "Arguments missing: two data sources and match level are required",
                    "warning",
                )
                return

            data_source_1 = arg_tokens[0].upper()
            if data_source_1 not in self.snapshot_data["DATA_SOURCES"]:
                print_message(f"Invalid data source: {data_source_1}", "error")
                return

            data_source_2 = arg_tokens[1].upper()
            if data_source_2 not in self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"]:
                print_message(f"Invalid data source: {data_source_2}", "error")
                return

            match_level = arg_tokens[2].upper()
            match_level_code = None
            for match_level_arm in self.valid_match_level_parameters:
                if match_level.startswith(match_level_arm):
                    match_level_code = self.valid_match_level_parameters[match_level_arm]
                    break

            if not match_level_code:
                print_message("Invalid match level", "error")
                return

            # duplicates are matches for cross source
            if match_level_code == "DUPLICATE_SAMPLE":
                match_level_code = "MATCH_SAMPLE"
            try:
                sample_records = sorted(
                    self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2][match_level_code],
                    key=lambda x: int(str(x).split()[0]),
                )
            except:
                sample_records = []

            if len(sample_records) == 0:
                print_message("No records found", "warning")
                return

            match_level_base = match_level_code.replace("_SAMPLE", "")
            if not self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2].get(
                match_level_code.replace("_SAMPLE", "_PRINCIPLES")
            ):
                print_message(
                    "Outdated snapshot, please create a new one using the latest G2Snapshot.py",
                    "error",
                )
                return

            while True:
                header = f"Matching statistics for {match_level_base} between {data_source_1} and {data_source_2}"
                report_row = self.select_matching_category(
                    self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2][
                        match_level_code.replace("_SAMPLE", "_PRINCIPLES")
                    ],
                    header,
                )
                if not report_row:
                    break

                current_sample = 0
                sample_records = report_row[4]
                color_match_key = self.colorize_match_data({"matchKey": report_row[2]})
                while True:
                    self.current_review_list = f"Sample {current_sample + 1} of {len(sample_records)} for {match_level_base} on {color_match_key} between {data_source_1} and {data_source_2}"
                    current_records = str(sample_records[current_sample]).split()
                    if match_level_code in ("MATCH_SAMPLE"):
                        return_code = self.do_get(
                            "detail " + current_records[0],
                            dataSourceFilter=[data_source_1, data_source_2],
                        )
                    else:
                        if match_level_code == "AMBIGUOUS_MATCH_SAMPLE":
                            for this_entity_id in current_records:
                                ambiguous_list = self.get_ambiguous_entity_set(
                                    this_entity_id
                                )  # returns all the relationships for the truly ambiguous entity
                                if ambiguous_list:
                                    current_records = ambiguous_list
                                    break
                            return_code = self.do_compare(
                                ",".join(current_records),
                                dataSourceFilter=[data_source_1, data_source_2],
                            )
                        else:
                            if len(current_records) > 2:
                                self.current_review_list += self.colorize(
                                    f"\n(showing 2 of {len(current_records)} qualifying relationships for entity {current_records[0]})",
                                    "reset,dim,italics",
                                )
                            return_code = self.do_compare(
                                ",".join(current_records[:3]),
                                dataSourceFilter=[data_source_1, data_source_2],
                            )

                    if return_code != 0:
                        print_message("This entity no longer exists", "error")

                    while True:
                        if match_level_code in ("MATCH_SAMPLE"):
                            reply = input(
                                self.colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "DHWE"
                        else:
                            reply = input(
                                self.colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "WE"
                        if reply:
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply.upper().startswith("Q"):
                            break
                        elif reply.upper() == ("S"):
                            self.do_scroll("")
                        elif reply.upper()[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply.upper()[0] in special_actions:
                            if reply.upper().startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply.upper().startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply.upper().startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply.upper().startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )
                    if reply.upper().startswith("Q"):
                        break
            self.current_review_list = None

    # ---------------------------
    def help_search(self):
        print(
            textwrap.dedent(
                f"""\

        Search for an entity by its attributes.

        {self.colorize('Syntax:', 'highlight2')}
            search Joe Smith {self.colorize('without a json structure performs a search on name alone', 'dim')}
            search {'{'}"name_full": "Joe Smith"{'}'}
            search {'{'}"name_org": "ABC Company"{'}'}
            search {'{'}"name_last": "Smith", "name_first": "Joe", "date_of_birth": "1992-12-10"{'}'}
            search {'{'}"name_org": "ABC Company", "addr_full": "111 First St, Anytown, USA 11111"{'}'}

        {self.colorize('Notes:', 'highlight2')}
            Searching by name alone may not locate a specific entity.
            Try adding a date of birth, address, or phone number if not found by name alone.
        """
            )
        )

    # ---------------------------
    def do_search(self, arg):
        if not arg:
            self.help_search()
            return
        try:
            if arg.startswith("{"):
                parm_data = dict_keys_upper(json.loads(arg))
            else:
                parm_data = {"FEATURES": []}
                for search_str in arg.split("|"):
                    if ":" not in search_str:
                        parm_data["FEATURES"].append({"NAME_FULL": search_str})
                        parm_data["FEATURES"].append({"NAME_ORG": search_str})
                    else:
                        str_split = [x.strip() for x in search_str.split(":")]
                        parm_data["FEATURES"].append({str_split[0].upper(): str_split[1]})
        except (ValueError, KeyError) as err:
            print_message(f"Invalid json parameter: {err}", "error")
            return

        print("\nSearching ...")
        search_json = parm_data
        search_flag_list = [
            "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
            "SZ_INCLUDE_FEATURE_SCORES",
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_INCLUDE_MATCH_KEY_DETAILS",
            "SZ_SEARCH_INCLUDE_STATS",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data = self.call_sdk("search_by_attributes", search_flag_list, json.dumps(search_json))
        except SzError as err:
            print_message(err, "error")
            return

        tbl_title = "Search Results"
        tbl_columns = [
            {"name": "Index", "width": 5, "align": "center"},
            {"name": "Entity ID", "width": 15, "align": "center"},
            {"name": "Entity Name", "width": 75, "align": "left"},
            {"name": "Data Sources", "width": 75, "align": "left"},
            {"name": "Match Key", "width": 75, "align": "left"},
            {"name": "Match Score", "width": 15, "align": "center"},
            {"name": "Relationships", "width": 15, "align": "left"},
        ]
        tbl_rows = []

        matched_list = []
        for matched_entity in json_data["RESOLVED_ENTITIES"]:
            entity_data = matched_entity["ENTITY"]["RESOLVED_ENTITY"]
            feature_scores = matched_entity["MATCH_INFO"]["FEATURE_SCORES"]
            match_score = 0
            for feature_code in matched_entity["MATCH_INFO"]["FEATURE_SCORES"].keys():
                score_weight = 1 if feature_code == "NAME" else 0.5
                best_score_record = sorted(feature_scores[feature_code], key=lambda x: x["SCORE"])[-1]
                if best_score_record["SCORE"] >= 50:
                    match_score += best_score_record["SCORE"] * score_weight

            relationships = matched_entity["ENTITY"]["RELATED_ENTITIES"]
            disclosed_count = len([x for x in relationships if x["IS_DISCLOSED"] > 0])
            derived_count = len(relationships) - disclosed_count

            matched_list.append(
                {
                    "ENTITY_ID": entity_data["ENTITY_ID"],
                    "ENTITY_NAME": entity_data["ENTITY_NAME"],
                    "RECORDS": entity_data["RECORDS"],
                    "MATCH_SCORE": match_score,
                    "MATCH_INFO": matched_entity["MATCH_INFO"],
                    "REL_COUNTS": {"DERIVED": derived_count, "DISCLOSED": disclosed_count},
                }
            )

        tbl_rows = []
        search_index = 0
        self.last_search_result = []
        for matched_entity in sorted(matched_list, key=lambda k: k["MATCH_SCORE"], reverse=True):
            search_index += 1
            tbl_rows.append(
                [
                    self.colorize(search_index, "dim"),
                    self.colorize_entity(matched_entity["ENTITY_ID"]),
                    matched_entity["ENTITY_NAME"],
                    self.fmt_record_list(matched_entity["RECORDS"], 1, 75),
                    self.fmt_match_key(matched_entity["MATCH_INFO"]),
                    matched_entity["MATCH_SCORE"],
                    "\n".join(
                        [
                            f"{v} {self.colorize(k.lower(), 'dim')}"
                            for k, v in matched_entity["REL_COUNTS"].items()
                            if v > 0
                        ]
                    ),
                ]
            )
            self.last_search_result.append(str(matched_entity["ENTITY_ID"]))

        if len(matched_list) > 0:
            tbl_title = f"{len(matched_list)} entities found ..."
            self.show_report2(self.render_table2(tbl_title, tbl_columns, tbl_rows))
            return

        if json_data.get("SEARCH_STATISTICS"):
            candidate_stats = json_data["SEARCH_STATISTICS"][0]["CANDIDATE_KEYS"]["SUMMARY"]
            if candidate_stats["FOUND"] > 0:
                msg = "\tOne or more entities were found but did not score high enough to be returned"
                msg += "\n\tPlease include additional or more complete attributes in your search"
            elif candidate_stats["GENERIC"] > 0:
                msg = "\tToo many entities would be returned"
                msg += "\n\tPlease include additional attributes to narrow the search results"
            elif candidate_stats["NOT_FOUND"] > 0:
                msg = "\tNo entities at all were found"
                msg += "\n\tPlease search by other attributes for this entity if you feel it should exist"
            else:
                msg = "\tNo search keys were even generated"
                msg += "\n\tPlease search by other attributes"
        else:  # older versions do not have statistics
            msg = "\tNo matches found or there were simply too many to return"
            msg += "\n\tPlease include additional search parameters if you feel this entity is in the database"
        print_message(msg, "warning")

    # ---------------------------
    def help_getFeatures(self):
        print(
            textwrap.dedent(
                f"""\

        Displays how a particular entity's features were parsed.

        {self.colorize('Syntax:', 'highlight2')}
            getFeatures <entity_id>
            getFeatures <entity_id> ADDRESS

        {self.colorize('Notes:', 'highlight2')}
            {self.colorize('Add a feature type code after the entity_id to filter for only those features', 'dim')}
        """
            )
        )

    # ---------------------------
    def do_getFeatures(self, arg, **kwargs):
        called_direct = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_getFeatures()
            return 0
        self.do_get("features " + arg)

    # ---------------------------
    def help_get(self):
        print(
            textwrap.dedent(
                f"""\

        Displays a particular entity by entity_id or by data_source and record_id.

        {self.colorize('Syntax:', 'highlight2')}
            get <entity_id>               {self.colorize("looks up an entity's resume by entity ID", 'dim')}
            get <dataSource> <recordID>   {self.colorize("looks up an entity's resume by data source and record ID", 'dim')}
            get search <search index>     {self.colorize("looks up an entity's resume by search index (requires a prior search)", 'dim')}

        {self.colorize('Notes:', 'highlight2')}
            {self.colorize('Add the keyword ', 'dim')}DETAIL{self.colorize(' to display each record in the entity separately.', 'dim')}
            {self.colorize('Add the keyword ', 'dim')}FEATURES{self.colorize(' to display how its features were parsed.', 'dim')}
            {self.colorize('Add the keyword ', 'dim')}ALL{self.colorize(' to display all the attributes of the entity if they are getting cut off.', 'dim')}
        """
            )
        )

    # ---------------------------
    def do_get(self, arg, **kwargs):
        """get an entity resume"""
        if not arg:
            self.help_get()
            return 0

        data_source_filter = None
        if self.current_settings["data_source_suppression"] == "on":
            data_source_filter = kwargs.get("dataSourceFilter")

        kwargs["show_relations_on_get"] = self.current_settings["show_relations_on_get"]
        kwargs["show_detail"] = False
        kwargs["feature_filters"] = []
        kwargs["attr_limit"] = 20
        features_only = False
        arg_tokens = []

        for token in arg.split():
            if token.upper() == "DETAIL":
                kwargs["show_detail"] = True
            elif token.upper().startswith("FEATURE"):
                features_only = True
            elif token.upper() == "ALL":
                kwargs["attr_limit"] = -1
            elif features_only and not token.isdigit():
                kwargs["feature_filters"].append(token.upper())
            else:
                arg_tokens.append(token.upper())
        if len(arg_tokens) == 2 and arg_tokens[0].upper() == "SEARCH":
            last_token = arg_tokens[1]
            if not (last_token.isdigit() and 1 <= int(last_token) <= len(self.last_search_result)):
                print_message("Invalid search index from the prior search", "error")
                return 0
            else:
                arg_tokens = [str(self.last_search_result[int(last_token) - 1])]
        if len(arg_tokens) not in (1, 2):
            print_message("Incorrect number of parameters", "warning")
            return 0
        if len(arg_tokens) == 1 and not arg_tokens[0].isnumeric():
            print_message("Entity ID must be numeric", "error")
            return 0
        try:
            if features_only:
                report = sz_pretty.get_features(arg_tokens, **kwargs)
            else:
                report = sz_pretty.get_entity(arg_tokens, **kwargs)
        except Exception as err:
            print_message(err, "error")
            return 0
        self.show_report2(report)

    # ---------------------------
    def find(self, step, arg):
        starting_id = 0
        data_source = None
        arg_list = arg.split()
        get_flag_list = []
        for parm in arg_list:
            if parm.isdigit():
                starting_id = parm
            else:
                data_source = parm.upper()
                get_flag_list = ["SZ_ENTITY_INCLUDE_RECORD_SUMMARY"]
        if starting_id:
            entity_id = int(starting_id)
        else:
            entity_id = self.last_entity_id + step
        trys = 0
        while True:
            try:
                resolved_json = self.call_sdk("get_entity_by_entity_id", get_flag_list, entity_id)
                if data_source:
                    found = False
                    for record in resolved_json["RESOLVED_ENTITY"]["RECORD_SUMMARY"]:
                        if record["DATA_SOURCE"].startswith(data_source):
                            found = True
                            break
                    if found:
                        self.do_get(str(entity_id))
                        break
                    else:
                        raise (Exception("does not contain data source"))
                else:
                    self.do_get(str(entity_id))
                    break
            except:
                entity_id += step
                trys += 1
                if trys == 1000:
                    print("\nsearching ...")
                if entity_id <= 0 or trys >= 100000:
                    if step == -1:
                        print_message("no prior entities", "warning")
                    else:
                        print_message("search for next abandoned after 100k tries", "error")
                    break

    # ---------------------------
    def do_next(self, arg):
        self.find(1, arg)

    def do_n(self, arg):
        remove_from_history()
        self.do_next(arg)

    # ---------------------------
    def do_previous(self, arg):
        self.find(-1, arg)

    def do_p(self, arg):
        remove_from_history()
        self.do_previous(arg)

    # ---------------------------
    def help_compare(self):
        print(
            textwrap.dedent(
                f"""\

        Compares a set of entities by placing them side by side in a columnar format.

        {self.colorize('Syntax:', 'highlight2')}
            compare <entity_id1> <entity_id2>   {self.colorize('compares the listed entities', 'dim')}
            compare search                      {self.colorize('places all the search results side by side', 'dim')}
            compare search <top (n)>            {self.colorize('places the top (n) search results side by side', 'dim')}
       """
            )
        )

    # ---------------------------
    def do_compare(self, arg, **kwargs):
        """show entities side by side"""
        if not arg:
            self.help_compare()
            return 0
        data_source_filter = None
        if self.current_settings["data_source_suppression"] == "on":
            data_source_filter = kwargs.get("dataSourceFilter")

        if isinstance(arg, str) and "SEARCH" in arg.upper():
            entity_list = self.last_search_result
            last_token = arg.split()[len(arg.split()) - 1]
            if last_token.isdigit():
                entity_list = self.last_search_result[: int(last_token)]
        elif "," in arg:
            entity_list = arg.split(",")
        else:
            entity_list = arg.split()
        try:
            if len(entity_list) == 1:
                report = sz_pretty.compare_relationships(entity_list[0])
            else:
                report = sz_pretty.compare_entities(entity_list)
        except Exception as err:
            print_message(err, "error")
            return 0
        self.show_report2(report)

    # ---------------------------
    def help_tree(self):
        print(
            textwrap.dedent(
                f"""\

        Displays an entity tree from a particular entity's point of view.

        {self.colorize('Syntax:', 'highlight2')}
            tree <entity_id>                  {self.colorize('displays the first degree relationships of an entity', 'dim')}
            tree <entity_id> degree <n>       {self.colorize('displays relationships of an entity out to <n> degrees', 'dim')}
            tree <entity_id> degree <n> all   {self.colorize('adding the "all" tag disables the default limit of 10 per category', 'dim')}
        """
            )
        )

    # ---------------------------
    def do_tree(self, arg, **kwargs):
        """display entity relationships in a tree"""
        if not arg:
            self.help_tree()
            return

        root_entity_id = None
        build_out_degree = 1
        max_children = 25
        arg_list = arg.split()
        if arg_list[-1].upper() == "ALL":
            max_children = 10000
            arg_list.pop(-1)
        if len(arg_list) in (1, 3):
            if arg_list[0].isdigit():
                root_entity_id = int(arg_list[0])
            if len(arg_list) == 3 and arg_list[1].upper() == "DEGREE" and arg_list[2].isdigit():
                build_out_degree = int(arg_list[2])
        if not root_entity_id:
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return

        self.show_report2(sz_pretty.get_relationship_tree(root_entity_id, **kwargs))

    # ---------------------------
    def get_ambiguous_entity_set(self, entity_id):
        # get other ambiguous relationships if this is the ambiguous entity
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_OPTION_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data_2 = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return

        ambiguous_entity = "AMBIGUOUS_ENTITY" in json_data_2["RESOLVED_ENTITY"]["FEATURES"]
        if ambiguous_entity and "RELATED_ENTITIES" in json_data_2:
            entity_set = []
            for related_entity in json_data_2["RELATED_ENTITIES"]:
                if related_entity["IS_AMBIGUOUS"] != 0:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            if len(entity_set) > 1:
                return [entity_id] + entity_set
        return

    # ---------------------------
    def get_related_entity_set(self, entity_id, sample_category=""):
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data_2 = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return
        entity_set = []
        for related_entity in json_data_2["RELATED_ENTITIES"]:
            if sample_category == "POSSIBLE_MATCH_SAMPLE":
                if related_entity["MATCH_LEVEL"] <= 2 and related_entity["IS_AMBIGUOUS"] == 0:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            elif sample_category == "POSSIBLY_RELATED_SAMPLE":
                if related_entity["MATCH_LEVEL"] == 3:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            else:
                entity_set.append(str(related_entity["ENTITY_ID"]))
        return [entity_id] + sorted(entity_set, key=lambda x: int(x))

    # ---------------------------
    def help_why(self):
        print(
            textwrap.dedent(
                f"""\

        Shows the internal values and scores used to determine why a set of records resolved or only related.

        {self.colorize('Syntax:', 'highlight2')}
            why <entity_id1>                                            {self.colorize('shows why the records in a single entity resolved together', 'dim')}
            why <entity_id1> <entity_id2>                               {self.colorize('shows why two or more different entities did not resolve', 'dim')}
            why <data_source1> <record_id1> <data_source2> <record_id2> {self.colorize('shows if the two data source records could resolve or relate', 'dim')}

        {self.colorize('Color legend:', 'highlight2')}
            {self.colorize('green', 'good')} indicates the values matched and contributed to the overall score
            {self.colorize('red', 'bad')} indicates the values did not match and hurt the overall score
            {self.colorize('yellow', 'caution')} indicates the values did not match but did not hurt the overall score
            {self.colorize('cyan', 'highlight2')} indicates the values only helped get the record on the candidate list
            {self.colorize('dimmed', 'dim')} values were ignored (see the bracket legend below)

        {self.colorize('Bracket legend:', 'highlight2')}
            [99] indicates how many entities share this value
            [~] indicates that this value was not used to find candidates as too many entities share it
            [!] indicates that this value was not not even scored as too many entities share it
            [#] indicates that this value was suppressed in favor of a more complete value\n
        """
            )
        )

    # ---------------------------
    def do_why(self, arg):
        if not arg:
            self.help_why()
            return -1 if caller != "onecmd" else 0

        old_why_not = False
        if arg.upper().endswith(" OLD"):
            old_why_not = True
            arg = arg[0:-4]

        if "SEARCH" in arg.upper():
            last_token = arg.split()[len(arg.split()) - 1]
            if last_token.isdigit():
                entity_list = self.last_search_result[: int(last_token)]
            else:
                entity_list = self.last_search_result
        elif "," in arg:
            entity_list = arg.split(",")
        else:
            entity_list = arg.split()

        if not all(x.isnumeric() for x in entity_list) and not entity_list[0].upper() in sz_pretty.dsrc_code_lookup:
            print_message("invalid parameters, see help", "error")
            return

        if len(entity_list) == 1:
            self.show_report2(sz_pretty.why_how(entity_list[0]))
        elif len(entity_list) == 2 and not old_why_not:
            self.show_report2(sz_pretty.why_not(entity_list))
        elif len(entity_list) == 4 and entity_list[0].upper() in sz_pretty.dsrc_code_lookup:
            self.show_report2(sz_pretty.why_records(entity_list))
        else:
            self.show_report2(sz_pretty.why_not_many(entity_list))


    def why_display(self, entity_data, tbl_title, row1_title):

        tbl_columns = [
            {
                "name": self.colorize(row1_title, "row_title"),
                "width": 50,
                "align": "left",
            }
        ]
        tbl_rows = []

        data_source_row = ["DATA_SOURCES"]
        match_key_row = ["WHY_RESULT"]
        cross_relations_row = ["RELATIONSHIPS"]
        feature_array = {}
        for entity_id in sorted(entity_data.keys()):
            # add the column
            color = "entity_color" if row1_title == "ENTITY_ID" else "dim"
            tbl_columns.append({"name": self.colorize(entity_id, color), "width": 75, "align": "left"})

            # add the data sources
            data_source_row.append("\n".join(sorted(entity_data[entity_id]["dataSources"])))

            # add the cross relationships
            if "crossRelations" in entity_data[entity_id]:
                relation_list = []
                for relationship in [
                    x
                    for x in sorted(
                        entity_data[entity_id]["crossRelations"],
                        key=lambda k: k["entityId"],
                    )
                ]:
                    if len(entity_list) <= 2:  # suppress to entity if only 2
                        del relationship["entityId"]
                    relation_list.append(self.colorize_match_data(relationship))
                cross_relations_row.append("\n".join(relation_list))

            # add the matchKey
            if "whyKey" not in entity_data[entity_id] or not entity_data[entity_id]["whyKey"]:
                # can only happen with the old multiple entity why
                match_key_row.append(self.colorize("Not found!", "bad"))
            # TODO - Ant -
            # elif type(entity_data[entity_id]["whyKey"]) != list:
            elif not isinstance(entity_data[entity_id]["whyKey"], list):
                match_key_row.append(self.colorize_match_data(entity_data[entity_id]["whyKey"]))
            else:
                temp_list = []
                for why_key in [x for x in sorted(entity_data[entity_id]["whyKey"], key=lambda k: k["entityId"])]:
                    if "entityId" in why_key and len(entity_list) <= 2:  # suppress to entity if only 2
                        del why_key["entityId"]
                    temp_list.append(self.colorize_match_data(why_key))
                match_key_row.append("\n".join(temp_list))

            # prepare the feature rows
            why_key = entity_data[entity_id]["whyKey"]
            for lib_feat_id in entity_data[entity_id]["features"]:
                feature_data = entity_data[entity_id]["features"][lib_feat_id]
                ftype_id = feature_data["ftypeId"]
                formatted_feature = self.why_format_feature(feature_data, why_key)
                if ftype_id not in feature_array:
                    feature_array[ftype_id] = {}
                if entity_id not in feature_array[ftype_id]:
                    feature_array[ftype_id][entity_id] = []
                feature_array[ftype_id][entity_id].append(formatted_feature)

        # prepare the table
        tbl_rows.append(data_source_row)
        if len(cross_relations_row) > 1:
            tbl_rows.append(cross_relations_row)
        tbl_rows.append(match_key_row)

        # add the feature rows
        for ftype_id in sorted(feature_array, key=lambda k: self.ftype_id_order[k]):
            feature_row = [(self.ftype_lookup[ftype_id]["FTYPE_CODE"] if ftype_id in self.ftype_lookup else "unknown")]
            for entity_id in sorted(entity_data.keys()):
                if entity_id not in feature_array[ftype_id]:
                    feature_row.append("")
                else:
                    feature_list = []
                    for feature_dict in sorted(
                        sorted(
                            feature_array[ftype_id][entity_id],
                            key=lambda k: (k["featDesc"]),
                        ),
                        key=lambda k: (k["sortOrder"]),
                    ):
                        feature_list.append(feature_dict["formattedFeatDesc"])
                    feature_row.append("\n".join(feature_list))
            tbl_rows.append(feature_row)

        # colorize the first column
        for i in range(len(tbl_rows)):
            tbl_rows[i][0] = self.colorize(tbl_rows[i][0], "row_title")

        self.render_table(tbl_title, tbl_columns, tbl_rows, displayFlag="No")
        if row1_title != "Step":
            self.show_report("auto", from_how_or_why=True)

    # ---------------------------
    def why_entity(self, entity_list):
        # TODO - Ant -
        print("\nNot supported on V4, JB wants to figure out...\n")
        return

        why_flag_list = ["SZ_WHY_ENTITY_DEFAULT_FLAGS"]
        try:
            json_data = self.call_sdk("why_entity_by_entity_id", why_flag_list, int(entity_list[0]))
        # except Exception as err:
        except SzError as err:
            print_message(err, "error")
            return None

        entity_data = {}
        for why_result in json_data["WHY_RESULTS"]:
            internal_id = why_result["INTERNAL_ID"]
            entity_id = why_result["ENTITY_ID"]
            this_id = internal_id  # will eventually be entityId when why not function is added
            entity_data[this_id] = {}

            records = self.why_fmt_record_list(why_result["FOCUS_RECORDS"])
            features = self.why_get_features(json_data, entity_id, internal_id)
            if "MATCH_INFO" not in why_result:
                why_key = None
            else:
                why_key, features = self.why_add_match_info(features, why_result["MATCH_INFO"])

            entity_data[this_id]["dataSources"] = records
            entity_data[this_id]["whyKey"] = why_key
            entity_data[this_id]["features"] = features

        return entity_data

    # ---------------------------
    def why_add_match_info(self, features, matchInfo, default_side="INBOUND"):
        other_side = "CANDIDATE" if default_side == "INBOUND" else "INBOUND"

        why_key = {}
        why_key["matchKey"] = matchInfo["WHY_KEY"]
        why_key["ruleCode"] = self.getRule_desc(matchInfo["WHY_ERRULE_CODE"])
        why_key["anyCandidates"] = False

        # update from candidate section of why
        if "CANDIDATE_KEYS" in matchInfo:
            for ftype_code in matchInfo["CANDIDATE_KEYS"]:
                ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                for feat_record in matchInfo["CANDIDATE_KEYS"][ftype_code]:
                    lib_feat_id = feat_record["FEAT_ID"]
                    if lib_feat_id not in features:
                        print("warning: candidate feature %s not in record!" % lib_feat_id)
                        continue
                    features[lib_feat_id]["ftypeCode"] = ftype_code
                    features[lib_feat_id]["ftypeId"] = ftype_id
                    features[lib_feat_id]["wasCandidate"] = "Yes"
                    features[lib_feat_id]["matchScore"] = 100
                    features[lib_feat_id]["matchLevel"] = "SAME"
                    why_key["anyCandidates"] = True

        # update from scoring section of why
        for ftype_code in matchInfo["FEATURE_SCORES"]:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            best_score_record = {}
            for feat_record in matchInfo["FEATURE_SCORES"][ftype_code]:
                # if featRecord.get('scoringWasSuppressed','No') == 'Yes':
                #    continue
                # BUG WHERE INBOUND/CANDIDATE IS SOMETIMES REVERSED...
                if feat_record[default_side + "_FEAT_ID"] in features:
                    lib_feat_id = feat_record[default_side + "_FEAT_ID"]
                    matched_feat_id = feat_record[other_side + "_FEAT_ID"]
                    matched_feat_desc = feat_record[other_side + "_FEAT_DESC"]
                elif feat_record[other_side + "_FEAT_ID"] in features:
                    lib_feat_id = feat_record[other_side + "_FEAT_ID"]
                    matched_feat_id = feat_record[default_side + "_FEAT_ID"]
                    matched_feat_desc = feat_record[default_side + "_FEAT_DESC"]
                else:
                    print("warning: scored feature %s not in either record!" % lib_feat_id)
                    continue

                feat_record = self.why_set_match_score(feat_record)
                match_score = feat_record["MATCH_SCORE"]
                match_score_display = feat_record["MATCH_SCORE_DISPLAY"]
                match_level = feat_record["SCORE_BUCKET"]
                feat_behavior = feat_record["SCORE_BEHAVIOR"]

                if "matchScore" not in best_score_record or match_score > best_score_record["matchScore"]:
                    best_score_record["libFeatId"] = lib_feat_id
                    best_score_record["matchScore"] = match_score
                    best_score_record["matchScoreDisplay"] = match_score_display
                    best_score_record["matchLevel"] = match_level
                    best_score_record["matchedFeatId"] = matched_feat_id
                    best_score_record["matchedFeatDesc"] = matched_feat_desc
                    best_score_record["featBehavior"] = feat_behavior

            # and bestScoreRecord['libFeatId'] in features) or not : #--adjusted for how
            if best_score_record:
                lib_feat_id = best_score_record["libFeatId"]
                if lib_feat_id not in features:  # adjusted for how
                    # input(f'hit how adjustment on {libFeatId}, press any key')
                    features[lib_feat_id] = {}
                features[lib_feat_id]["libFeatId"] = lib_feat_id
                features[lib_feat_id]["ftypeId"] = ftype_id
                features[lib_feat_id]["ftypeCode"] = ftype_code
                features[lib_feat_id]["wasScored"] = "Yes"
                features[lib_feat_id]["matchScore"] = best_score_record["matchScore"]
                features[lib_feat_id]["matchScoreDisplay"] = best_score_record["matchScoreDisplay"]
                features[lib_feat_id]["matchLevel"] = best_score_record["matchLevel"]
                features[lib_feat_id]["matchedFeatId"] = best_score_record["matchedFeatId"]
                features[lib_feat_id]["matchedFeatDesc"] = best_score_record["matchedFeatDesc"]
                features[lib_feat_id]["featBehavior"] = best_score_record["featBehavior"]

        return why_key, features

    # ---------------------------
    def why_not_2(self, entity_list):

        why_flag_list = ["SZ_WHY_ENTITIES_DEFAULT_FLAGS"]
        try:
            json_data = self.call_sdk(
                "why_entities",
                why_flag_list,
                [int(entity_list[0]), int(entity_list[1])],
            )
        except SzError as err:
            print_message(err, "error")
            return

        entity_data = {}
        for why_result in json_data["WHY_RESULTS"]:
            for this_id in [why_result["ENTITY_ID"], why_result["ENTITY_ID_2"]]:
                entity_data[this_id] = {}
                best_entity = None
                for resolved_entity in json_data["ENTITIES"]:
                    if resolved_entity["RESOLVED_ENTITY"]["ENTITY_ID"] == this_id:
                        best_entity = resolved_entity
                        break
                if not best_entity:
                    print("\nInternal error: resolved entity %s missing!\n" % this_id)
                    return None

                records = self.why_fmt_record_list(best_entity["RESOLVED_ENTITY"]["RECORDS"])
                features = {}
                for ftype_code in best_entity["RESOLVED_ENTITY"]["FEATURES"]:
                    for distinct_feature_record in best_entity["RESOLVED_ENTITY"]["FEATURES"][ftype_code]:
                        for feat_record in distinct_feature_record["FEAT_DESC_VALUES"]:
                            lib_feat_id = feat_record["LIB_FEAT_ID"]
                            if lib_feat_id not in features:
                                features[lib_feat_id] = {}
                                features[lib_feat_id]["ftypeId"] = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                                features[lib_feat_id]["ftypeCode"] = ftype_code
                                features[lib_feat_id]["featDesc"] = feat_record["FEAT_DESC"]
                                features[lib_feat_id]["isCandidate"] = feat_record["USED_FOR_CAND"]
                                features[lib_feat_id]["isScored"] = feat_record["USED_FOR_SCORING"]
                                features[lib_feat_id]["entityCount"] = feat_record["ENTITY_COUNT"]
                                features[lib_feat_id]["candidateCapReached"] = feat_record["CANDIDATE_CAP_REACHED"]
                                features[lib_feat_id]["scoringCapReached"] = feat_record["SCORING_CAP_REACHED"]
                                features[lib_feat_id]["scoringWasSuppressed"] = feat_record["SUPPRESSED"]

                if "MATCH_INFO" not in why_result:
                    why_key = None
                else:
                    why_key, features = self.why_add_match_info(features, why_result["MATCH_INFO"])

                entity_data[this_id]["dataSources"] = records
                entity_data[this_id]["whyKey"] = why_key
                entity_data[this_id]["features"] = features

                entity_data[this_id]["crossRelations"] = []
                for related_entity in best_entity["RELATED_ENTITIES"]:
                    if str(related_entity["ENTITY_ID"]) in entity_list:
                        relationship = {}
                        relationship["entityId"] = related_entity["ENTITY_ID"]
                        relationship["matchKey"] = related_entity["MATCH_KEY"]
                        relationship["ruleCode"] = self.getRule_desc(related_entity["ERRULE_CODE"])
                        entity_data[this_id]["crossRelations"].append(relationship)

        return entity_data

    # ---------------------------
    def why_not_manyx(self, entity_list):

        why_flag_list = [
            "SZ_WHY_ENTITY_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
        ]

        master_ftype_list = []
        entity_data = {}
        for entity_id in entity_list:
            entity_data[entity_id] = {}
            try:
                json_data = self.call_sdk("why_entity_by_entity_id", why_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                return

            # add the data sources and create search json
            search_json = {}
            entity_data[entity_id]["dataSources"] = []
            for record in json_data["ENTITIES"][0]["RESOLVED_ENTITY"]["RECORDS"]:
                entity_data[entity_id]["dataSources"].append("%s: %s" % (record["DATA_SOURCE"], record["RECORD_ID"]))
                if not search_json:
                    search_json = record["JSON_DATA"]
                else:  # merge the json records
                    root_attributes = {}
                    for root_attribute in record["JSON_DATA"]:
                        # TODO - Ant -
                        # if type(record["JSON_DATA"][root_attribute]) != list:
                        if not isinstance(record["JSON_DATA"][root_attribute], list):
                            root_attributes[root_attribute] = record["JSON_DATA"][root_attribute]
                        else:
                            if root_attribute not in search_json:
                                search_json[root_attribute] = []
                            for sub_record in record["JSON_DATA"][root_attribute]:
                                search_json[root_attribute].append(sub_record)
                    if root_attributes:
                        if "ROOT_ATTRIBUTES" not in search_json:
                            search_json["ROOT_ATTRIBUTES"] = []
                        search_json["ROOT_ATTRIBUTES"].append(root_attributes)

            # get info for these features from the resolved entity section
            entity_data[entity_id]["features"] = {}
            for ftype_code in json_data["ENTITIES"][0]["RESOLVED_ENTITY"]["FEATURES"]:
                for feat_record in json_data["ENTITIES"][0]["RESOLVED_ENTITY"]["FEATURES"][ftype_code]:
                    for feat_values in feat_record["FEAT_DESC_VALUES"]:
                        lib_feat_id = feat_values["LIB_FEAT_ID"]
                        if lib_feat_id not in entity_data[entity_id]["features"]:
                            entity_data[entity_id]["features"][lib_feat_id] = {}
                            entity_data[entity_id]["features"][lib_feat_id]["ftypeId"] = self.ftype_code_lookup[
                                ftype_code
                            ]["FTYPE_ID"]
                            entity_data[entity_id]["features"][lib_feat_id]["ftypeCode"] = ftype_code
                            entity_data[entity_id]["features"][lib_feat_id]["featDesc"] = feat_values["FEAT_DESC"]
                            entity_data[entity_id]["features"][lib_feat_id]["isCandidate"] = feat_values[
                                "USED_FOR_CAND"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["isScored"] = feat_values[
                                "USED_FOR_SCORING"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["entityCount"] = feat_values["ENTITY_COUNT"]
                            entity_data[entity_id]["features"][lib_feat_id]["candidateCapReached"] = feat_values[
                                "CANDIDATE_CAP_REACHED"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["scoringCapReached"] = feat_values[
                                "SCORING_CAP_REACHED"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["scoringWasSuppressed"] = feat_values[
                                "SUPPRESSED"
                            ]
                            if entity_data[entity_id]["features"][lib_feat_id]["ftypeId"] not in master_ftype_list:
                                master_ftype_list.append(entity_data[entity_id]["features"][lib_feat_id]["ftypeId"])

            # see how this entity is related to the others
            get_flag_list = ["SZ_ENTITY_BRIEF_DEFAULT_FLAGS"]
            try:
                json_data2 = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                return

            entity_data[entity_id]["crossRelations"] = []
            for related_entity in json_data2["RELATED_ENTITIES"]:
                if str(related_entity["ENTITY_ID"]) in entity_list:
                    relationship = {}
                    relationship["entityId"] = related_entity["ENTITY_ID"]
                    relationship["matchKey"] = related_entity["MATCH_KEY"]
                    relationship["ruleCode"] = self.getRule_desc(related_entity["ERRULE_CODE"])
                    entity_data[entity_id]["crossRelations"].append(relationship)

            # search for this entity to get the scores against the others
            search_flag_list = [
                "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
                "SZ_INCLUDE_FEATURE_SCORES",
                "SZ_ENTITY_INCLUDE_ENTITY_NAME",
                "SZ_ENTITY_INCLUDE_RECORD_DATA",
            ]
            try:
                json_data2 = self.call_sdk("search_by_attributes", search_flag_list, json.dumps(search_json))
            except SzError as err:
                print_message(err, "error")
                return

            entity_data[entity_id]["whyKey"] = []
            for resolved_entity_base in json_data2["RESOLVED_ENTITIES"]:
                resolved_entity = resolved_entity_base["ENTITY"]["RESOLVED_ENTITY"]
                resolved_entity_match_info = resolved_entity_base["MATCH_INFO"]
                if str(resolved_entity["ENTITY_ID"]) in entity_list and str(resolved_entity["ENTITY_ID"]) != entity_id:
                    why_key = {}
                    why_key["matchKey"] = resolved_entity_match_info["MATCH_KEY"]
                    why_key["ruleCode"] = self.getRule_desc(resolved_entity_match_info["ERRULE_CODE"])
                    why_key["entityId"] = resolved_entity["ENTITY_ID"]
                    entity_data[entity_id]["whyKey"].append(why_key)
                    for feature_code in resolved_entity_match_info["FEATURE_SCORES"]:
                        # get the best score for the feature
                        best_score_record = None
                        for score_record in resolved_entity_match_info["FEATURE_SCORES"][feature_code]:
                            # print (json.dumps(scoreRecord, indent=4))
                            if not best_score_record:
                                best_score_record = score_record
                            elif "GNR_FN" in score_record and score_record["GNR_FN"] > best_score_record["GNR_FN"]:
                                best_score_record = score_record
                            elif "BT_FN" in score_record and score_record["BT_FN"] > best_score_record["BT_FN"]:
                                best_score_record = score_record
                            elif (
                                "FULL_SCORE" in score_record
                                and score_record["FULL_SCORE"] > best_score_record["FULL_SCORE"]
                            ):
                                best_score_record = score_record
                        # update the entity feature
                        for lib_feat_id in entity_data[entity_id]["features"]:
                            # print ('-' * 50)
                            # print(entityData[entityId]['features'][libFeatId])
                            if entity_data[entity_id]["features"][lib_feat_id][
                                "ftypeCode"
                            ] == feature_code and entity_data[entity_id]["features"][lib_feat_id]["featDesc"] in (
                                best_score_record["INBOUND_FEAT"],
                                best_score_record["CANDIDATE_FEAT"],
                            ):
                                match_score = 0
                                match_level = "DIFF"
                                if "GNR_FN" in best_score_record:
                                    match_score = best_score_record["GNR_FN"]
                                    if "GNR_ON" in best_score_record and best_score_record["GNR_ON"] >= 0:
                                        match_score_display = "org:%s" % best_score_record["GNR_ON"]
                                    else:
                                        match_score_display = "score:%s" % best_score_record["GNR_FN"]
                                        if "GNR_GN" in best_score_record and best_score_record["GNR_GN"] >= 0:
                                            match_score_display += "|giv:%s" % best_score_record["GNR_GN"]
                                        if "GNR_SN" in best_score_record and best_score_record["GNR_SN"] >= 0:
                                            match_score_display += "|sur:%s" % best_score_record["GNR_SN"]
                                    if match_score == 100:
                                        match_level = "SAME"
                                    else:
                                        if "NAME" in resolved_entity_match_info["MATCH_KEY"]:
                                            match_level = "CLOSE"
                                elif "BT_FN" in best_score_record:
                                    match_score = best_score_record["BT_FN"]
                                    if "BT_ON" in best_score_record and best_score_record["BT_ON"] > 0:
                                        match_score_display = "org:%s" % best_score_record["BT_ON"]
                                    else:
                                        match_score_display = "full:%s" % best_score_record["BT_FN"]
                                    if match_score == 100:
                                        match_level = "SAME"
                                    else:
                                        if "NAME" in resolved_entity_match_info["MATCH_KEY"]:
                                            match_level = "CLOSE"
                                else:
                                    match_score = best_score_record["FULL_SCORE"]
                                    match_score_display = str(best_score_record["FULL_SCORE"])
                                    if match_score == 100:
                                        match_level = "SAME"
                                    else:
                                        cfrtn_record = self.cfrtn_lookup[
                                            self.cfunc_lookup[self.scored_ftype_codes[feature_code]["CFUNC_ID"]][
                                                "CFUNC_ID"
                                            ]
                                        ]
                                        if match_score >= cfrtn_record["CLOSE_SCORE"]:
                                            match_level = "CLOSE"

                                if (
                                    "matchScore" not in entity_data[entity_id]["features"][lib_feat_id]
                                    or match_score > entity_data[entity_id]["features"][lib_feat_id]["matchScore"]
                                ):
                                    entity_data[entity_id]["features"][lib_feat_id]["wasScored"] = "Yes"
                                    entity_data[entity_id]["features"][lib_feat_id]["matchedFeatId"] = 0
                                    entity_data[entity_id]["features"][lib_feat_id]["matchedFeatDesc"] = (
                                        best_score_record["CANDIDATE_FEAT"]
                                        if entity_data[entity_id]["features"][lib_feat_id]["featDesc"]
                                        == best_score_record["INBOUND_FEAT"]
                                        else best_score_record["INBOUND_FEAT"]
                                    )
                                    entity_data[entity_id]["features"][lib_feat_id]["matchScore"] = match_score
                                    entity_data[entity_id]["features"][lib_feat_id][
                                        "matchScoreDisplay"
                                    ] = match_score_display
                                    entity_data[entity_id]["features"][lib_feat_id]["matchLevel"] = match_level
                                break

        # find matching features whether scored or not (accounts for candidate keys as well)
        for entity_id in entity_list:
            for lib_feat_id in entity_data[entity_id]["features"]:
                for entity_id_1 in entity_list:
                    if entity_id != entity_id_1 and lib_feat_id in entity_data[entity_id_1]["features"]:
                        entity_data[entity_id]["features"][lib_feat_id]["wasCandidate"] = (
                            "Yes" if entity_data[entity_id]["features"][lib_feat_id]["isCandidate"] == "Y" else "No"
                        )
                        entity_data[entity_id]["features"][lib_feat_id]["matchScore"] = 100
                        entity_data[entity_id]["features"][lib_feat_id]["matchLevel"] = "SAME"
                        break

        return entity_data

    # ---------------------------
    def why_fmt_record_list(self, record_list):
        records_by_source = {}
        for record in record_list:
            if record["DATA_SOURCE"] not in records_by_source:
                records_by_source[record["DATA_SOURCE"]] = [record["RECORD_ID"]]
            else:
                records_by_source[record["DATA_SOURCE"]].append(record["RECORD_ID"])
        record_display = []
        for data_source in sorted(records_by_source.keys()):
            colored_data_source = self.colorize_dsrc(data_source)
            if len(records_by_source[data_source]) > 1:
                record_display.append(f"{colored_data_source}: {len(records_by_source[data_source])} records")
            else:
                for record_id in sorted(records_by_source[data_source]):
                    record_display.append(f"{colored_data_source}: {record_id}")
        return record_display

    # ---------------------------
    def feature_counter_display(self, feature_data):
        counter_display = "["
        if feature_data["candidateCapReached"] == "Y":
            counter_display += "~"
        if feature_data["scoringCapReached"] == "Y":
            counter_display += "!"
        if feature_data["scoringWasSuppressed"] == "Y":
            counter_display += "#"
        counter_display += str(feature_data["entityCount"]) + "]"
        return counter_display

    # ---------------------------
    def why_format_feature(self, feature_data, why_key):

        feature_data["formattedFeatDesc"] = feature_data["featDesc"].strip()
        ftype_code = feature_data["ftypeCode"]
        feature_data["counterDisplay"] = self.feature_counter_display(feature_data)
        feature_data["formattedFeatDesc"] += " " + feature_data["counterDisplay"]
        feature_data["formattedFeatDesc1"] = feature_data["formattedFeatDesc"]

        dimmit = any(c in feature_data["counterDisplay"] for c in ["~", "!", "#"])
        feature_data["sortOrder"] = 3
        if "wasScored" in feature_data:
            if feature_data["matchLevel"] in ("SAME", "CLOSE"):
                feature_data["sortOrder"] = 1
                feature_data["featColor"] = "good"
            else:
                feature_data["sortOrder"] = 2
                if not why_key:
                    feature_data["featColor"] = "bad"
                elif isinstance(why_key, dict) and ("-" + ftype_code) not in why_key["matchKey"]:
                    feature_data["featColor"] = "caution"
                elif isinstance(why_key, list) and ("-" + ftype_code) not in why_key[0]["matchKey"]:
                    feature_data["featColor"] = "caution"
                else:
                    feature_data["featColor"] = "bad"
            # if dimmit:
            #    featureData['featColor'] += ',dim'
            feature_data["formattedFeatDesc1"] = feature_data["formattedFeatDesc"]
            feature_data["formattedFeatDesc"] = self.colorize(
                feature_data["formattedFeatDesc"], feature_data["featColor"]
            )

            # note: addresses may score same tho not exact!
            if feature_data["matchLevel"] != "SAME" or feature_data["matchedFeatDesc"] != feature_data["featDesc"]:
                feature_data["formattedFeatDesc"] += "\n" + self.colorize(
                    f"\u2514\u2500\u2500 {feature_data['matchedFeatDesc']} ({feature_data['matchScoreDisplay']})",
                    feature_data["featColor"],
                )

        elif "matchScore" in feature_data:  # must be same and likely a candidate builder
            feature_data["sortOrder"] = 1
            feature_data["featColor"] = "highlight2" + (",dim" if dimmit else "")
            feature_data["formattedFeatDesc1"] = feature_data["formattedFeatDesc"]
            feature_data["formattedFeatDesc"] = self.colorize(
                feature_data["formattedFeatDesc"], feature_data["featColor"]
            )

        else:
            if ftype_code == "AMBIGUOUS_ENTITY":
                if feature_data["formattedFeatDesc"].startswith(" ["):
                    feature_data["formattedFeatDesc"] = "Ambiguous!"
                feature_data["formattedFeatDesc1"] = self.colorize(feature_data["formattedFeatDesc"], "bad")
                feature_data["formattedFeatDesc"] = self.colorize(feature_data["formattedFeatDesc"], "bad")

        # sort rejected matches lower
        if dimmit:
            feature_data["sortOrder"] += 0.5

        return feature_data

    # ---------------------------
    def why_get_features(self, json_data, entity_id, internal_id=None):
        best_entity = None
        best_record = None
        for resolved_entity in json_data["ENTITIES"]:
            # TODO - Ant - What if this isn't == ?
            if resolved_entity["RESOLVED_ENTITY"]["ENTITY_ID"] == entity_id:
                for dsrc_record in resolved_entity["RESOLVED_ENTITY"]["RECORDS"]:
                    if dsrc_record["INTERNAL_ID"] == internal_id:
                        best_entity = resolved_entity
                        best_record = dsrc_record
                        break

        if not best_record or "FEATURES" not in best_record:
            print("\nno features found for resolved entity %s, internal ID %s\n" % (entity_id, internal_id))
            return {}

        features = self.buildout_record_features(best_record["FEATURES"], best_entity["RESOLVED_ENTITY"]["FEATURES"])
        return features

    # ---------------------------
    def buildout_record_features(self, recordFeatures, featureData):
        features = {}
        for feat_record in recordFeatures:
            lib_feat_id = feat_record["LIB_FEAT_ID"]
            usage_type = feat_record.get("USAGE_TYPE", "")
            if lib_feat_id not in features:
                features[feat_record["LIB_FEAT_ID"]] = {}
                features[lib_feat_id]["ftypeId"] = -1
                features[lib_feat_id]["ftypeCode"] = "unknown"
                features[lib_feat_id]["usageType"] = usage_type
                features[lib_feat_id]["featDesc"] = "missing %s" % lib_feat_id
                features[lib_feat_id]["isCandidate"] = "N"
                features[lib_feat_id]["isScored"] = "N"
                features[lib_feat_id]["entityCount"] = -1
                features[lib_feat_id]["candidateCapReached"] = "N"
                features[lib_feat_id]["scoringCapReached"] = "N"
                features[lib_feat_id]["scoringWasSuppressed"] = "N"

        for ftype_code in featureData:
            for distinct_feature_record in featureData[ftype_code]:
                for feat_record in distinct_feature_record["FEAT_DESC_VALUES"]:
                    lib_feat_id = feat_record["LIB_FEAT_ID"]
                    if lib_feat_id in features:
                        features[lib_feat_id]["ftypeId"] = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                        features[lib_feat_id]["ftypeCode"] = ftype_code
                        # disabled here in favor of the record level usage type
                        # features[libFeatId]['usageType'] = distinctFeatureRecord.get('USAGE_TYPE','')
                        features[lib_feat_id]["featDesc"] = feat_record["FEAT_DESC"]
                        features[lib_feat_id]["isCandidate"] = feat_record["USED_FOR_CAND"]
                        features[lib_feat_id]["isScored"] = feat_record["USED_FOR_SCORING"]
                        features[lib_feat_id]["entityCount"] = feat_record["ENTITY_COUNT"]
                        features[lib_feat_id]["candidateCapReached"] = feat_record["CANDIDATE_CAP_REACHED"]
                        features[lib_feat_id]["scoringCapReached"] = feat_record["SCORING_CAP_REACHED"]
                        features[lib_feat_id]["scoringWasSuppressed"] = feat_record["SUPPRESSED"]

        return features

    # ---------------------------
    def why_add_match_info(self, features, matchInfo, default_side="INBOUND"):
        other_side = "CANDIDATE" if default_side == "INBOUND" else "INBOUND"

        why_key = {}
        why_key["matchKey"] = matchInfo["WHY_KEY"]
        why_key["ruleCode"] = self.getRule_desc(matchInfo["WHY_ERRULE_CODE"])
        why_key["anyCandidates"] = False

        # update from candidate section of why
        if "CANDIDATE_KEYS" in matchInfo:
            for ftype_code in matchInfo["CANDIDATE_KEYS"]:
                ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                for feat_record in matchInfo["CANDIDATE_KEYS"][ftype_code]:
                    lib_feat_id = feat_record["FEAT_ID"]
                    if lib_feat_id not in features:
                        print("warning: candidate feature %s not in record!" % lib_feat_id)
                        continue
                    features[lib_feat_id]["ftypeCode"] = ftype_code
                    features[lib_feat_id]["ftypeId"] = ftype_id
                    features[lib_feat_id]["wasCandidate"] = "Yes"
                    features[lib_feat_id]["matchScore"] = 100
                    features[lib_feat_id]["matchLevel"] = "SAME"
                    why_key["anyCandidates"] = True

        # update from scoring section of why
        for ftype_code in matchInfo["FEATURE_SCORES"]:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            best_score_record = {}
            for feat_record in matchInfo["FEATURE_SCORES"][ftype_code]:
                # if featRecord.get('scoringWasSuppressed','No') == 'Yes':
                #    continue
                # BUG WHERE INBOUND/CANDIDATE IS SOMETIMES REVERSED...
                if feat_record[default_side + "_FEAT_ID"] in features:
                    lib_feat_id = feat_record[default_side + "_FEAT_ID"]
                    matched_feat_id = feat_record[other_side + "_FEAT_ID"]
                    matched_feat_desc = feat_record[other_side + "_FEAT_DESC"]
                elif feat_record[other_side + "_FEAT_ID"] in features:
                    lib_feat_id = feat_record[other_side + "_FEAT_ID"]
                    matched_feat_id = feat_record[default_side + "_FEAT_ID"]
                    matched_feat_desc = feat_record[default_side + "_FEAT_DESC"]
                else:
                    print("warning: scored feature %s not in either record!" % lib_feat_id)
                    continue

                feat_record = self.why_set_match_score(feat_record)
                match_score = feat_record["MATCH_SCORE"]
                match_score_display = feat_record["MATCH_SCORE_DISPLAY"]
                match_level = feat_record["SCORE_BUCKET"]
                feat_behavior = feat_record["SCORE_BEHAVIOR"]

                if "matchScore" not in best_score_record or match_score > best_score_record["matchScore"]:
                    best_score_record["libFeatId"] = lib_feat_id
                    best_score_record["matchScore"] = match_score
                    best_score_record["matchScoreDisplay"] = match_score_display
                    best_score_record["matchLevel"] = match_level
                    best_score_record["matchedFeatId"] = matched_feat_id
                    best_score_record["matchedFeatDesc"] = matched_feat_desc
                    best_score_record["featBehavior"] = feat_behavior

            # and bestScoreRecord['libFeatId'] in features) or not : #--adjusted for how
            if best_score_record:
                lib_feat_id = best_score_record["libFeatId"]
                if lib_feat_id not in features:  # adjusted for how
                    # input(f'hit how adjustment on {libFeatId}, press any key')
                    features[lib_feat_id] = {}
                features[lib_feat_id]["libFeatId"] = lib_feat_id
                features[lib_feat_id]["ftypeId"] = ftype_id
                features[lib_feat_id]["ftypeCode"] = ftype_code
                features[lib_feat_id]["wasScored"] = "Yes"
                features[lib_feat_id]["matchScore"] = best_score_record["matchScore"]
                features[lib_feat_id]["matchScoreDisplay"] = best_score_record["matchScoreDisplay"]
                features[lib_feat_id]["matchLevel"] = best_score_record["matchLevel"]
                features[lib_feat_id]["matchedFeatId"] = best_score_record["matchedFeatId"]
                features[lib_feat_id]["matchedFeatDesc"] = best_score_record["matchedFeatDesc"]
                features[lib_feat_id]["featBehavior"] = best_score_record["featBehavior"]

        return why_key, features

    # ---------------------------
    def why_set_match_score(self, feat_record):
        if "GNR_FN" in feat_record["ADDITIONAL_SCORES"]:
            match_score = feat_record["ADDITIONAL_SCORES"]["GNR_FN"]
            if "GNR_ON" in feat_record and feat_record["GNR_ON"] >= 0:
                match_score_display = "org:%s" % feat_record["GNR_ON"]
            else:
                # matchScoreDisplay = "full:%s" % featRecord["GNR_FN"]
                match_score_display = f"full:{feat_record['ADDITIONAL_SCORES']['GNR_FN']}"
                if "GNR_GN" in feat_record and feat_record["GNR_GN"] >= 0:
                    match_score_display += "|giv:%s" % feat_record["GNR_GN"]
                if "GNR_SN" in feat_record and feat_record["GNR_SN"] >= 0:
                    match_score_display += "|sur:%s" % feat_record["GNR_SN"]
        elif "BT_FN" in feat_record:
            match_score = feat_record["BT_FN"]
            if "BT_ON" in feat_record and feat_record["BT_ON"] > 0:
                match_score_display = "org:%s" % feat_record["BT_ON"]
            else:
                match_score_display = "full:%s" % feat_record["BT_FN"]
        else:
            match_score = feat_record["ADDITIONAL_SCORES"]["FULL_SCORE"]
            match_score_display = "full:" + str(feat_record["ADDITIONAL_SCORES"]["FULL_SCORE"])

        feat_record["MATCH_SCORE"] = match_score
        feat_record["MATCH_SCORE_DISPLAY"] = match_score_display

        return feat_record

    # ---------------------------
    def help_how(self):
        entity_id = self.colorize_entity("<entity_id>")
        print(
            textwrap.dedent(
                f"""\

            Shows shows how the records in a single entity came together.

            {self.colorize('Syntax:', 'highlight2')}
                how {entity_id}            {self.colorize('shows a summary of the resolution process', 'dim')}
                how {entity_id} concise    {self.colorize('shows the matching features as part of the tree view', 'dim')}
                how {entity_id} formatted  {self.colorize('shows the matching features in a table', 'dim')}

            {self.colorize('How to read:', 'highlight2')}
                A how report documents each step of the resolution process for an entity so if
                an entity has 100s records there will be 100s of steps. Each step will either
                create a virtual entity, add to it or combine it with other virtual entities
                that were created created along the way.

                For instance, there may be a set of records (a virtual entity) that match on name
                and address and another set that match on name and phone before a record with the
                same name, address and phone combines the two virtual entities into one!

            {self.colorize('Pro tip!', 'good')}
                The overview section helps you locate interesting resolution steps that you
                can search for in the concise or formatted view.  You can search for ...
                    - a particular step number such as step "2"
                    - a virtual entity_id such as {self.colorize_entity('V123-S2', 'dim')}
                        {self.colorize('(the -S number after the virtual entity ID is the step number that updated it.  Try', 'italics')}
                            {self.colorize('searching for just the V number before the dash to find all steps that include it.)', 'italics')}
                    - any other string such as a match_key, principle code, specific name, address, etc
             """
            )
        )

    def do_how(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_how()
            return -1 if caller else 0

        display_level = "overview"
        for level in ["stats", "columnar", "brief", "table", "verbose"]:
            if level in arg:
                display_level = level
                arg = arg.replace(level, "").strip()

        try:
            entity_id = int(arg)
        except:
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return -1 if caller else 0

        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]
        try:
            entity_json = self.call_sdk("get_entity_by_entity_id", get_flag_list, entity_id)
        except SzError as err:
            print_message(err, "error")
            return
        how_flag_list = ["SZ_HOW_ENTITY_DEFAULT_FLAGS"]
        try:
            how_json = self.call_sdk("how_entity_by_entity_id", how_flag_list, entity_id)
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0
        how_data = self.get_how_data(how_json, entity_json)
        print(how_data["ROOT_NODE"].render_tree())
        print("wait2")

        step_data = how_data["ALL_STEPS"]

        how_report = "How report"

        if display_level == "table":
            for step_num in sorted(step_data.keys()):
                how_report += f"\nStep {step_num}\n"
                entities = {}
                for entity in step_data[step_num]["ENTITY_LIST"]:
                    virtual_id = entity["VIRTUAL_ID"]
                    # debug_print(entity["FEATURES"])
                    features = {
                        x: entity["FEATURES"][x]
                        for x in entity["FEATURES"].keys()
                        if entity["FEATURES"][x]["USED_FOR_SCORING"] == "Y"
                    }
                    entities[virtual_id] = {
                        "ENTITY_ID": virtual_id,
                        "FEATURES": features,
                        "RECORDS": entity["RECORDS"],
                        "MATCH_INFO": step_data[step_num]["MATCH_INFO"],
                    }
                how_report += self.why_display2(entities, "VIRTUAL ID", "")

        self.show_report2(how_report, auto_scroll=True)

    # ---------------------------
    def do_how2(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_how()
            return -1 if caller else 0

        how_display_level = "overview"
        for level in ["summary", "columnar", "brief", "table", "verbose"]:
            if level in arg:
                how_display_level = level
                arg = arg.replace(level, "").strip()

        try:
            entity_id = int(arg)
        except:
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return -1 if caller else 0

        # do get first
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]

        try:
            get_entity_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0

        stat_pack = {
            "steps": {},
            "features": {},
            "rules": {},
            "ftype_counter": {},
            "rule_counter": {},
        }

        # build record feature matrix
        total_record_count = 0
        total_feature_count = 0
        features_by_record = {}
        for record_data in get_entity_data["RESOLVED_ENTITY"]["RECORDS"]:
            total_record_count += 1
            if record_data["DATA_SOURCE"] not in features_by_record:
                features_by_record[record_data["DATA_SOURCE"]] = {}
            features_by_record[record_data["DATA_SOURCE"]][record_data["RECORD_ID"]] = self.buildout_record_features(
                record_data["FEATURES"],
                get_entity_data["RESOLVED_ENTITY"]["FEATURES"],
            )

            # accumulate feature stats
            for lib_feat_id in features_by_record[record_data["DATA_SOURCE"]][record_data["RECORD_ID"]]:
                feature_data = features_by_record[record_data["DATA_SOURCE"]][record_data["RECORD_ID"]][lib_feat_id]
                ftype_id = feature_data["ftypeId"]
                counter_display = self.feature_counter_display(feature_data)
                feat_desc = f"{self.colorize(lib_feat_id, 'dim')}: {feature_data['featDesc']} {counter_display}"

                if ftype_id not in stat_pack["features"]:
                    stat_pack["features"][ftype_id] = {}
                if ftype_id not in stat_pack["ftype_counter"]:
                    stat_pack["ftype_counter"][ftype_id] = {}
                    stat_pack["ftype_counter"][ftype_id]["featureCount"] = 0
                    stat_pack["ftype_counter"][ftype_id]["candidateCapReached"] = 0
                    stat_pack["ftype_counter"][ftype_id]["scoringCapReached"] = 0
                    stat_pack["ftype_counter"][ftype_id]["scoringWasSuppressed"] = 0
                if feat_desc not in stat_pack["features"][ftype_id]:
                    total_feature_count += 1
                    stat_pack["features"][ftype_id][feat_desc] = 1
                    stat_pack["ftype_counter"][ftype_id]["featureCount"] += 1
                    for threshold in [
                        "candidateCapReached",
                        "scoringCapReached",
                        "scoringWasSuppressed",
                    ]:
                        if feature_data[threshold] == "Y":
                            stat_pack["ftype_counter"][ftype_id][threshold] += 1
                else:
                    stat_pack["features"][ftype_id][feat_desc] += 1

        how_flag_list = ["SZ_HOW_ENTITY_DEFAULT_FLAGS"]
        try:
            json_data = self.call_sdk("how_entity_by_entity_id", how_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0

        entity_name = get_entity_data["RESOLVED_ENTITY"].get("ENTITY_NAME", "name not mapped")
        how_header = (
            "\n"
            + self.colorize(
                f"How report for entity {self.colorize_entity(entity_id)}: {entity_name}",
                "table_title",
            )
            + "\n"
        )
        if (
            json_data["HOW_RESULTS"]["FINAL_STATE"].get("NEED_REEVALUATION", 0)
            or len(json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]) > 1
        ):
            final_entity_count = len(json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"])
            how_header += (
                "\n" + self.colorize(f"{final_entity_count} final entities, reevaluation needed!", "bad") + "\n"
            )
            # - maybe start with concise view if multiple
            # if how_display_level == 'overview'
            #     how_display_level = 'concise'

        # annotate steps and create aggregate dictionary
        stat_pack["largest_combine_steps"] = {}
        stat_pack["lowest_feature_scores"] = {}
        stat_pack["name_not_scored"] = []

        step_count = 0
        aggregate_nodes = {}
        resolution_steps = {}
        for step_data in json_data["HOW_RESULTS"]["RESOLUTION_STEPS"]:
            step_count += 1
            step_num = step_data["STEP"]

            step_data["MATCH_INFO"]["WHY_KEY"] = step_data["MATCH_INFO"]["MATCH_KEY"]
            step_data["MATCH_INFO"]["WHY_ERRULE_CODE"] = step_data["MATCH_INFO"]["ERRULE_CODE"]
            for virtual_entity_num in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]:
                default_side = (
                    "INBOUND"
                    if step_data["INBOUND_VIRTUAL_ENTITY_ID"] == step_data[virtual_entity_num]["VIRTUAL_ENTITY_ID"]
                    else "CANDIDATE"
                )
                step_data[virtual_entity_num].update(
                    self.get_virtual_entity_data(step_data[virtual_entity_num], features_by_record)
                )
                features = step_data[virtual_entity_num]["features"]
                why_key, features = self.why_add_match_info(features, step_data["MATCH_INFO"], default_side)
                step_data[virtual_entity_num]["features"] = features

            step_data["singleton_nodes"] = []
            step_data["aggregate_nodes"] = []
            for virtual_entity in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]:
                if step_data[virtual_entity]["node_type"] == "singleton":
                    step_data["singleton_nodes"].append(step_data[virtual_entity]["VIRTUAL_ENTITY_ID"])
                else:
                    step_data["aggregate_nodes"].append(step_data[virtual_entity]["VIRTUAL_ENTITY_ID"])

            if len(step_data["singleton_nodes"]) == 2:
                step_data["step_type"] = "Create virtual entity"
            elif len(step_data["aggregate_nodes"]) == 2:
                step_data["step_type"] = "Combine virtual entities"
                lowest_member_count = (
                    step_data["VIRTUAL_ENTITY_1"]["member_count"]
                    if step_data["VIRTUAL_ENTITY_1"]["member_count"] < step_data["VIRTUAL_ENTITY_2"]["member_count"]
                    else step_data["VIRTUAL_ENTITY_2"]["member_count"]
                )
                total_member_count = (
                    step_data["VIRTUAL_ENTITY_1"]["member_count"] + step_data["VIRTUAL_ENTITY_2"]["member_count"]
                )
                if lowest_member_count not in stat_pack["largest_combine_steps"]:
                    stat_pack["largest_combine_steps"][lowest_member_count] = [[step_num, total_member_count]]
                else:
                    stat_pack["largest_combine_steps"][lowest_member_count].append([step_num, total_member_count])
            else:
                step_data["step_type"] = "Add record to virtual entity"

            if step_data["step_type"] not in stat_pack["steps"]:
                stat_pack["steps"][step_data["step_type"]] = 1
            else:
                stat_pack["steps"][step_data["step_type"]] += 1

            step_data["MATCH_INFO"]["matchKey"] = step_data["MATCH_INFO"]["MATCH_KEY"]
            step_data["MATCH_INFO"]["ruleCode"] = self.getRule_desc(step_data["MATCH_INFO"]["ERRULE_CODE"])
            formatted_match_key, formatted_errule_code = self.colorize_match_data(step_data["MATCH_INFO"]).split("\n ")
            step_data["MATCH_INFO"]["formatted_match_key"] = formatted_match_key
            step_data["MATCH_INFO"]["formatted_errule_code"] = formatted_errule_code
            if formatted_errule_code not in stat_pack["rules"]:
                stat_pack["rules"][formatted_errule_code] = {}
                stat_pack["rule_counter"][formatted_errule_code] = 1
            else:
                stat_pack["rule_counter"][formatted_errule_code] += 1
            if formatted_match_key not in stat_pack["rules"][formatted_errule_code]:
                stat_pack["rules"][formatted_errule_code][formatted_match_key] = 1
            else:
                stat_pack["rules"][formatted_errule_code][formatted_match_key] += 1

            # format the features and find the lowest scoring
            for lib_feat_id in step_data["VIRTUAL_ENTITY_2"]["features"]:
                feature_data = step_data["VIRTUAL_ENTITY_2"]["features"][lib_feat_id]
                feature_data = self.why_format_feature(feature_data, step_data["MATCH_INFO"])
                step_data["VIRTUAL_ENTITY_2"]["features"][lib_feat_id] = feature_data

            name_was_scored = False
            for lib_feat_id in step_data["VIRTUAL_ENTITY_1"]["features"]:
                feature_data = step_data["VIRTUAL_ENTITY_1"]["features"][lib_feat_id]
                print(feature_data)
                feature_data = self.why_format_feature(feature_data, step_data["MATCH_INFO"])
                step_data["VIRTUAL_ENTITY_1"]["features"][lib_feat_id] = feature_data

                ftype_id = feature_data["ftypeId"]
                ftype_code = feature_data["ftypeCode"]
                if feature_data.get("wasScored", "No") == "Yes" and ftype_code in step_data["MATCH_INFO"]["MATCH_KEY"]:
                    match_score = feature_data["matchScore"]
                    if ftype_id not in stat_pack["lowest_feature_scores"]:
                        stat_pack["lowest_feature_scores"][ftype_id] = {}
                    if match_score not in stat_pack["lowest_feature_scores"][ftype_id]:
                        stat_pack["lowest_feature_scores"][ftype_id][match_score] = [step_num]
                    else:
                        stat_pack["lowest_feature_scores"][ftype_id][match_score].append(step_num)
                    if ftype_code == "NAME":
                        name_was_scored = True
            if not name_was_scored:
                stat_pack["name_not_scored"].append(step_num)

            resolution_steps[step_num] = step_data
            new_virtual_id = step_data.get("RESULT_VIRTUAL_ENTITY_ID", None)
            if new_virtual_id:
                # if new_virtual_id in aggregate_nodes:
                # print(json.dumps(step_data, indent=4))
                # print(f'\nunexpected: multiple steps for {new_virtual_id} {step_num} and ' + aggregate_nodes[new_virtual_id]['final_step'])
                # input('wait')
                aggregate_nodes[new_virtual_id] = {
                    "final_step": step_num,
                    "all_steps": [],
                }

        # start from the end and combine the prior steps that just add another singleton
        orphan_final_entity_data = {}
        render_node_list = []
        for final_virtual_data in json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]:
            final_virtual_id = final_virtual_data["VIRTUAL_ENTITY_ID"]
            render_node_list.append({"node_id": final_virtual_id, "parent_node": "root", "step_num": 999999})

            current_aggregate_list = [final_virtual_id]
            while current_aggregate_list:
                current_node_id = current_aggregate_list[-1]

                # if there are no steps for this final node it became a orphan singleton
                if current_node_id not in aggregate_nodes:
                    orphan_final_entity_data[current_node_id] = self.get_virtual_entity_data(
                        final_virtual_data, features_by_record
                    )
                    current_aggregate_list.pop()
                else:
                    # keep going down chain until two singletons or two aggregates
                    aggregate_node_id = current_node_id
                    while True:
                        prior_step = aggregate_nodes[aggregate_node_id]["final_step"]
                        aggregate_nodes[current_node_id]["all_steps"].append(prior_step)
                        if len(resolution_steps[prior_step]["aggregate_nodes"]) == 1:
                            aggregate_node_id = resolution_steps[prior_step]["aggregate_nodes"][0]
                        else:
                            break

                    # if ended on step with two aggregates, each must be traversed
                    current_aggregate_list.pop()
                    if len(resolution_steps[prior_step]["aggregate_nodes"]) == 2:
                        for aggregate_node_id in resolution_steps[prior_step]["aggregate_nodes"]:
                            step_num = (
                                int(aggregate_node_id[aggregate_node_id.find("S") + 1 :])
                                if "S" in aggregate_node_id
                                else 0
                            )
                            current_aggregate_list.append(aggregate_node_id)
                            render_node_list.append(
                                {
                                    "node_id": aggregate_node_id,
                                    "parent_node": current_node_id,
                                    "step_num": step_num,
                                }
                            )

        # create overview tree
        summary_node = Node("summary")
        summary_node.node_desc = self.colorize("SUMMARY", "highlight1")

        resolution_node = Node("resolution")
        resolution_node.node_desc = self.how_format_statistic_header("RESOLUTION SUMMARY")
        summary_node.add_child(resolution_node)

        category_node = Node("steps")
        category_node.node_desc = self.how_format_statistic("Resolution steps", step_count)
        for item in stat_pack["steps"]:
            item_node = Node(item)
            item_node.node_desc = self.colorize(self.how_format_statistic(item, stat_pack["steps"][item]), "italics")
            category_node.add_child(item_node)
        resolution_node.add_child(category_node)

        interesting_step_list = []
        for step_num in stat_pack["name_not_scored"]:
            interesting_step_list.append([step_num, "name not scored"])
        for ftype_id in sorted(stat_pack["lowest_feature_scores"]):
            ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
            cntr = 0
            for lowest_score in sorted(stat_pack["lowest_feature_scores"][ftype_id]):
                if lowest_score < 90:
                    for step_num in stat_pack["lowest_feature_scores"][ftype_id][lowest_score]:
                        interesting_step_list.append([step_num, f"{ftype_code} scored {lowest_score}"])
                    cntr += 1
                if cntr == 2:
                    break
        cntr = 0
        for lowest_member_count in sorted(stat_pack["largest_combine_steps"], reverse=True):
            for large_step_info in sorted(
                stat_pack["largest_combine_steps"][lowest_member_count],
                key=lambda k: k[1],
                reverse=True,
            ):
                step_num = large_step_info[0]
                highest_member_count = large_step_info[1] - lowest_member_count
                interesting_step_list.append(
                    [
                        step_num,
                        f"Combines a group of {lowest_member_count} with a group of {highest_member_count}",
                    ]
                )
            cntr += 1
            if cntr == 2:
                break
        if interesting_step_list:
            interesting_step_data = {}
            for step_num, reason in interesting_step_list:
                if step_num not in interesting_step_data:
                    interesting_step_data[step_num] = [reason]
                else:
                    interesting_step_data[step_num].append(reason)

            category_node = Node("interesting steps")
            category_node.node_desc = self.how_format_statistic("Steps of interest", len(interesting_step_data))
            for step_num in sorted(interesting_step_data.keys()):
                step_prefix = f"Step {step_num} - "
                interesting_step_node = Node(step_num)
                interesting_step_node.node_desc = ""
                for reason in interesting_step_data[step_num]:
                    interesting_step_node.node_desc += step_prefix + reason
                    step_prefix = " " * len(step_prefix)
                category_node.add_child(interesting_step_node)
            resolution_node.add_child(category_node)

        category_node = Node("rules")
        category_node.node_desc = "Principles used"
        resolution_node.add_child(category_node)
        for rule_info in sorted(stat_pack["rule_counter"].items(), key=lambda item: item[1], reverse=True):
            rule = rule_info[0]
            rule_node = Node(rule)
            rule_cnt = self.colorize(f"({rule_info[1]})", "highlight2")
            rule_node.node_desc = f"{rule} {rule_cnt}"
            category_node.add_child(rule_node)
            for match_key_info in sorted(stat_pack["rules"][rule].items(), key=lambda item: item[1], reverse=True):
                match_key = match_key_info[0]
                match_key_node = Node(match_key)
                match_key_cnt = self.colorize(f"({match_key_info[1]})", "highlight2")
                match_key_node.node_desc = f"{match_key} {match_key_cnt}"
                rule_node.add_child(match_key_node)

        category_node = Node("entity")
        category_node.node_desc = self.how_format_statistic_header("ENTITY SUMMARY")
        summary_node.add_child(category_node)

        for stat_data in [
            ["Total record count", total_record_count],
            ["Total feature count", total_feature_count],
        ]:
            item_node = Node(stat_data[0])
            item_node.node_desc = self.how_format_statistic(stat_data[0], stat_data[1])
            category_node.add_child(item_node)

        for ftype_id in sorted(stat_pack["features"], key=lambda k: self.ftype_id_order[k]):
            ftype_node = Node(ftype_id)
            ftype_cnt = self.colorize(
                f"({stat_pack['ftype_counter'][ftype_id]['featureCount']})",
                "highlight2",
            )
            ftype_node.node_desc = f"{self.colorize_attr(self.ftype_lookup[ftype_id]["FTYPE_CODE"])} {ftype_cnt}"
            category_node.add_child(ftype_node)
            feat_desc_info_list = sorted(
                stat_pack["features"][ftype_id].items(),
                key=lambda item: item[1],
                reverse=True,
            )
            cnt = 0
            for feat_desc_info in feat_desc_info_list:
                cnt += 1
                if cnt in (
                    1,
                    2,
                    len(feat_desc_info_list),
                    len(feat_desc_info_list) - 1,
                ):
                    feat_desc = feat_desc_info[0]
                    feat_node = Node(feat_desc)
                    feat_cnt = self.colorize(f"({feat_desc_info[1]})", "highlight2")
                    if any(i in feat_desc for i in ["[~", "[!", "[#"]):
                        feat_desc = self.colorize(feat_desc, "dim")
                    feat_node.node_desc = f"{feat_desc} {feat_cnt}"
                    ftype_node.add_child(feat_node)
                elif cnt == 3 and len(feat_desc_info_list) > 4:
                    ftype_node.add_child(Node("~~~"))

        columnar_data = {}
        tree_nodes = {}
        filter_str = None
        while True:
            tree_nodes["root"] = Node("root")
            tree_nodes["root"].node_desc = self.colorize("RESOLUTION STEPS", "bold")
            for render_node_data in sorted(render_node_list, key=lambda x: x["step_num"], reverse=True):
                render_node_id = render_node_data["node_id"]
                parent_node_id = render_node_data["parent_node"]

                # describe the node
                colored_node_id = self.colorize_entity(render_node_id)
                if parent_node_id == "root":
                    num_final_nodes = len(json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"])
                    final_node_index = 0
                    for final_state_data in json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]:
                        final_node_index += 1
                        if final_state_data["VIRTUAL_ENTITY_ID"] == render_node_id:
                            break
                    if num_final_nodes == 1:
                        render_node_desc = self.colorize(f"{colored_node_id}: final entity", "dim")
                    else:
                        render_node_desc = self.colorize(
                            f"{colored_node_id}: final entity {final_node_index} of {num_final_nodes}",
                            "dim",
                        )
                else:
                    render_node_desc = self.colorize(f"{colored_node_id}: interim entity", "dim")

                tree_nodes[render_node_id] = Node(render_node_id)
                tree_nodes[render_node_id].node_desc = render_node_desc
                tree_nodes[parent_node_id].add_child(tree_nodes[render_node_id])
                tree_nodes[render_node_id].add_parent(tree_nodes[parent_node_id])

                # there are no prior steps, this final node is a singleton
                if render_node_id not in aggregate_nodes:
                    orphan_entity_data = orphan_final_entity_data[render_node_id]
                    step_node_id = f"orphan-{render_node_id}"
                    tree_nodes[step_node_id] = Node(step_node_id)
                    tree_nodes[step_node_id].node_desc = "Singleton"
                    tree_nodes[step_node_id].node_text = (
                        f"{orphan_entity_data['colored_desc']} {orphan_entity_data['entity_name']}"
                    )
                    tree_nodes[render_node_id].add_child(tree_nodes[step_node_id])
                    tree_nodes[step_node_id].add_parent(tree_nodes[render_node_id])

                # go through all the steps that built this node
                else:
                    for step_num in sorted(aggregate_nodes[render_node_id]["all_steps"], reverse=True):
                        step_data = resolution_steps[step_num]
                        step_node_id = f"Step {step_num}"
                        step_node_desc = step_node_id + ": " + step_data["step_type"]
                        step_node_desc += f" on {step_data['MATCH_INFO']['formatted_match_key']} {step_data['MATCH_INFO']['formatted_errule_code']}"

                        # always ensure lone singleton is on the left
                        if (
                            step_data["VIRTUAL_ENTITY_1"]["node_type"] != "singleton"
                            and step_data["VIRTUAL_ENTITY_2"]["node_type"] == "singleton"
                        ):
                            left_virtual_entity = "VIRTUAL_ENTITY_2"
                            right_virtual_entity = "VIRTUAL_ENTITY_1"
                        else:
                            left_virtual_entity = "VIRTUAL_ENTITY_1"
                            right_virtual_entity = "VIRTUAL_ENTITY_2"

                        left_features = step_data[left_virtual_entity]["features"]
                        right_features = step_data[right_virtual_entity]["features"]

                        # find the best matching record for each side
                        #  to make selection of best matching feature less arbitrary
                        left_matching_record_list = {}
                        right_matching_record_list = {}
                        for lib_feat_id in left_features:
                            if left_features[lib_feat_id].get("wasScored", "No") == "Yes":
                                for record_key in left_features[lib_feat_id]["record_list"]:
                                    if record_key not in left_matching_record_list:
                                        left_matching_record_list[record_key] = []
                                    left_matching_record_list[record_key].append(lib_feat_id)

                                matched_feat_id = left_features[lib_feat_id]["matchedFeatId"]
                                if matched_feat_id in right_features:
                                    for record_key in right_features[matched_feat_id]["record_list"]:
                                        if record_key not in right_matching_record_list:
                                            right_matching_record_list[record_key] = []
                                        right_matching_record_list[record_key].append(matched_feat_id)
                                else:
                                    record_key = "MISSING!"
                                    input(
                                        f"note1: step {step_num}, right side missing {lib_feat_id} {left_features[lib_feat_id].get('ftypeCode', '?')} \"{left_features[lib_feat_id].get('featDesc', '?')}\", press any key ..."
                                    )
                                    if record_key not in right_matching_record_list:
                                        right_matching_record_list[record_key] = []
                                    right_matching_record_list[record_key].append(matched_feat_id)

                        best_left_record_key = sorted(
                            sorted(
                                [
                                    {"key": i, "len": len(left_matching_record_list[i])}
                                    for i in left_matching_record_list
                                ],
                                key=lambda k: k["key"],
                            ),
                            key=lambda k: k["len"],
                            reverse=True,
                        )[0]["key"]
                        best_right_record_key = sorted(
                            sorted(
                                [
                                    {
                                        "key": i,
                                        "len": len(right_matching_record_list[i]),
                                    }
                                    for i in right_matching_record_list
                                ],
                                key=lambda k: k["key"],
                            ),
                            key=lambda k: k["len"],
                            reverse=True,
                        )[0]["key"]

                        # gather the features to display by type for each side
                        features_by_type = {}
                        for side_data in [
                            [
                                "left",
                                left_features,
                                right_features,
                                best_left_record_key,
                                best_right_record_key,
                            ],
                            [
                                "right",
                                right_features,
                                left_features,
                                best_right_record_key,
                                best_left_record_key,
                            ],
                        ]:
                            side = side_data[0]
                            features1 = side_data[1]
                            features2 = side_data[2]
                            best_record_key1 = side_data[3]
                            best_record_key2 = side_data[4]

                            for lib_feat_id in features1:
                                feature_data = features1[lib_feat_id]

                                ftype_id = feature_data["ftypeId"]
                                if ftype_id not in features_by_type:
                                    features_by_type[ftype_id] = {
                                        "left": [],
                                        "right": [],
                                    }

                                # get the best record keys for each side
                                matched_feat_id = feature_data.get("matchedFeatId")
                                if matched_feat_id:
                                    if best_record_key1 in features1[lib_feat_id]["record_list"]:
                                        feature_data["record_key1"] = best_record_key1
                                    else:
                                        feature_data["record_key1"] = features1[lib_feat_id]["record_list"][0]

                                    if matched_feat_id not in features2:
                                        feature_data["record_key2"] = "ERROR" + self.dsrc_record_sep + "MISSING"
                                        input(
                                            f"note: step {step_num}, {side} side missing {matched_feat_id} {feature_data.get('ftypeCode', '?')} \"{feature_data.get('featDesc', '?')}\", press any key ..."
                                        )

                                    else:
                                        if best_record_key2 in features2[matched_feat_id]["record_list"]:
                                            feature_data["record_key2"] = best_record_key2
                                        else:
                                            feature_data["record_key2"] = features2[matched_feat_id]["record_list"][0]

                                # skip unmatched if not showing full detail
                                elif how_display_level != "verbose":
                                    continue

                                features_by_type[ftype_id][side].append(feature_data)

                        colored_virtual_id1 = self.colorize_entity(
                            step_data[left_virtual_entity]["VIRTUAL_ENTITY_ID"], "dim"
                        )
                        colored_virtual_id2 = self.colorize_entity(
                            step_data[right_virtual_entity]["VIRTUAL_ENTITY_ID"], "dim"
                        )

                        if how_display_level == "columnar":
                            for step_num in sorted(resolution_steps.keys()):
                                for virtual_entity in [
                                    resolution_steps[step_num][tag] for tag in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]
                                ]:
                                    if virtual_entity["node_type"] == "singleton":
                                        step_key = f"{step_num:05}-{virtual_entity['VIRTUAL_ENTITY_ID']}"

                                        columnar_data[step_key] = {
                                            "dataSources": self.why_fmt_record_list(
                                                virtual_entity["MEMBER_RECORDS"][0]["RECORDS"]
                                            ),
                                            "whyKey": {
                                                "matchKey": resolution_steps[step_num]["MATCH_INFO"]["MATCH_KEY"],
                                                "ruleCode": resolution_steps[step_num]["MATCH_INFO"]["ERRULE_CODE"],
                                            },
                                            "features": virtual_entity["features"],
                                        }

                        elif how_display_level == "brief":
                            step_node_desc += f"\n{colored_virtual_id1} {step_data[left_virtual_entity]['colored_desc']} {step_data[left_virtual_entity]['entity_name']}"
                            if not step_data["step_type"].startswith("Add"):
                                step_node_desc += f"\n{colored_virtual_id2} {step_data[right_virtual_entity]['colored_desc']} {step_data[right_virtual_entity]['entity_name']}"

                            step_node_text = ""
                            for ftype_id in sorted(
                                features_by_type.keys(),
                                key=lambda k: self.ftype_id_order[k],
                            ):
                                for feature_data in sorted(
                                    sorted(
                                        features_by_type[ftype_id]["left"],
                                        key=lambda k: (k["featDesc"]),
                                    ),
                                    key=lambda k: (k["sortOrder"]),
                                ):
                                    color_ftype_code = self.colorize_attr(feature_data["ftypeCode"])
                                    color_record_key_1 = self.colorize_dsrc1(
                                        ": ".join(feature_data["record_key1"].split(self.dsrc_record_sep))
                                    )
                                    color_record_key_2 = self.colorize_dsrc1(
                                        ": ".join(feature_data["record_key2"].split(self.dsrc_record_sep))
                                    )
                                    colored_match_score = self.colorize(
                                        f"({feature_data['matchScoreDisplay']})",
                                        feature_data["featColor"],
                                    )
                                    step_node_text += f"{color_ftype_code}: {color_record_key_1} - {feature_data['featDesc']} | {color_record_key_2} - {feature_data['matchedFeatDesc']} {colored_match_score}\n"
                        elif how_display_level != "summary":
                            row_title = self.colorize("VIRTUAL_ID", "dim")
                            tbl_title = None
                            tbl_columns = []
                            tbl_columns.append({"name": row_title, "width": 20, "align": "left"})
                            tbl_columns.append(
                                {
                                    "name": colored_virtual_id1,
                                    "width": 70,
                                    "align": "left",
                                }
                            )
                            tbl_columns.append(
                                {
                                    "name": self.colorize("scores", "dim"),
                                    "width": 10,
                                    "align": "center",
                                }
                            )
                            tbl_columns.append(
                                {
                                    "name": colored_virtual_id2,
                                    "width": 70,
                                    "align": "left",
                                }
                            )
                            tbl_rows = []

                            row_title = self.colorize("DATA_SOURCES", "row_title")
                            tbl_row = [row_title]
                            for virtual_entity_data in [
                                [left_virtual_entity, best_left_record_key],
                                [right_virtual_entity, best_right_record_key],
                            ]:
                                virtual_entity = virtual_entity_data[0]
                                best_record_key = virtual_entity_data[1]
                                if step_data[virtual_entity]["node_type"] == "singleton":
                                    dsrc_display = step_data[virtual_entity]["colored_desc"]
                                else:
                                    dsrc_display = (
                                        step_data[virtual_entity]["node_desc"]
                                        + "\n best: "
                                        + self.colorize_dsrc1(": ".join(best_record_key.split(self.dsrc_record_sep)))
                                    )
                                tbl_row.append(dsrc_display)
                            tbl_row.insert(2, "")  # for score column
                            tbl_rows.append(tbl_row)

                            for ftype_id in sorted(
                                features_by_type.keys(),
                                key=lambda k: self.ftype_id_order[k],
                            ):
                                if not features_by_type[ftype_id]["left"] and not features_by_type[ftype_id]["right"]:
                                    continue  # removes unscored if not full
                                ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
                                colored_ftype_code = self.colorize_attr(ftype_code)

                                # get the right side values
                                scored_right = {}
                                unscored_right = []
                                for feature_data in sorted(
                                    sorted(
                                        features_by_type[ftype_id]["right"],
                                        key=lambda k: (k["featDesc"]),
                                    ),
                                    key=lambda k: (k["sortOrder"]),
                                ):
                                    if feature_data.get("wasScored"):
                                        scored_right[feature_data["libFeatId"]] = feature_data
                                    else:
                                        unscored_right.append(feature_data["formattedFeatDesc1"])

                                # add all the scored ones from the lefts point of view
                                unscored_left = []
                                for feature_data in sorted(
                                    sorted(
                                        features_by_type[ftype_id]["left"],
                                        key=lambda k: (k["featDesc"]),
                                    ),
                                    key=lambda k: (k["sortOrder"]),
                                ):
                                    if feature_data.get("wasScored"):
                                        feature_score = "\n".join(
                                            self.colorize(item, feature_data["featColor"])
                                            for item in feature_data["matchScoreDisplay"].split("|")
                                        )

                                        feature_desc1 = feature_data["formattedFeatDesc1"]
                                        if step_data[left_virtual_entity]["node_type"] != "singleton":
                                            from_desc = "from: " + self.colorize_dsrc1(
                                                ": ".join(feature_data["record_key1"].split(self.dsrc_record_sep))
                                            )
                                            if feature_data["record_key1"] == best_left_record_key:
                                                from_desc = self.colorize(from_desc, "dim")
                                            feature_desc1 += "\n " + from_desc

                                        if feature_data["matchedFeatId"] not in scored_right:
                                            feature_desc2 = self.colorize(
                                                f"Internal error: {feature_data['matchedFeatId']} missing from {colored_virtual_id2}",
                                                "bad",
                                            )
                                            # input(feature_desc2 + ', press enter')
                                        else:
                                            feature_desc2 = scored_right[feature_data["matchedFeatId"]][
                                                "formattedFeatDesc1"
                                            ]
                                        if step_data[right_virtual_entity]["node_type"] != "singleton":
                                            from_desc = "from: " + self.colorize_dsrc1(
                                                ": ".join(feature_data["record_key2"].split(self.dsrc_record_sep))
                                            )
                                            if feature_data["record_key2"] == best_right_record_key:
                                                from_desc = self.colorize(from_desc, "dim")
                                            feature_desc2 += "\n " + from_desc

                                        tbl_rows.append(
                                            [
                                                colored_ftype_code,
                                                feature_desc1,
                                                feature_score,
                                                feature_desc2,
                                            ]
                                        )
                                    else:
                                        unscored_left.append(feature_data["formattedFeatDesc1"])

                                if unscored_right or unscored_left:
                                    tbl_rows.append(
                                        [
                                            colored_ftype_code,
                                            "\n".join(unscored_left),
                                            "",
                                            "\n".join(unscored_right),
                                        ]
                                    )

                            self.render_table(tbl_title, tbl_columns, tbl_rows, displayFlag="No")
                            step_node_text = self.current_report

                        if how_display_level != "columnar":
                            tree_nodes[step_node_id] = Node(step_node_id)
                            tree_nodes[step_node_id].node_desc = step_node_desc
                            tree_nodes[step_node_id].node_text = step_node_text
                            tree_nodes[render_node_id].add_child(tree_nodes[step_node_id])
                            tree_nodes[step_node_id].add_parent(tree_nodes[render_node_id])

            if how_display_level == "overview":
                how_report = summary_node.render_tree(filter_str)
            elif how_display_level == "columnar":
                self.why_display(columnar_data, "whyhow", "Step")
                how_report = self.current_report
            elif tree_nodes["root"].children:  # will be no children if singleton
                if filter_str and filter_str.startswith("~node~"):
                    filter_str = filter_str[6:]
                    # steps don't actually have children, must go to the parent entity and show tree from there
                    if tree_nodes[filter_str].children:
                        parent_node = tree_nodes[filter_str]
                    else:
                        parent_node = tree_nodes[filter_str].parents[0]
                    if parent_node.parents:
                        parent_node = parent_node.parents[0]
                    if parent_node.node_id != "root":
                        temp_node = Node("~~~")
                    else:
                        temp_node = parent_node
                    temp_node.add_child(parent_node)
                    how_report = temp_node.render_tree(filter_str)
                elif len(tree_nodes["root"].children) > 1:
                    tree_nodes["root"].node_desc = "Final entities"
                    how_report = tree_nodes["root"].render_tree(filter_str)
                else:
                    how_report = tree_nodes["root"].children[0].render_tree(filter_str)
            else:
                how_report = "There are no resolution steps to display!"

            if filter_str and filter_str not in how_report:
                input(f"\n{filter_str} was not found, press enter to continue")
                filter_str = None
            else:
                self.current_report = (
                    how_header
                    + ("\nFiltered for " + self.colorize(filter_str, "fg_white,bg_red") + "\n" if filter_str else "")
                    + "\n"
                    + how_report
                )

            self.show_report("auto", search=filter_str, from_how_or_why=True)

            reply = input(
                self.colorize_prompt(
                    "\nSelect (O)verview, (B)reif, (C)olumnar, (T)able, (V)erbose, (S)earch or (Q)uit ... "
                )
            )
            if reply:
                remove_from_history()
            else:
                continue

            if reply.upper() in ("Q", "QUIT"):
                break
            elif reply.upper() == ("O"):
                how_display_level = "overview"
                filter_str = None
            elif reply.upper() == ("C"):
                how_display_level = "columnar"
            elif reply.upper() == ("B"):
                how_display_level = "brief"
            elif reply.upper() == ("T"):
                how_display_level = "table"
            elif reply.upper() == ("V"):
                how_display_level = "verbose"
            elif reply.upper() == ("S"):
                if len(reply) > 1:
                    filter_str = reply[1:].strip()
                else:
                    filter_str = input(
                        "\nEnter a step number, a virtual entity ID, any other string or leave blank to clear filter ... "
                    )
                    remove_from_history()
            elif reply.isnumeric():
                filter_str = reply

            elif len(reply) > 1:
                filter_str = reply

            # check if they entered a valid step number
            if filter_str and filter_str.isnumeric():
                filter_str = f"Step {filter_str}"
                if filter_str not in tree_nodes:
                    input(f"\nStep {filter_str} not found, press enter to continue")
                    filter_str = None

            # check if they entered a node_id
            if filter_str and filter_str in tree_nodes:
                filter_str = f"~node~{filter_str}"

            if filter_str:
                how_display_level = "concise" if how_display_level == "overview" else how_display_level
        print()

        return

    # ---------------------------
    def get_virtual_entity_data(self, raw_virtual_entity_data, features_by_record):
        virtual_entity_data = {"id": raw_virtual_entity_data["VIRTUAL_ENTITY_ID"]}
        virtual_entity_data["record_count"] = 0
        virtual_entity_data["member_count"] = 0
        virtual_entity_data["records"] = {}
        virtual_entity_data["features"] = {}
        best_name_candidates = {"PRIMARY": "", "OTHER": ""}
        for member_data in raw_virtual_entity_data["MEMBER_RECORDS"]:
            virtual_entity_data["member_count"] += 1
            for record in sorted(member_data["RECORDS"], key=lambda k: k["DATA_SOURCE"] + k["RECORD_ID"]):
                virtual_entity_data["record_count"] += 1
                if record["DATA_SOURCE"] not in virtual_entity_data["records"]:
                    virtual_entity_data["records"][record["DATA_SOURCE"]] = []
                virtual_entity_data["records"][record["DATA_SOURCE"]].append(record["RECORD_ID"])

                # creates the master feature list for the virtual entity (accumulating which records have which features)
                record_key = record["DATA_SOURCE"] + self.dsrc_record_sep + record["RECORD_ID"]
                for lib_feat_id in features_by_record.get(record["DATA_SOURCE"], {}).get(record["RECORD_ID"], []):
                    if lib_feat_id not in virtual_entity_data["features"]:
                        virtual_entity_data["features"][lib_feat_id] = dict(
                            features_by_record[record["DATA_SOURCE"]][record["RECORD_ID"]][lib_feat_id]
                        )
                        virtual_entity_data["features"][lib_feat_id]["record_list"] = [record_key]
                    elif record_key not in virtual_entity_data["features"][lib_feat_id]["record_list"]:
                        virtual_entity_data["features"][lib_feat_id]["record_list"].append(record_key)

                    if virtual_entity_data["features"][lib_feat_id]["ftypeCode"] == "NAME":
                        this_name = virtual_entity_data["features"][lib_feat_id]["featDesc"]
                        this_usage_type = (
                            "PRIMARY"
                            if virtual_entity_data["features"][lib_feat_id]["usageType"] == "PRIMARY"
                            else "OTHER"
                        )
                        if len(this_name) > len(best_name_candidates[this_usage_type]):
                            best_name_candidates[this_usage_type] = this_name
        virtual_entity_data["entity_name"] = (
            best_name_candidates["PRIMARY"] if best_name_candidates["PRIMARY"] else best_name_candidates["OTHER"]
        )

        # a member is an obs_ent, despite how many records it has
        if len(raw_virtual_entity_data["MEMBER_RECORDS"]) == 1:
            additional_note = ""
            if virtual_entity_data["record_count"] > 1:  # its got additional pure dupes
                additional_note = self.colorize(
                    " +" + str(virtual_entity_data["record_count"] - 1) + " pure dupes",
                    "dim",
                )

            virtual_entity_data["node_type"] = "singleton"
            record = raw_virtual_entity_data["MEMBER_RECORDS"][0]["RECORDS"][0]
            virtual_entity_data["node_desc"] = record["DATA_SOURCE"] + ": " + record["RECORD_ID"] + additional_note
            virtual_entity_data["colored_desc"] = self.colorize_dsrc1(
                record["DATA_SOURCE"] + ": " + record["RECORD_ID"] + additional_note
            )

        else:
            virtual_entity_data["node_type"] = "aggregate"
            virtual_entity_data["node_desc"] = " | ".join(
                self.colorize_dsrc1(ds + " (" + str(len(virtual_entity_data["records"][ds])) + ")")
                for ds in sorted(virtual_entity_data["records"].keys())
            )
            virtual_entity_data["colored_desc"] = virtual_entity_data["node_desc"]

        return virtual_entity_data

    # ---------------------------
    def how_format_statistic_header(self, header):
        return self.colorize(header, "highlight2")

    # ---------------------------
    def how_format_statistic(self, stat, cnt):
        return stat + " " + self.colorize("(" + str(cnt) + ")", "highlight2")

    # ---------------------------
    def help_score(self):
        print(
            textwrap.dedent(
                f"""\

        Compares any two features and shows the scores returned.

        {self.colorize('Syntax:', 'highlight2')}
            score [{'{'}"name_last": "Smith", "name_first": "Joseph"{'}'}, {'{'}"name_last": "Smith", "name_first": "Joe"{'}'}]
            score [{'{'}"addr_full": "111 First St, Anytown, USA"{'}'}, {'{'}"addr_full": "111 First Street, Anytown"{'}'}]
            score [{'{'}"passport_number": "1231234", "passport_country": "US"{'}'}, {'{'}"passport_number": "1231234", "passport_country": "USA"{'}'}]

        {self.colorize('Notes:', 'highlight2')}
            Use the keyword "force" to force the two records to find each other by adding a trusted_id.
        """
            )
        )

    # ---------------------------
    def do_score(self, arg):
        if not arg:
            self.help_score()
            return

        force_trusted_id = "FORCE" in [x.upper() for x in arg.split()]
        if force_trusted_id:
            arg = " ".join([x for x in arg.split() if x.upper() != "FORCE"])

        try:
            json_data = json.loads(arg)
        except (ValueError, KeyError) as err:
            print_message(f"Invalid json parameter: {err}", "error")
            return

        # TODO - Ant -
        # if type(json_data) != list or len(json_data) != 2:
        if not isinstance(json_data, list) or len(json_data) != 2:
            print_message("json parameter must be a list of two features to compare", "error")
            return

        record1json = dict_keys_upper(json_data[0])
        record2json = dict_keys_upper(json_data[1])

        # use the test data source and entity type
        record1json["RECORD_TYPE"] = "SCORE_TEST"
        record2json["RECORD_TYPE"] = "SCORE_TEST"

        if force_trusted_id:
            record1json["TRUSTED_ID_TYPE"] = "SCORE"
            record1json["TRUSTED_ID_NUMBER"] = "TEST"
            record2json["TRUSTED_ID_TYPE"] = "SCORE"
            record2json["TRUSTED_ID_NUMBER"] = "TEST"

        # add the records
        try:
            sz_engine.add_record("TEST", "SCORE_RECORD_1", json.dumps(record1json))
            sz_engine.add_record("TEST", "SCORE_RECORD_2", json.dumps(record2json))
        except SzError as err:
            # TODO - Ant - str() ?
            print_message(err, "error")
            return

        self.do_why("TEST SCORE_RECORD_1 TEST SCORE_RECORD_2")

        # delete the two temporary records
        try:
            sz_engine.delete_record("TEST", "SCORE_RECORD_1")
            sz_engine.delete_record("TEST", "SCORE_RECORD_2")
        except SzError as err:
            print_message(err, "error")
            return

        return

    # ---------------------------
    def help_assign(self):
        print(
            textwrap.dedent(
                f"""\

        Assigns records from a particular entity to a trusted_id in order to move them to another entity

        {self.colorize('Syntax:', 'highlight2')}
            assign <trusted_id_attribute> <trusted_id_value> to <entity_id> <name_spec>

        {self.colorize('Example:', 'highlight2')}
            assign trusted_id_number 1001 to 7 "ABC Company"
        """
            )
        )

    # ---------------------------
    def xx_assign(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_merge()
            return -1 if caller else 0

        if "," in arg:
            arg_list = next(csv.reader([arg], delimiter=",", quotechar='"', skipinitialspace=True))
        else:
            arg_list = next(csv.reader([arg], delimiter=" ", quotechar='"', skipinitialspace=True))

        if len(arg_list) != 5:
            print_message("Incorrect syntax (be sure to quote parameters with spaces)", "error")
            self.help_merge()
            return -1 if caller else 0

        trusted_id_type = arg_list[0]
        trusted_id_number = arg_list[1]
        from_entity_id = int(arg_list[3])
        name_spec = arg_list[4]

        get_entity_flags = [
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]

        try:
            entity_data = self.call_sdk("get_entity_by_entity_id", get_entity_flags, from_entity_id)
        except Exception as err:
            print_message(err, "error")
            return -1 if caller else 0

        qualifying_names = []
        qualifying_feature_ids = []
        for feature_data in entity_data["RESOLVED_ENTITY"]["FEATURES"].get("NAME", []):
            for values_data in feature_data["FEAT_DESC_VALUES"]:
                if name_spec.upper() in values_data["FEAT_DESC"].upper() or name_spec == "*":
                    qualifying_names.append(values_data["FEAT_DESC"])
                    qualifying_feature_ids.append(values_data["LIB_FEAT_ID"])

        if len(qualifying_names) == 0:
            print_message("No features with that name match this entity", "error")
            return -1 if caller else 0

        qualifying_records = []
        for record_data in entity_data["RESOLVED_ENTITY"]["RECORDS"]:
            if name_spec == "*":
                qualifying_records.append(record_data)
            else:
                for feature_data in record_data["FEATURES"]:
                    if feature_data["LIB_FEAT_ID"] in qualifying_feature_ids:
                        qualifying_records.append(record_data)
                        break

        if len(qualifying_records) == 0:
            print_message("No records with that name match this entity", "error")
            return -1 if caller else 0

        question = (
            f"\n{len(qualifying_feature_ids)} names affecting {len(qualifying_records)} records will be assigned, "
            "OK"
            " to proceed ..."
        )
        reply = input(question)
        if reply.upper() != "OK":
            print_message("Assign aborted", "warning")
            return -1 if caller else 0
        else:
            remove_from_history()

        print()
        for record_data in qualifying_records:
            data_source = record_data["DATA_SOURCE"]
            record_id = record_data["RECORD_ID"]
            json_data = dict(record_data["JSON_DATA"])
            json_data[trusted_id_type] = trusted_id_number
            print(f"updating {data_source}: {record_id} ...")
            try:
                sz_engine.add_record(data_source, record_id, json.dumps(json_data))
            except SzError as err:
                print_message(err, "error")
                break

        print("\nResulting entity ... \n")
        get_record_data = qualifying_records[0]["DATA_SOURCE"] + " " + qualifying_records[0]["RECORD_ID"]
        # TODO - Ant - What is this doing?
        try:
            resolved_json = self.call_sdk("get_entity_by_record_id", [], get_record_data.split())
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0
        self.do_get(get_record_data)

    # ---------------------------
    def help_merge(self):
        print(
            textwrap.dedent(
                f"""\

        Merges any two entities or records.

        {self.colorize('Syntax:', 'highlight2')}
            merge 1, 2, "reason for merge"
            merge data_source1, record_id1, data_source2, record_id2, "reason for merge"
        """
            )
        )

    # ---------------------------
    def xx_merge(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_merge()
            return -1 if caller else 0

        feedback_data = {"type": "merge"}
        if "," in arg:
            arg_list = next(csv.reader([arg], delimiter=",", quotechar='"', skipinitialspace=True))
        else:
            arg_list = next(csv.reader([arg], delimiter=" ", quotechar='"', skipinitialspace=True))
        if len(arg_list) in (2, 4):
            reason = input("\nPlease provide a reason for the merge ... ")
            if reason:
                arg_list.append(f'"{reason}"')
                remove_from_history()
            else:
                print_message("Merge aborted, a reason is required", "warning")
                return -1 if caller else 0

        if len(arg_list) == 3:
            feedback_data["level"] = "entity"
            feedback_data["entity_id1"] = int(arg_list[0])
            feedback_data["entity_id2"] = int(arg_list[1])
            feedback_data["reason"] = arg_list[2]
        elif len(arg_list) == 5:
            feedback_data["level"] = "record"
            feedback_data["data_source1"] = arg_list[0]
            feedback_data["record_id1"] = arg_list[1]
            feedback_data["data_source2"] = arg_list[2]
            feedback_data["record_id2"] = arg_list[3]
            feedback_data["reason"] = arg_list[4]
        else:
            print_message("Invalid number of parameters", "error")
            self.help_merge()
            return -1 if caller else 0

        record_list = []
        get_record_flags = [
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FORMATTED_DATA",
        ]
        if feedback_data["level"] == "entity":
            get_entity_flags = [
                "SZ_ENTITY_INCLUDE_ENTITY_NAME",
                "SZ_ENTITY_INCLUDE_RECORD_DATA",
            ]

            try:
                resolved_json_1 = self.call_sdk(
                    "get_entity_by_entity_id",
                    get_entity_flags,
                    feedback_data["entity_id1"],
                )
                resolved_json_2 = self.call_sdk(
                    "get_entity_by_entity_id",
                    get_entity_flags,
                    feedback_data["entity_id2"],
                )
            except SzError as err:
                print_message(err, "error")
                return -1 if caller else 0

            entity_id1 = feedback_data["entity_id1"]
            entity_id2 = feedback_data["entity_id2"]
            entity_name1 = resolved_json_1["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_name2 = resolved_json_2["RESOLVED_ENTITY"]["ENTITY_NAME"]
            record_count1 = len(resolved_json_1["RESOLVED_ENTITY"]["RECORDS"])
            record_count2 = len(resolved_json_2["RESOLVED_ENTITY"]["RECORDS"])
            record_list += resolved_json_1["RESOLVED_ENTITY"]["RECORDS"]
            record_list += resolved_json_2["RESOLVED_ENTITY"]["RECORDS"]
            print(
                textwrap.dedent(
                    f"""\

            Merge:
                Entity {self.colorize_entity(entity_id1)}: {entity_name1} ({self.colorize_dsrc(str(record_count1) + ' records')})
                Entity {self.colorize_entity(entity_id2)}: {entity_name2} ({self.colorize_dsrc(str(record_count2) + ' records')})
                Reason: {feedback_data['reason']}
            """
                )
            )
            reply = input('Type "OK" to merge these entities ... ')
            if reply.upper() != "OK":
                print_message("Merge aborted", "warning")
                return -1 if caller else 0
            else:
                remove_from_history()

        else:
            record_list.append(
                {
                    "DATA_SOURCE": feedback_data["data_source1"],
                    "RECORD_ID": feedback_data["record_id1"],
                }
            )
            record_list.append(
                {
                    "DATA_SOURCE": feedback_data["data_source2"],
                    "RECORD_ID": feedback_data["record_id2"],
                }
            )

        # get merge log
        last_id = 0
        for record in self.feedback_log:
            last_id = record["id"] if record["id"] > last_id else last_id
        feedback_data["id"] = last_id + 1
        feedback_data["datetime"] = datetime.now().strftime("%m/%d/%Y %H:%M:%S")
        feedback_data["json_records"] = []
        feedback_data["record_list"] = []

        print("\nRecords:")
        for record_data in record_list:
            try:
                record_json = self.call_sdk(
                    "get_record",
                    get_record_flags,
                    [record_data["DATA_SOURCE"], record_data["RECORD_ID"]],
                )
            except SzError as err:
                print_message(err, "error")
                return -1 if caller else 0

            json_data = record_json["JSON_DATA"]
            # if 'DATA_SOURCE' not in json_data:
            #    json_data['DATA_SOURCE'] = record_data['DATA_SOURCE']
            # if 'RECORD_ID' not in json_data:
            #    json_data['RECORD_ID'] = record_data['RECORD_ID']
            feedback_data["json_records"].append(json_data)
            feedback_data["record_list"].append(
                {
                    "DATA_SOURCE": record_data["DATA_SOURCE"],
                    "RECORD_ID": record_data["RECORD_ID"],
                }
            )
            record_name = (
                record_json["NAME_DATA"][0] if len(record_json.get("NAME_DATA", [])) > 0 else "no name on record"
            )
            print(
                f"  {self.colorize_dsrc(record_json['DATA_SOURCE'] + ': ' + record_json['RECORD_ID'])} {self.colorize_attr(record_name)}"
            )
        if feedback_data["level"] != "entity":
            reply = input('\nType "OK" to merge these records ... ')
            if reply.upper() != "OK":
                print_message("Merge aborted", "warning")
                return -1 if caller else 0
            else:
                remove_from_history()

        print("\nMerging records ...")
        for json_data in feedback_data["json_records"]:
            new_json = dict(json_data)
            if "feedback" not in new_json:
                new_json["feedback"] = []
            new_json["feedback"].append(
                {
                    "TRUSTED_ID_TYPE": feedback_data["type"],
                    "TRUSTED_ID_NUMBER": feedback_data["id"],
                }
            )
            try:
                sz_engine.add_record(new_json["DATA_SOURCE"], new_json["RECORD_ID"], json.dumps(new_json))
            except SzError as err:
                print(str(err))
                break
                # --TODO: undo what was done

        print("\nResulting entity ... \n")
        get_record_data = (
            feedback_data["record_list"][0]["DATA_SOURCE"] + " " + feedback_data["record_list"][0]["RECORD_ID"]
        )
        try:
            resolved_json = self.call_sdk("get_entity_by_record_id", [], get_record_data.split())
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0

        feedback_data["resulting_entity_id"] = resolved_json["RESOLVED_ENTITY"]["ENTITY_ID"]

        self.feedback_log.append(feedback_data)
        self.feedback_updated = True

        self.do_get(get_record_data)

    # ---------------------------
    def render_table(self, tbl_title, tbl_columns, tbl_rows, **kwargs):

        # display flags (start/append/done) allow for multiple tables to be displayed together and scrolled as one
        # such as an entity and its relationships

        # possible kwargs
        display_flag = kwargs.get("displayFlag")
        title_color = kwargs.get("titleColor", "table_title")
        title_justify = kwargs.get("titleJustify", "l")
        header_color = kwargs.get("headerColor", "column_header")
        combine_headers = kwargs.get("combineHeaders", False)

        # setup the table
        table_object = PrettyTable()
        # tableObject.title = tbl_title
        table_object.hrules = PRETTY_TABLE_ALL
        if True:  # PRETTYTABLE_STYLE_AVAILABLE:
            table_object.set_style(SINGLE_BORDER)
        else:
            table_object.horizontal_char = "\u2500"
            table_object.vertical_char = "\u2502"
            table_object.junction_char = "\u253C"

        field_name_list = []
        column_header_list = []
        for column_data in tbl_columns:
            field_name_list.append(column_data["name"])
            column_header_list.append(
                "\n".join(self.colorize(str(x), "column_header") for x in str(column_data["name"]).split("\n"))
            )
        table_object.field_names = field_name_list

        table_object.header = False  # make first row header to allow for stacked column header names
        table_object.add_row(column_header_list)

        total_row_cnt = 0
        for row in tbl_rows:
            total_row_cnt += 1
            row[0] = "\n".join([i for i in str(row[0]).split("\n")])
            table_object.add_row(row)

        # format with data in the table
        for column_data in tbl_columns:
            # tableObject.max_width[str(columnData['name'])] = columnData['width']
            table_object.align[column_data["name"]] = column_data["align"][0:1].lower()

        table_str = table_object.get_string()
        if combine_headers:
            table_str = self.combine_table_headers(table_str)

        # write to a file so can be viewed with less
        # also write to the lastTableData variable in case cannot write to file
        fmt_table_string = ""
        if tbl_title:
            fmt_table_string = self.colorize(tbl_title, title_color) + "\n"
        fmt_table_string += table_str + "\n"

        write_mode = "w"
        if display_flag in ("append", "end"):
            fmt_table_string = "\n" + fmt_table_string
            write_mode = "a"

        if write_mode == "w":
            self.current_report = fmt_table_string
        else:
            self.current_report = self.current_report + fmt_table_string

        # display if a single table or done accumulating tables to display
        if not display_flag or display_flag == "end":
            print("")
            self.show_report("auto")
            print("")
        return

    # ---------------------------
    def render_table2(self, tbl_title, tbl_columns, tbl_rows, **kwargs):

        title_color = kwargs.get("titleColor", "table_title")
        title_justify = kwargs.get("titleJustify", "l")
        header_color = kwargs.get("headerColor", "column_header")
        combine_headers = kwargs.get("combineHeaders", False)

        table_object = PrettyTable()
        table_object.hrules = PRETTY_TABLE_ALL
        # table_object.set_style(SINGLE_BORDER)
        table_object.horizontal_char = "\u2500"
        table_object.vertical_char = "\u2502"
        table_object.junction_char = "\u253C"

        field_name_list = []
        column_header_list = []
        for column_data in tbl_columns:
            field_name_list.append(column_data["name"])
            column_header_list.append(
                "\n".join(self.colorize(str(x), "column_header") for x in str(column_data["name"]).split("\n"))
            )
        table_object.field_names = field_name_list
        table_object.header = False
        table_object.add_row(column_header_list)

        total_row_cnt = 0
        for row in tbl_rows:
            total_row_cnt += 1
            row[0] = "\n".join([i for i in str(row[0]).split("\n")])
            table_object.add_row(row)

        for column_data in tbl_columns:
            table_object.align[column_data["name"]] = column_data["align"][0:1].lower()

        table_str = table_object.get_string()
        if combine_headers:
            table_str = self.combine_table_headers(table_str)
        if tbl_title:
            table_str = f"{self.colorize(tbl_title, title_color)}\n{table_str}"

        return table_str + "\n"

    # ---------------------------
    def combine_table_headers(self, report_str):
        report = report_str.split("\n")
        col_sep = report[1][0]
        old_header1 = report[1].replace(Colors.COLUMN_HEADER, "").replace(Colors.RESET, "")
        self.colorize_characters_width = len(self.colorize("", "column_header"))
        headers1 = old_header1.split(col_sep)
        prior_header_len = 0
        new_header1 = col_sep
        new_header1_colored = col_sep
        for i in range(len(headers1)):
            if i > 0 and i < len(headers1) - 1:
                if (
                    i == len(headers1) - 2
                    or headers1[i].strip() != headers1[i - 1].strip()
                    or len(headers1[i - 1].strip()) == 0
                ):
                    if i == len(headers1) - 2:
                        prior_header_len += len(headers1[i]) + 1
                    if prior_header_len > 0:
                        new_header1 += f"{headers1[i-1]:^{prior_header_len-1}}{col_sep}"
                        new_header1_colored += f"{self.colorize(headers1[i-1], 'column_header'):^{prior_header_len-1+self.colorize_characters_width}}{col_sep}"
                        prior_header_len = 0
                prior_header_len += len(headers1[i]) + 1

        new_header0 = report[0]
        for i in range(len(old_header1)):
            if old_header1[i] == col_sep and new_header1[i] != col_sep:
                new_header0 = new_header0[0:i] + new_header0[i - 1] + new_header0[i + 1 :]

        new_report = [new_header0, new_header1_colored]
        new_report.extend(report[2:])

        return "\n".join(new_report)

    # ---------------------------
    # TODO - Ant - Fix search compare not auto scrolling
    # TODO search {"EMAIL_ADDRESS": "Kusha123@hmail.com"}
    # TODO compare search
    def show_report(self, arg=None, **kwargs):
        if not self.current_report:
            return

        print()
        if self.current_review_list:
            self.current_report = self.colorize(self.current_review_list, "bold") + "\n\n" + self.current_report

        from_how_or_why = kwargs.get("from_how_or_why")
        if self.current_settings["auto_scroll"] == "off" and not from_how_or_why:
            screen_width = os.get_terminal_size()[0] - 1
            for line in self.current_report.split("\n"):
                if len(re.sub(r"\\x1b\[\d*;\d*;\d*m", "", line)) < screen_width:
                    print(f" {line}")
                else:
                    nline = ""
                    nline_len = 1
                    formatting = False
                    for char in line:
                        nline += char
                        if char == "\033":
                            formatting = True
                        elif formatting and char == "m":
                            formatting = False
                        elif not formatting:
                            nline_len += 1
                        if nline_len >= screen_width:
                            break
                    print(f" {nline}{Colors.RESET}")
            return

        # note: the F allows less to auto quit if output fits on screen
        #  if they purposely went into scroll mode, we should not auto-quit!
        if arg == "auto":
            less_options = "-FMXSR"
        else:
            less_options = "-MXSR"

        # --start with a search
        search = kwargs.get("search")
        if search:
            less_options + " /" + search

        # try pipe to less on small enough files (pipe buffer usually 1mb and fills up on large entity displays)
        less = subprocess.Popen(["less", less_options], stdin=subprocess.PIPE)
        with suppress(Exception):
            less.stdin.write(self.current_report.encode())
            less.stdin.close()
            less.wait()
        print()

    def show_report2(self, report, **kwargs):
        no_scroll = kwargs.get("no_scroll")
        print()
        self.current_report = report
        if kwargs.get("no_scroll"):
            screen_width = os.get_terminal_size()[0] - 1
            for line in report.split("\n"):
                if len(re.sub(r"\\x1b\[\d*;\d*;\d*m", "", line)) < screen_width:
                    print(f" {line}")
                else:
                    nline = ""
                    nline_len = 1
                    formatting = False
                    for char in line:
                        nline += char
                        if char == "\033":
                            formatting = True
                        elif formatting and char == "m":
                            formatting = False
                        elif not formatting:
                            nline_len += 1
                        if nline_len >= screen_width:
                            break
                    print(f" {nline}{Colors.RESET}")
            return

        # if arg == "auto":
        less_options = "-FMXSR"
        # else:
        #    less_options = "-MXSR"

        # --start with a search
        search = kwargs.get("search")
        if search:
            less_options + " /" + search

        # try pipe to less on small enough files (pipe buffer usually 1mb and fills up on large entity displays)
        less = subprocess.Popen(["less", less_options], stdin=subprocess.PIPE)
        with suppress(Exception):
            less.stdin.write(report.encode())
            less.stdin.close()
            less.wait()
        print()

    # -----------------------------
    def do_scroll(self, arg):
        print()
        if not self.current_report:
            return
        # TODO - Ant - Not used?
        if arg == "auto":
            lessOptions = "FMXSR"
        else:
            lessOptions = "MXSR"

        # try pipe to less on small enough files (pipe buffer usually 1mb and fills up on large entity displays)
        less = subprocess.Popen(["less", "-FMXSR"], stdin=subprocess.PIPE)
        try:
            less.stdin.write(self.current_report.encode())
        except IOError:
            pass
        less.stdin.close()
        less.wait()
        print()

    # ---------------------------
    def help_export(self):
        print(
            textwrap.dedent(
                f"""\

        Exports the json records that make up the selected entities for debugging, reloading, etc.

        {self.colorize('Syntax:', 'highlight2')}
            export <entity_id>, <entity_id> degree <n> to <fileName> additive
            export search to <fileName>
            export search <search index> to <fileName>\n
        """
            )
        )

    # ---------------------------
    def do_export(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_export()
            return -1 if caller else 0

        entity_list = []
        file_name = None
        max_degree = 0
        additive = False

        arg = arg.replace(",", " ")
        arglist = arg.split()
        i = 0
        while i < len(arglist):
            this_token = arglist[i].upper()
            next_token = arglist[i + 1] if i + 1 < len(arglist) else ""
            if this_token == "TO":
                if next_token:
                    file_name = next_token
                    i += 1

            elif this_token == "SEARCH":
                if next_token.isdigit():
                    if int(next_token) > len(self.last_search_result):
                        print_message("Invalid search index", "error")
                        return -1 if caller else 0
                    else:
                        # TODO - Ant - What is lastToken? Errors if entering: export search 2
                        entity_list.append(self.last_search_result[int(lastToken) - 1])
                        i += 1
                else:
                    entity_list = self.last_search_result
            elif this_token == "DEGREE":
                if next_token.isdigit():
                    max_degree = int(next_token)
                    i += 1
            elif this_token.upper().startswith("ADD"):
                additive = True

            elif this_token.isdigit():
                entity_list.append(int(this_token))
            else:
                print_message(f"unknown command token: {this_token}", "warning")
            i += 1

        if not entity_list:
            print_message("No entities found", "warning")
            return

        if not file_name:
            if len(entity_list) == 1:
                file_name = str(entity_list[0]) + ".json"
            else:
                file_name = "records.json"
        try:
            f = open(file_name, "a" if additive else "w", encoding="utf-8")
        except IOError as err:
            print_message(err, "error")
            return

        get_flag_list = [
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
        ]
        if max_degree > 0:
            get_flag_list.append("SZ_ENTITY_INCLUDE_ALL_RELATIONS")

        exported_entity_list = []
        record_count = 0
        current_degree = 0
        current_entity_list = entity_list
        while current_degree <= max_degree:
            next_entity_list = []
            for entity_id in current_entity_list:
                exported_entity_list.append(entity_id)

                try:
                    json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
                except SzError as err:
                    print_message(err, "error")
                    return

                for record_data in json_data["RESOLVED_ENTITY"]["RECORDS"]:
                    f.write(json.dumps(record_data["JSON_DATA"]) + "\n")
                    record_count += 1

                if "RELATED_ENTITIES" in json_data:
                    for related_data in json_data["RELATED_ENTITIES"]:
                        if (
                            related_data["ENTITY_ID"] not in exported_entity_list
                            and related_data["ENTITY_ID"] not in next_entity_list
                        ):
                            next_entity_list.append(related_data["ENTITY_ID"])

            current_degree += 1
            if next_entity_list:
                current_entity_list = next_entity_list
            else:
                break

        # TODO - Ant - Move to finally in try above
        f.close

        print_message(f"{record_count} records written to {file_name}", "success")

    # ---------------------------
    def getRule_desc(self, errule_code):
        return (
            "Principle " + str(self.errule_code_lookup[errule_code]["ERRULE_ID"]) + ": " + errule_code
            if errule_code in self.errule_code_lookup
            else ""
        )

    # ---------------------------
    def get_config_data(self, table, field=None, value=None):

        record_list = []
        for i in range(len(self.cfg_data["G2_CONFIG"][table])):
            if field and value:
                if self.cfg_data["G2_CONFIG"][table][i][field] == value:
                    record_list.append(self.cfg_data["G2_CONFIG"][table][i])
            else:
                # TODO - Ant - Config change to SZ_CONFIG in V4?
                record_list.append(self.cfg_data["G2_CONFIG"][table][i])
        return record_list

    # ---------------------------
    def get_attribute_json(self, attribute_record):

        if "ADVANCED" not in attribute_record:
            attribute_record["ADVANCED"] = 0
        if "INTERNAL" not in attribute_record:
            attribute_record["INTERNAL"] = 0

        json_string = "{"
        json_string += '"id": "%s"' % attribute_record["ATTR_ID"]
        json_string += ', "attribute": "%s"' % attribute_record["ATTR_CODE"]
        json_string += ', "class": "%s"' % attribute_record["ATTR_CLASS"]
        json_string += ', "feature": "%s"' % attribute_record["FTYPE_CODE"]
        json_string += ', "element": "%s"' % attribute_record["FELEM_CODE"]
        json_string += ', "required": "%s"' % attribute_record["FELEM_REQ"].title()
        json_string += ', "default": "%s"' % attribute_record["DEFAULT_VALUE"]
        json_string += ', "advanced": "%s"' % ("Yes" if attribute_record["ADVANCED"] == 1 else "No")
        json_string += ', "internal": "%s"' % ("Yes" if attribute_record["INTERNAL"] == 1 else "No")
        json_string += "}"

        return json_string

    # ---------------------------
    def is_internal_attribute(self, attrStr):
        if ":" in attrStr:
            attrStr = attrStr.split(":")[0]
        attr_records = self.get_config_data("CFG_ATTR", "ATTR_CODE", attrStr.upper())
        if attr_records and attr_records[0]["INTERNAL"].upper().startswith("Y"):
            return True
        return False


# --------------------------------------
def print_message(msg_text, msg_type_or_color=""):
    if msg_type_or_color.upper() == "ERROR":
        msg_color = "FG_RED"
    elif msg_type_or_color.upper() == "WARNING":
        msg_color = "FG_YELLOW"
    elif msg_type_or_color.upper() == "INFO":
        msg_color = "FG_CYAN"
    elif msg_type_or_color.upper() == "SUCCESS":
        msg_color = "FG_GREEN"
    else:
        msg_color = msg_type_or_color
    print(f"\n{Colors.apply(msg_text, msg_color)}\n")


# --------------------------------------
def show_debug(call: str, output: str = "") -> None:
    """# TODO"""
    if args.debug_output.upper() in ("S", "SCR", "SCREEN") and output:
        print(f"- {call} -\n")
        print(f"{output}\n")
        return

    try:
        with open(args.debug_output, "a", encoding="utf-8") as f:
            f.write(f"- {call} -\n")
            f.write(f"{output}\n\n")
    except IOError as err:
        # TODO - Ant - Color
        print(f"cannot write to {args.debug_output}: {err}")


# --------------------------------------
def fmt_statistic(amt):
    amt = int(amt)
    if amt > 1000000:
        return "{:,.2f}m".format(round(amt / 1000000, 2))

    return "{:,}".format(amt)


# --------------------------------------
def dict_keys_upper(dict):
    return {k.upper(): v for k, v in dict.items()}


# --------------------------------------
def remove_from_history(idx=0):
    if readline:
        if not idx:
            idx = readline.get_current_history_length() - 1
        readline.remove_history_item(idx)


# --------------------------------------
def _append_slash_if_dir(p):
    if p and os.path.isdir(p) and p[-1] != os.sep:
        return p + os.sep
    else:
        return p


def debug_print(_value, _desc="some variable"):
    print("-" * 20)
    print(_desc)
    if type(_value) in (list, dict):
        print(json.dumps(_value, indent=4))
    else:
        print(_value)
    input("press any key ...")


# --------------------------------------
if __name__ == "__main__":
    appPath = os.path.dirname(os.path.abspath(sys.argv[0]))

    # capture the command line arguments
    argParser = argparse.ArgumentParser()
    argParser.add_argument(
        "-c",
        "--config_file_name",
        help="Path and name of optional G2Module.ini file to use.",
    )
    argParser.add_argument(
        "-s",
        "--snapshot_json_file",
        help="the name of a json statistics file computed by G2Snapshot.py",
    )
    argParser.add_argument(
        "-a",
        "--audit_json_file",
        help="the name of a json statistics file computed by G2Audit.py",
    )
    argParser.add_argument(
        "-w",
        "--webapp_url",
        help="the url to the senzing webapp if available",
    )
    argParser.add_argument(
        "-D",
        "--debug_output",
        help="print raw api json to screen or <filename.txt>",
    )
    argParser.add_argument(
        "-H",
        "--hist_disable",
        action="store_true",
        default=False,
        help="disable history file usage",
    )
    argParser.add_argument(
        "-t",
        "--debug_trace",
        action="store_true",
        default=False,
        help="output debug trace information",
    )
    args = argParser.parse_args()

    if args.snapshot_json_file and not os.path.exists(args.snapshot_json_file):
        print_message("Snapshot json file not found", "error")
        sys.exit(1)

    if args.audit_json_file and not os.path.exists(args.audit_json_file):
        print_message("Audit json file not found", "error")
        sys.exit(1)

    splash = Colors.apply("\n  ____|  __ \\     \\    \n", "DIM")
    splash += Colors.apply("  __|    |   |   _ \\   ", "DIM") + "Senzing G2\n"
    splash += Colors.apply("  |      |   |  ___ \\  ", "DIM") + "Exploratory Data Analysis\n"
    splash += Colors.apply(" _____| ____/ _/    _\\ \n", "DIM")
    print(splash)

    try:
        sz_pretty = sz_pretty_sdk(args.config_file_name, args.debug_trace, args.debug_output)
    except Exception as err:
        # except SzError as err:
        print_message(err, "error")
        sys.exit(1)

    try:
        from sz_database import SzDatabase

        sz_dbo = SzDatabase(json.loads(sz_api_config)["SQL"]["CONNECTION"])
    except Exception as err:
        sz_dbo = None

    G2CmdShell(args, sz_pretty, sz_dbo).cmdloop()

    sys.exit()
