#! /usr/bin/env python3

import argparse
import atexit
import cmd
import csv
import glob
import inspect
import json
import os
import re
import readline
import subprocess
import sys
import textwrap
import traceback
from contextlib import suppress
from typing import Any, Dict, List, Union

from _tool_helpers import Colors, get_engine_config
from senzing import SzAbstractFactory, SzEngineFlags, SzError

PRETTYTABLE_STYLE_AVAILABLE = False
try:
    from prettytable import ALL as PRETTY_TABLE_ALL
    from prettytable import PrettyTable

    # Supports both ptable and prettytable builds of prettytable (only prettytable has these styles)
    with suppress(ImportError):
        from prettytable import SINGLE_BORDER

        PRETTYTABLE_STYLE_AVAILABLE = True

except ImportError:
    print("\nPlease install the Python prettytable module (e.g. pip install prettytable)")
    sys.exit(1)

DATABASE_ACCESS = False
with suppress(ImportError):
    from _sz_database import SzDatabase

    DATABASE_ACCESS = True


def parse_cli_args() -> argparse.Namespace:
    """# TODO"""

    arg_parser = argparse.ArgumentParser(
        allow_abbrev=False,
        description="Utility to explore Senzing outcomes",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    arg_parser.add_argument(
        "-c",
        "--config_file_name",
        dest="ini_file_name",
        default=None,
        help="Path and name of optional G2Module.ini file to use.",
    )
    arg_parser.add_argument(
        "-s",
        "--snapshot_json_file",
        dest="snapshot_file_name",
        default=None,
        help="the name of a json statistics file computed by G2Snapshot.py",
    )
    arg_parser.add_argument(
        "-a",
        "--audit_json_file",
        dest="audit_file_name",
        default=None,
        help="the name of a json statistics file computed by G2Audit.py",
    )
    arg_parser.add_argument(
        "-w",
        "--webapp_url",
        dest="webapp_url",
        default=None,
        help="the url to the senzing webapp if available",
    )
    arg_parser.add_argument(
        "-D",
        "--debug_output",
        dest="debug_output",
        default=None,
        help="print raw api json to screen or <filename.txt>",
    )
    arg_parser.add_argument(
        "-H",
        "--histDisable",
        dest="histDisable",
        action="store_true",
        default=False,
        help="disable history file usage",
    )
    arg_parser.add_argument(
        "-t",
        "--debugTrace",
        dest="debugTrace",
        action="store_true",
        default=False,
        help="output debug trace information",
    )

    return arg_parser.parse_args()


# def execute_sz_api(
#     api_name: str,
#     flags: List[str],
#     parms: Union[List[Union[str, int]], int, str],
# ) -> Dict[str, Any]:
#     """# TODO"""
#     parms = parms if isinstance(parms, list) else [parms]
#     caller = inspect.stack()[1].function

#     try:
#         flags_int = SzEngineFlags.combine_flags(flags)
#         parms.append(flags_int)
#     except SzError as err:
#         raise SzError(f"{caller}: {api_name} - {err}") from None

#     # api_called = f"{api_name}({', '.join(str(x) for x in parm_list)})"

#     try:
#         api_call = getattr(sz_engine, api_name)
#         response = api_call(*parms)
#         response_data: Dict[str, Any] = json.loads(response)
#     except AttributeError:
#         raise SzError(
#             f"{caller}: {api_name} not available in {api_version['BUILD_VERSION']}"
#         ) from None
#     except SzError as err:
#         raise SzError(f"{caller}: {api_name} - {err}") from None

#     if debugOutput:
#         n_t = "\n\t"
#         show_debug(
#             caller,
#             f"{api_name}\n\t{n_t.join(flags)}\n{json.dumps(response_data, indent=4)}",
#         )

#     return response_data


def colorize(in_string, color_list="None"):
    return Colors.apply(in_string, color_list)


# ----------------------------
def colorize_prompt(prompt_str, auto_scroll="off"):
    # this is effectively off until the auto scroll parameter gets passed
    #  otherwise colorized tags causes word wrapping
    # example prompt: (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (Q)uit
    if auto_scroll == "on":
        for str1 in "PNGDHWEQCFSO":
            prompt_str = prompt_str.replace(f"({str1})", f"({Colors.apply(str1, 'bold')})")
    return prompt_str


# ---------------------------
def colorize_attr(attr_str, attr_color="attr_color"):
    if ":" in attr_str:
        attr_name = attr_str[0 : attr_str.find(":") + 1]
        attr_value = attr_str[attr_str.find(":") + 1 :].strip()
        return colorize(attr_name, attr_color) + " " + attr_value
    return colorize(attr_str, attr_color)


# ---------------------------
def colorize_dsrc(dsrc_str):
    if ":" in dsrc_str:
        return colorize_attr(dsrc_str, "dsrc_color")
    return colorize(dsrc_str, "dsrc_color")


# ---------------------------
def colorize_dsrc1(dsrc_str):
    return colorize(dsrc_str, "dsrc_color")


# ---------------------------
def colorize_entity(entity_str, added_color=None):
    entity_color = "entity_color" + ("," + added_color if added_color else "")
    if ":" in str(entity_str):
        return colorize_attr(entity_str, entity_color)
    return colorize(entity_str, entity_color)


# ---------------------------
def colorize_match_data(matchDict):
    if not matchDict["matchKey"]:
        if matchDict.get("anyCandidates", False):
            match_str = colorize("scored too low!", "bad")
        else:
            match_str = colorize("no matching keys", "bad")
    else:
        good_segments = []
        bad_segments = []
        prior_key = ""
        key_color = "fg_green"
        for key in re.split(r"(\+|\-)", matchDict["matchKey"]):
            if key in ("+", ""):
                prior_key = "+"
            elif key == "-":
                prior_key = "-"
            elif prior_key == "-":
                bad_segments.append(key)
            else:
                good_segments.append(key)
        if good_segments:
            match_str = colorize("+".join(good_segments), "good")
        else:
            match_str = ""
        if bad_segments:
            match_str += colorize("-" + "-".join(bad_segments), "bad")

        if matchDict.get("ruleCode"):
            match_str += f"\n {colorize(matchDict['ruleCode'], 'dim')}"
        # else:
        #    matchStr += f"\n {colorize('no principles satisfied!', 'bad')}"

    if "entityId" in matchDict and "entityName" in matchDict:
        match_str += f"\n to {colorize_entity(matchDict['entityId'])} {matchDict['entityName']}"
    elif "entityId" in matchDict:
        match_str += f" to {colorize_entity(matchDict['entityId'])}"

    return match_str


# --------------------------------------
def print_message(msg_text, msg_type_or_color=""):
    if msg_type_or_color.upper() == "ERROR":
        msg_color = "FG_RED"
    elif msg_type_or_color.upper() == "WARNING":
        msg_color = "FG_YELLOW"
    elif msg_type_or_color.upper() == "INFO":
        msg_color = "FG_CYAN"
    elif msg_type_or_color.upper() == "SUCCESS":
        msg_color = "FG_GREEN"
    else:
        msg_color = msg_type_or_color
    print(f"\n{Colors.apply(msg_text, msg_color)}\n")


# ==============================
class Node(object):

    def __init__(self, node_id):
        self.node_id = node_id
        self.node_desc = node_id
        self.node_text = None
        self.children = []
        self.parents = []

    def add_child(self, obj):
        self.children.append(obj)

    def add_parent(self, obj):
        self.parents.append(obj)

    def render_tree(self, filter_str=None):
        tree = ""
        tree += self.node_desc + "\n"
        if self.node_text:
            tree += self.node_text + "\n"
        parents = [{"node": self, "next_child": 0, "prior_nodes": [self]}]
        while parents:
            if parents[-1]["next_child"] == len(parents[-1]["node"].children):
                parents.pop()
                continue

            next_node = parents[-1]["node"].children[parents[-1]["next_child"]]
            parents[-1]["next_child"] += 1

            prefix = ""
            for i in range(len(parents)):
                if i < len(parents) - 1:  # prior level
                    prefix += "    " if parents[i]["next_child"] == len(parents[i]["node"].children) else "\u2502   "
                else:
                    prefix += (
                        "\u2514\u2500\u2500 "
                        if parents[i]["next_child"] == len(parents[i]["node"].children)
                        else "\u251c\u2500\u2500 "
                    )

            filter_str_in_desc = False
            node_desc = next_node.node_desc
            if node_desc and filter_str:
                if filter_str in node_desc:
                    node_desc = node_desc.replace(filter_str, colorize(filter_str, "bg_red, fg_white"))
                    filter_str_in_desc = True

            for line in node_desc.split("\n"):
                tree += prefix + line + "\n"
                if prefix[-4:] == "\u251c\u2500\u2500 ":
                    prefix = prefix[0:-4] + "\u2502   "
                elif prefix[-4:] == "\u2514\u2500\u2500 ":
                    prefix = prefix[0:-4] + "    "

            if next_node.node_text:
                node_text = next_node.node_text
                if filter_str:
                    if filter_str in node_text:
                        node_text = node_text.replace(filter_str, colorize(filter_str, "bg_red, fg_white"))
                    elif not filter_str_in_desc:
                        node_text = ""
                for line in node_text.split("\n"):
                    tree += prefix + line + "\n"

            if next_node not in parents[-1]["prior_nodes"] and next_node.children:
                # gather all prior level nodes so don't render twice
                prior_nodes = []
                for parent in parents:
                    prior_nodes += parent["node"].children

                parents.append({"node": next_node, "next_child": 0, "prior_nodes": prior_nodes})
        return tree


# ==============================


class SzCmdShell(cmd.Cmd):

    def __init__(self, cli_args, sz_abstract_factory: SzAbstractFactory, engine_settings):
        cmd.Cmd.__init__(self)
        readline.set_completer_delims(" ")

        # Acquire Senzing API engines
        self.engine_settings = engine_settings
        self.sz_factory = sz_abstract_factory

        try:
            self.sz_configmgr = self.sz_factory.create_sz_configmanager()
            self.sz_diagnostic = self.sz_factory.create_sz_diagnostic()
            self.sz_engine = self.sz_factory.create_sz_engine()
            self.sz_product = self.sz_factory.create_sz_product()
            default_config_id = self.sz_configmgr.get_default_config_id()
            default_config_doc = self.sz_configmgr.get_config(default_config_id)
            self.api_version = json.loads(self.sz_product.get_version())
            self.cfg_data = json.loads(default_config_doc)
        except SzError as err:
            print_message(err, "error")
            sys.exit(1)

        if DATABASE_ACCESS:
            try:
                connection_settings: str = json.loads(engine_settings)["SQL"]["CONNECTION"]
                self.sz_dbo = SzDatabase(connection_settings)
            except Exception as err:
                print_message(f"Database access is available but there was an error connecting: {err}", "error")
                print_message("The quickLook command will not be available", "error")

        self.intro = "\nType help or ? to list commands.\n"
        self.prompt = "(g2) "

        # store config dicts for fast lookup
        self.cli_args = cli_args
        self.debugOutput = cli_args.debug_output
        self.dsrc_lookup = {}
        self.engine_settings = engine_settings
        self.histDisable = cli_args.histDisable
        self.webapp_url = cli_args.webapp_url

        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_DSRC"]:
            self.dsrc_lookup[cfg_record["DSRC_ID"]] = cfg_record
        self.dsrc_code_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_DSRC"]:
            self.dsrc_code_lookup[cfg_record["DSRC_CODE"]] = cfg_record
        self.errule_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_ERRULE"]:
            self.errule_lookup[cfg_record["ERRULE_ID"]] = cfg_record
        self.errule_code_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_ERRULE"]:
            self.errule_code_lookup[cfg_record["ERRULE_CODE"]] = cfg_record
        self.ftype_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_FTYPE"]:
            self.ftype_lookup[cfg_record["FTYPE_ID"]] = cfg_record
        self.ftype_code_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_FTYPE"]:
            self.ftype_code_lookup[cfg_record["FTYPE_CODE"]] = cfg_record

        self.ftype_attr_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_ATTR"]:
            if cfg_record["FTYPE_CODE"] not in self.ftype_attr_lookup:
                self.ftype_attr_lookup[cfg_record["FTYPE_CODE"]] = {}
            self.ftype_attr_lookup[cfg_record["FTYPE_CODE"]][cfg_record["FELEM_CODE"]] = cfg_record

        # Build additional dictionary to easily reference ATTR_CLASS for FTYPE_CODE
        self.ftype_lookup_attr_class = {}
        for ftype_code, felem_codes_dicts in self.ftype_attr_lookup.items():
            # DATA_SOURCE, RECORD_ID and DSRC_ACTION are None
            if not ftype_code or not felem_codes_dicts:
                continue
            for first_felem in felem_codes_dicts:
                self.ftype_lookup_attr_class[ftype_code] = felem_codes_dicts[first_felem]["ATTR_CLASS"]
                # Only need first entry
                break

        self.cfunc_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_CFUNC"]:
            self.cfunc_lookup[cfg_record["CFUNC_ID"]] = cfg_record

        self.cfrtn_lookup = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_CFRTN"]:
            self.cfrtn_lookup[cfg_record["CFUNC_ID"]] = cfg_record

        self.scored_ftype_codes = {}
        for cfg_record in self.cfg_data["G2_CONFIG"]["CFG_CFCALL"]:
            cfg_record["FTYPE_CODE"] = self.ftype_lookup[cfg_record["FTYPE_ID"]]["FTYPE_CODE"]
            cfg_record["CFUNC_CODE"] = self.cfunc_lookup[cfg_record["CFUNC_ID"]]["CFUNC_CODE"]
            self.scored_ftype_codes[cfg_record["FTYPE_CODE"]] = cfg_record

        self.ambiguous_ftype_id = self.ftype_code_lookup["AMBIGUOUS_ENTITY"]["FTYPE_ID"]

        # set feature display sequence
        self.feature_sequence = {}
        self.feature_sequence[self.ambiguous_ftype_id] = 1  # ambiguous is first
        feature_sequence = 2
        # scored features second
        for cfg_record in sorted(self.cfg_data["G2_CONFIG"]["CFG_CFCALL"], key=lambda k: k["FTYPE_ID"]):
            if cfg_record["FTYPE_ID"] not in self.feature_sequence:
                self.feature_sequence[cfg_record["FTYPE_ID"]] = feature_sequence
                feature_sequence += 1
        # then the rest
        for cfg_record in sorted(self.cfg_data["G2_CONFIG"]["CFG_FTYPE"], key=lambda k: k["FTYPE_ID"]):
            if cfg_record["FTYPE_ID"] not in self.feature_sequence:
                self.feature_sequence[cfg_record["FTYPE_ID"]] = feature_sequence
                feature_sequence += 1

        # misc
        self.dsrc_record_sep = "~|~"
        self.__hidden_methods = "do_shell", "do_n", "do_p", "do_next", "do_previous"
        self.do_debug = False
        self.search_match_levels = {
            1: "Match",
            2: "Possible Match",
            3: "Possibly Related",
            4: "Name Only",
        }
        self.related_match_levels = {
            1: "Ambiguous Match",
            2: "Possible Match",
            3: "Possibly Related",
            4: "Name Only",
            11: "Disclosed Relation",
        }
        self.valid_match_level_parameters = {
            "0": "SINGLE_SAMPLE",
            "1": "DUPLICATE_SAMPLE",
            "2": "AMBIGUOUS_MATCH_SAMPLE",
            "3": "POSSIBLE_MATCH_SAMPLE",
            "4": "POSSIBLY_RELATED_SAMPLE",
            "S": "SINGLE_SAMPLE",
            "D": "DUPLICATE_SAMPLE",
            "M": "DUPLICATE_SAMPLE",
            "A": "AMBIGUOUS_MATCH_SAMPLE",
            "P": "POSSIBLE_MATCH_SAMPLE",
            "R": "POSSIBLY_RELATED_SAMPLE",
            "SINGLE": "SINGLE_SAMPLE",
            "DUPLICATE": "DUPLICATE_SAMPLE",
            "MATCH": "DUPLICATE_SAMPLE",
            "AMBIGUOUS": "AMBIGUOUS_MATCH_SAMPLE",
            "POSSIBLE": "POSSIBLE_MATCH_SAMPLE",
            "POSSIBLY": "POSSIBLY_RELATED_SAMPLE",
            "RELATED": "POSSIBLY_RELATED_SAMPLE",
        }

        self.category_sort_order = {
            "MATCH": 1,
            "AMBIGUOUS_MATCH": 2,
            "POSSIBLE_MATCH": 3,
            "POSSIBLY_RELATED": 4,
            "DISCLOSED_RELATION": 5,
        }

        self.last_entity_id = 0

        # get settings
        settings_file_name = "." + os.path.basename(sys.argv[0].lower().replace(".py", "")) + "_settings"

        self.settings_file_name = os.path.join(os.path.expanduser("~"), settings_file_name)

        self.current_settings = {}
        with suppress(Exception):
            self.current_settings = json.load(open(self.settings_file_name, encoding="utf-8"))

        # default last snapshot/audit file from parameters
        if self.cli_args.snapshot_file_name:
            self.current_settings["snapshotFile"] = self.cli_args.snapshot_file_name
        if self.cli_args.audit_file_name:
            self.current_settings["auditFile"] = self.cli_args.audit_file_name

        # load prior snapshot file
        if "snapshotFile" in self.current_settings and os.path.exists(self.current_settings["snapshotFile"]):
            self.do_load(self.current_settings["snapshotFile"])
        else:
            self.snapshot_file = None
            self.snapshot_data = {}

        # load prior audit file
        if "auditFile" in self.current_settings and os.path.exists(self.current_settings["auditFile"]):
            self.do_load(self.current_settings["auditFile"])
        else:
            self.audit_file = None
            self.audit_data = {}

        # default settings for data and cross sources summary reports
        self.configurable_settings_list = [
            {
                "setting": "color_scheme",
                "values": ["default", "light", "dark"],
                "description": "light works better on dark backgrounds and vice-versa",
            },
            {
                "setting": "data_source_suppression",
                "values": ["off", "on"],
                "description": "restricts the data and crossSourceSummary reports to only applicable data sources",
            },
            {
                "setting": "show_relations_on_get",
                "values": ["tree", "grid", "none"],
                "description": "display relationships on get in tree or grid or not at all",
            },
            {
                "setting": "audit_measure",
                "values": ["pairwise", "legacy"],
                "description": "show official pairwise or legacy (record based) statistics",
            },
            {
                "setting": "auto_scroll",
                "values": ["off", "on"],
                "description": "automatically go into scrolling mode if table larger than screen",
            },
        ]
        for setting_data in self.configurable_settings_list:
            self.current_settings[setting_data["setting"]] = self.current_settings.get(
                setting_data["setting"], setting_data["values"][0]
            )

        # set the color scheme
        self.do_set(f"color_scheme {self.current_settings['color_scheme']}")

        self.last_search_result = []
        self.current_review_list = None
        self.current_render_string = None

        # history
        self.readline_avail = True if "readline" in sys.modules else False
        self.histCheck()

        # feedback file
        self.feedback_log = []
        self.feedback_updated = False
        self.feedback_filename = json.loads(self.engine_settings)["PIPELINE"]["CONFIGPATH"] + os.sep + "feedback.log"
        if os.path.exists(self.feedback_filename):
            with open(self.feedback_filename, "r", encoding="utf-8") as f:
                self.feedback_log = [json.loads(x) for x in f.readlines()]

    # ---------------------------

    def execute_sz_api(
        self,
        api_name: str,
        flags: List[str],
        parms: Union[List[Union[str, int]], int, str],
    ) -> Dict[str, Any]:
        """# TODO"""
        parms = parms if isinstance(parms, list) else [parms]
        caller = inspect.stack()[1].function

        try:
            flags_int = SzEngineFlags.combine_flags(flags)
            parms.append(flags_int)
        except SzError as err:
            raise SzError(f"{caller}: {api_name} - {err}") from None

        try:
            api_call = getattr(self.sz_engine, api_name)
            response = api_call(*parms)
            response_data: Dict[str, Any] = json.loads(response)
        except AttributeError:
            raise SzError(f"{caller}: {api_name} not available in {self.api_version['BUILD_VERSION']}") from None
        except SzError as err:
            raise SzError(f"{caller}: {api_name} - {err}") from None

        if self.debugOutput:
            n_t = "\n\t"
            self.show_debug(
                caller,
                f"{api_name}\n\t{n_t.join(flags)}\n{json.dumps(response_data, indent=4)}",
            )

        return response_data

    def show_debug(self, call: str, output: str = "") -> None:
        """# TODO"""
        if self.debugOutput.upper() in ("S", "SCR", "SCREEN") and output:
            print(f"- {call} -\n")
            print(f"{output}\n")
            return

        try:
            with open(self.debugOutput, "a", encoding="utf-8") as f:
                f.write(f"- {call} -\n")
                f.write(f"{output}\n\n")
        except IOError as err:
            print(f"cannot write to {self.debugOutput}: {err}")

    def get_names(self):
        """hides functions from available list of Commands. Seperate help sections for some"""
        return [n for n in dir(self.__class__) if n not in self.__hidden_methods]

    def completenames(self, text, *ignored):
        dotext = "do_" + text
        return [a[3:] for a in self.get_names() if a.lower().startswith(dotext.lower())]

    # ---------------------------
    def emptyline(self):
        return

    # ---------------------------
    def do_quit(self, arg):
        remove_from_history()
        return True

    # ---------------------------
    def do_exit(self, arg):
        self.do_quit(self)
        return True

    # ---------------------------
    def cmdloop(self):
        while True:
            try:
                cmd.Cmd.cmdloop(self)
                break
            except KeyboardInterrupt:
                ans = input("\n\nAre you sure you want to exit?  ")
                if ans in ["y", "Y", "yes", "YES"]:
                    break
            except TypeError as ex:
                print_message(str(ex), "error")
                _, _, traceback_ = sys.exc_info()
                for item in traceback.format_tb(traceback_):
                    print(item)

    # ---------------------------
    def postloop(self):
        try:
            with open(self.settings_file_name, "w", encoding="utf-8") as f:
                json.dump(self.current_settings, f)
        except:
            pass

        if self.feedback_updated:
            print(f"merges logged to {self.feedback_filename}")
            with open(self.feedback_filename, "w", encoding="utf-8") as f:
                for record in self.feedback_log:
                    f.write(json.dumps(record) + "\n")

    def do_help(self, help_topic):
        if not help_topic:
            print(
                textwrap.dedent(
                    f"""\

            {colorize('Adhoc entity commands:', 'highlight2')}
                search {colorize('- search for entities by name and/or other attributes.', 'dim')}
                get {colorize('- get an entity by entity ID or record_id.', 'dim')}
                compare {colorize('- place two or more entities side by side for easier comparison.', 'dim')}
                how {colorize('- get a step by step replay of how an entity came together.', 'dim')}
                why {colorize('- see why entities or records either did or did not resolve.', 'dim')}
                tree {colorize("- see a tree view of an entity's relationships through 1 or 2 degrees.", 'dim')}
                export {colorize("- export the json records for an entity for debugging or correcting and reloading.", 'dim')}

            {colorize('Snapshot reports:', 'highlight2')} {colorize('(requires a json file created with G2Snapshot)', 'italics')}
                dataSourceSummary {colorize('– shows how many duplicates were detected within each data source, as well as ', 'dim')}
                {colorize('the possible matches and relationships that were derived. For example, how many duplicate customers ', 'dim')}
                {colorize('there are, and are any of them related to each other.', 'dim')}
                crossSourceSummary {colorize('– shows how many matches were made across data sources.  For example, how many ', 'dim')}
                {colorize('employees are related to customers.', 'dim')}
                entitySizeBreakdown {colorize("– shows how many entities of what size were created.  For instance, some entities ", 'dim')}
                {colorize("are singletons, some might have connected 2 records, some 3, etc.  This report is primarily used to", 'dim')}
                {colorize("ensure there are no instances of over matching.   For instance, it’s ok for an entity to have hundreds", 'dim')}
                {colorize("of records as long as there are not too many different names, addresses, identifiers, etc.", 'dim')}

            {colorize('Audit report:', 'highlight2')} {colorize('(requires a json file created with G2Audit)', 'italics')}
                auditSummary {colorize("- shows the precision, recall and F1 scores with the ability to browse the entities that", 'dim')}
                {colorize("were split or merged.", 'dim')}

            {colorize('Other commands:', 'highlight2')}
                quickLook {colorize("- show the number of records in the repository by data source without a snapshot.", 'dim')}
                load {colorize("- load a snapshot or audit report json file.", 'dim')}
                score {colorize("- show the scores of any two names, addresses, identifiers, or combination thereof.", 'dim')}
                set {colorize("- various settings affecting how entities are displayed.", 'dim')}

            {colorize('Senzing Knowledge Center:', 'dim')} {colorize('https://senzing.zendesk.com/hc/en-us', 'highlight2, underline')}
            {colorize('Senzing Support Request:', 'dim')} {colorize('https://senzing.zendesk.com/hc/en-us/requests/new', 'highlight2, underline')}

             """
                )
            )
        else:
            cmd.Cmd.do_help(self, help_topic)

    # ---------------------------
    def help_knowledgeCenter(self):
        print(
            f"\nSenzing Knowledge Center: {colorize('https://senzing.zendesk.com/hc/en-us', 'highlight2, underline')}\n"
        )

    # ---------------------------
    def help_support(self):
        print(
            f"\nSenzing Support Request: {colorize('https://senzing.zendesk.com/hc/en-us/requests/new', 'highlight2, underline')}\n"
        )

    # ---------------------------
    def histCheck(self):

        self.histFileName = None
        self.histFileError = None
        self.histAvail = False

        if not self.histDisable:

            if readline:
                tmpHist = "." + os.path.basename(sys.argv[0].lower().replace(".py", "_history"))
                self.histFileName = os.path.join(os.path.expanduser("~"), tmpHist)

                # Try and open history in users home first for longevity
                try:
                    open(self.histFileName, "a").close()
                except IOError as e:
                    self.histFileError = f"{e} - Couldn't use home, trying /tmp/..."

                # Can't use users home, try using /tmp/ for history useful at least in the session
                if self.histFileError:

                    self.histFileName = f"/tmp/{tmpHist}"
                    try:
                        open(self.histFileName, "a").close()
                    except IOError as e:
                        self.histFileError = f"{e} - User home dir and /tmp/ failed!"
                        return

                hist_size = 2000
                readline.read_history_file(self.histFileName)
                readline.set_history_length(hist_size)
                atexit.register(readline.set_history_length, hist_size)
                atexit.register(readline.write_history_file, self.histFileName)

                self.histFileName = self.histFileName
                self.histFileError = None
                self.histAvail = True

    # ---------------------------
    def do_history(self, arg):

        if self.histAvail:
            print()
            for i in range(readline.get_current_history_length()):
                print(readline.get_history_item(i + 1))
            print()
        else:
            print_message("History isn't available in this session", "warning")

    # ---------------------------
    def do_shell(self, line):
        """\nRun OS shell commands: !<command>\n"""
        if line:
            output = os.popen(line).read()
            print(f"\n{output}\n")

    # ---------------------------
    def help_set(self):
        print(
            textwrap.dedent(
                f"""\

        {colorize('Syntax:', 'highlight2')}
            set <setting> <value>

        {colorize('settings:', 'highlight2')} """
            )
        )
        print(
            colorize(
                f"    {'setting':<23} {'[possible values]':<22} {'current':<13} {'description'}",
                "dim",
            )
        )
        for setting_data in self.configurable_settings_list:
            current_value = colorize(self.current_settings[setting_data["setting"]], "bold")
            print(
                f"    {setting_data['setting']:<23} {'[' + ', '.join(setting_data['values']) + ']':<22} {current_value:<22} {colorize(setting_data['description'], 'dim')}"
            )
        print()

    # ---------------------------
    def complete_set(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)

        arg = line[before_arg + 1 : endidx]

        possibles = []
        spaces = line.count(" ")
        if spaces <= 1:
            possibles = [x["setting"] for x in self.configurable_settings_list]
        elif spaces == 2:
            setting = line.split()[1]
            for setting_data in self.configurable_settings_list:
                if setting_data["setting"] == setting:
                    possibles = setting_data["values"]

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_set(self, arg):
        if not arg:
            self.help_set()
            return

        settings_dict = {}
        for setting_data in self.configurable_settings_list:
            settings_dict[setting_data["setting"]] = setting_data["values"]

        if settings_dict:
            arg_list = arg.split()
            if (
                len(arg_list) != 2
                or (arg_list[0] not in settings_dict)
                or (arg_list[1] not in settings_dict[arg_list[0]])
            ):
                print_message("Invalid setting", "error")
                return

        self.current_settings[arg_list[0]] = arg_list[1]
        if arg_list[0] == "color_scheme":
            Colors.set_theme(arg_list[1])

    # ---------------------------
    def do_version(self, arg):
        print(f"\nSenzing API version: {self.api_version['BUILD_VERSION']}\n")

    # ---------------------------
    def help_load(self):

        print(
            textwrap.dedent(
                f"""\

        {colorize('Syntax:', 'highlight2')}
            load <snapshotFile.json>  {colorize('loads a snapshot file for review', 'dim')}
            load <auditFile.json>     {colorize('loads an audit file for review', 'dim')}

        """
            )
        )

    # ---------------------------
    def do_load(self, arg):

        statpack_file_name = arg
        if not os.path.exists(statpack_file_name):
            print_message("File not found!", "error")
            return

        try:
            json_data = json.load(open(statpack_file_name, encoding="utf-8"))
        except ValueError as err:
            print_message(err, "error")
            return

        # TODO - G2Snapshot?
        if "SOURCE" in json_data and json_data["SOURCE"] in ("G2Snapshot"):  # 'pocSnapshot',
            self.current_settings["snapshotFile"] = statpack_file_name
            self.snapshot_file = statpack_file_name
            self.snapshot_data = json_data
            print_message(f"successfully loaded {statpack_file_name}", "info")
        elif "SOURCE" in json_data and json_data["SOURCE"] in ("G2Audit"):  # 'pocAudit',
            self.current_settings["auditFile"] = statpack_file_name
            self.audit_file = statpack_file_name
            self.audit_data = json_data
            print_message(f"successfully loaded {statpack_file_name}", "info")
        else:
            print_message("Invalid G2Explorer statistics file", "error")

    # ---------------------------
    def complete_load(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        if before_arg == -1:
            return  # arg not found

        fixed = line[before_arg + 1 : begidx]  # fixed portion of the arg
        arg = line[before_arg + 1 : endidx]
        pattern = arg + "*"

        completions = []
        for path in glob.glob(pattern):
            path = _append_slash_if_dir(path)
            completions.append(path.replace(fixed, "", 1))
        return completions

    # ---------------------------
    def help_quickLook(self):
        print("\nDisplays current data source stats without a snapshot\n")

    # ---------------------------
    def do_quickLook(self, arg):
        if not DATABASE_ACCESS:
            print_message(f"\nDirect database access is required, database drivers must be installed\n", "error")
            return
        tblTitle = "Data source counts"
        tblColumns = [
            {"name": "id", "width": 5, "align": "center"},
            {"name": "DataSource", "width": 30, "align": "left"},
            {"name": "ActualRecordCount", "width": 20, "align": "right"},
            {"name": "DistinctRecordCount", "width": 20, "align": "right"},
        ]
        sql = "select DSRC_ID, count(*) as RECORD_COUNT, count(distinct ENT_SRC_KEY) as UNIQUE_COUNT from DSRC_RECORD"
        tblRows = []
        actual_count = distinct_count = 0
        for row in self.sz_dbo.fetchAllDicts(self.sz_dbo.sqlExec(sql)):
            tblRows.append(
                [
                    colorize(row["DSRC_ID"], "row_title"),
                    colorize_dsrc(self.dsrc_lookup[row["DSRC_ID"]]["DSRC_CODE"]),
                    "{:,}".format(row["RECORD_COUNT"]),
                    "{:,}".format(row["UNIQUE_COUNT"]),
                ]
            )
            actual_count += row["RECORD_COUNT"]
            distinct_count += row["UNIQUE_COUNT"]
        if len(tblRows) > 1:
            tblRows.append(
                [
                    "",
                    colorize("  Totals", "row_title"),
                    colorize("{:,}".format(actual_count), "row_title"),
                    colorize("{:,}".format(distinct_count), "row_title"),
                ]
            )
        self.render_table(tblTitle, tblColumns, tblRows)

    # print("\nNot currently implemented in V4 beta\n")

    # try:
    #     g2_diagnostic_module = G2Diagnostic()
    #     g2_diagnostic_module.init("pyG2Diagnostic", iniParams, False)
    #     response = bytearray()
    #     g2_diagnostic_module.getDataSourceCounts(response)
    #     response = response.decode() if response else ""
    #     g2_diagnostic_module.destroy()
    # except G2Exception as err:
    #     print_message(err, "error")
    #     return
    # jsonResponse = json.loads(response)

    # tblTitle = "Data source counts"
    # tblColumns = []
    # tblColumns.append({"name": "id", "width": 5, "align": "center"})
    # tblColumns.append({"name": "DataSource", "width": 30, "align": "left"})
    # tblColumns.append({"name": "ActualRecordCount", "width": 20, "align": "right"})
    # tblColumns.append(
    #     {"name": "DistinctRecordCount", "width": 20, "align": "right"}
    # )
    # tblRows = []
    # actual_count = distinct_count = 0
    # for row in jsonResponse:
    #     tblRow = []
    #     tblRow.append(colorize(row["DSRC_ID"], "row_title"))
    #     tblRow.append(colorize_dsrc(row["DSRC_CODE"]))
    #     tblRow.append("{:,}".format(row["DSRC_RECORD_COUNT"]))
    #     tblRow.append("{:,}".format(row["OBS_ENT_COUNT"]))
    #     tblRows.append(tblRow)
    #     actual_count += row["DSRC_RECORD_COUNT"]
    #     distinct_count += row["OBS_ENT_COUNT"]
    # tblRows.append(
    #     [
    #         "",
    #         colorize("  Totals", "row_title"),
    #         colorize("{:,}".format(actual_count), "row_title"),
    #         colorize("{:,}".format(distinct_count), "row_title"),
    #     ]
    # )

    # self.renderTable(tblTitle, tblColumns, tblRows)

    # ---------------------------
    def move_pointer(self, reply, current_item, max_items):
        """moves the sample record pointer for all reports"""
        if reply.upper().startswith("P"):  # previous
            if current_item == 0:
                input("\nNo prior records, press enter to continue")
            else:
                return current_item - 1
        elif reply.upper().startswith("N"):  # next
            if current_item == max_items - 1:
                input("\nno more records, press enter to continue")
            else:
                return current_item + 1
        elif reply.upper().startswith("G"):  # goto
            reply = reply[1:]
            if not reply:
                reply = input("\nSample item number to go to? ")
                if reply:
                    remove_from_history()
            if reply:
                if reply.isnumeric() and int(reply) > 0 and int(reply) <= max_items:
                    return int(reply) - 1
                else:
                    print_message("Invalid sample item number for this sample set!", "warning")
        return current_item

    # ---------------------------
    def export_report_sample(self, reply, currentRecords, fileName):
        if "TO " in reply.upper():
            fileName = reply[reply.upper().find("TO") + 2 :].strip()
        if fileName:
            self.do_export(",".join(currentRecords) + " to " + fileName)

    # ---------------------------
    def help_auditSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays audit statistics and examples.

        {colorize('Syntax:', 'highlight2')}
            auditSummary                        {colorize('with no parameters displays the overall stats', 'dim')}
            auditSummary merge                  {colorize('shows a list of merge sub-categories', 'dim')}
            auditSummary merge 1                {colorize('shows examples of merges in sub-category 1', 'dim')}
            auditSummary split                  {colorize('shows a list of split sub-categories', 'dim')}
            auditSummary split 1                {colorize('shows examples of splits in sub-category 1', 'dim')}
            auditSummary save to <filename.csv> {colorize('saves the entire audit report to a csv file', 'dim')}

        """
            )
        )

    # ---------------------------
    def complete_auditSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)

        arg = line[before_arg + 1 : endidx]

        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.audit_data:
                for category in self.audit_data["AUDIT"]:
                    possibles.append(category)
        else:
            possibles = []

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_auditSummary(self, arg):

        if not self.audit_data or "AUDIT" not in self.audit_data:
            print_message(
                "Please load a json file created with G2Audit.py to use this command",
                "warning",
            )
            return
        elif not self.audit_data["ENTITY"].get("PRIOR_COUNT"):
            print_message(
                "Prior version audit file detected.  Please review with the prior version or re-create for this one.",
                "warning",
            )
            return

        category_colors = {}
        category_colors["MERGE"] = "good"
        category_colors["SPLIT"] = "bad"
        category_colors["SPLIT+MERGE"] = "fg_red,bg_green"
        category_colors["unknown"] = "bg_red,fg_white"

        # display the summary if no arguments
        if not arg:
            audit_categories = []
            category_order = {"MERGE": 0, "SPLIT": 1, "SPLIT+MERGE": 2}
            for category in sorted(
                self.audit_data["AUDIT"].keys(),
                key=lambda x: category_order[x] if x in category_order else 9,
            ):
                category_color = (
                    category_colors[category] if category in category_colors else category_colors["unknown"]
                )
                category_data = [
                    colorize(category, category_color),
                    colorize(
                        fmt_statistic(self.audit_data["AUDIT"][category]["COUNT"]),
                        "bold",
                    ),
                ]
                audit_categories.append(category_data)
            while len(audit_categories) < 3:
                audit_categories.append(["", 0])

            # show records or pairs
            if self.current_settings["audit_measure"] == "pairwise":
                audit_measure = "PAIRS"
                audit_header = "Pairs"
            else:
                audit_measure = "RECORDS"
                audit_header = "Matches"

            tbl_title = "Audit Summary from %s" % self.audit_file
            tbl_columns = []
            tbl_columns.append({"name": "Statistic1", "width": 25, "align": "left"})
            tbl_columns.append({"name": "Entities", "width": 25, "align": "right"})
            tbl_columns.append({"name": audit_header, "width": 25, "align": "right"})
            tbl_columns.append({"name": colorize("-", "invisible"), "width": 5, "align": "center"})
            tbl_columns.append({"name": "Statistic2", "width": 25, "align": "left"})
            tbl_columns.append({"name": "Accuracy", "width": 25, "align": "right"})
            tbl_rows = []

            row = []
            row.append(colorize("Prior Count", "highlight2"))
            row.append(fmt_statistic(self.audit_data["ENTITY"].get("PRIOR_COUNT", -1)))
            row.append(fmt_statistic(self.audit_data[audit_measure].get("PRIOR_COUNT", -1)))
            row.append("")
            row.append(colorize("Same Positives", "highlight2"))
            row.append(colorize(fmt_statistic(self.audit_data[audit_measure]["SAME_POSITIVE"]), None))
            tbl_rows.append(row)

            row = []
            row.append(colorize("Newer Count", "highlight2"))
            row.append(fmt_statistic(self.audit_data["ENTITY"].get("NEWER_COUNT", -1)))
            row.append(fmt_statistic(self.audit_data[audit_measure].get("NEWER_COUNT", -1)))
            row.append("")
            row.append(colorize("New Positives", category_colors["MERGE"]))
            row.append(colorize(fmt_statistic(self.audit_data[audit_measure]["NEW_POSITIVE"]), None))
            tbl_rows.append(row)

            row = []
            row.append(colorize("Common Count", "highlight2"))
            row.append(fmt_statistic(self.audit_data["ENTITY"].get("COMMON_COUNT", -1)))
            row.append(fmt_statistic(self.audit_data[audit_measure].get("COMMON_COUNT", -1)))
            row.append("")
            row.append(colorize("New Negatives", category_colors["SPLIT"]))
            row.append(colorize(fmt_statistic(self.audit_data[audit_measure]["NEW_NEGATIVE"]), None))
            tbl_rows.append(row)

            row = []
            row.append(audit_categories[0][0])
            row.append(audit_categories[0][1])
            row.append(
                ""
            )  # (colorize(self.auditData['PAIRS']['INCREASE'], 'good') if self.auditData['PAIRS']['INCREASE'] else '')
            row.append("")
            row.append(colorize("Precision", "highlight2"))
            row.append(colorize(self.audit_data[audit_measure]["PRECISION"], None))
            tbl_rows.append(row)

            row = []
            row.append(audit_categories[1][0])
            row.append(audit_categories[1][1])
            row.append(
                ""
            )  # (colorize(self.auditData['PAIRS']['DECREASE'], 'bad') if self.auditData['PAIRS']['DECREASE'] else '')
            row.append("")
            row.append(colorize("Recall", "highlight2"))
            row.append(colorize(self.audit_data[audit_measure]["RECALL"], None))
            tbl_rows.append(row)

            row = []
            row.append(audit_categories[2][0])
            row.append(audit_categories[2][1])
            row.append(
                ""
            )  # (colorize(self.auditData['PAIRS']['SIMILAR'], 'highlight1') if self.auditData['PAIRS']['SIMILAR'] else '')
            row.append("")
            row.append(colorize("F1 Score", "highlight2"))
            row.append(colorize(self.audit_data[audit_measure]["F1-SCORE"], None))
            tbl_rows.append(row)

            # add any extra categories (which will occur if there were missing records)
            if len(audit_categories) > 3:
                i = 3
                while i < len(audit_categories):
                    row = []
                    row.append(audit_categories[i][0])
                    row.append(audit_categories[i][1])
                    row.append("")
                    row.append("")
                    row.append("")
                    row.append("")
                    tbl_rows.append(row)
                    i += 1

            self.render_table(tbl_title, tbl_columns, tbl_rows)

        # build complete report and save to a file
        elif arg.upper().startswith("SAVE"):
            file_name = arg[7:].strip()
            file_headers = ["category", "sub_category", "audit_id"]
            file_rows = []
            row_cnt = 0
            for category in self.audit_data["AUDIT"]:
                for sub_category in self.audit_data["AUDIT"][category]["SUB_CATEGORY"]:
                    for sample_records in self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["SAMPLE"]:
                        table_columns, table_data = self.showAuditSample(
                            sample_records, None
                        )  # 2nd parameter cuts out colorize for save to file
                        record_headers = []
                        for column_dict in table_columns:
                            column_name = column_dict["name"].lower()
                            if column_name not in record_headers:
                                record_headers.append(column_name)
                            if column_name not in file_headers:
                                file_headers.append(column_name)
                        for record_data in table_data:
                            row_data = dict(zip(record_headers, record_data))
                            row_data["category"] = category
                            row_data["sub_category"] = sub_category
                            row_data["audit_id"] = sample_records[0]["audit_id"]
                            file_rows.append(row_data)
                            row_cnt += 1
                            if row_cnt % 1000 == 0:
                                print(f"{row_cnt} records processed")

            with open(file_name, "w", encoding="utf-8") as f:
                w = csv.DictWriter(f, file_headers, dialect=csv.excel, quoting=csv.QUOTE_ALL)
                w.writeheader()
                for row_data in file_rows:
                    w.writerow(row_data)
            print_message(f"{row_cnt} records written to {file_name}!", "success")

        # display next level report
        else:
            arg_list = arg.upper().split()
            if arg_list[0] not in self.audit_data["AUDIT"]:
                print_message(
                    f"{arg} not found, please choose a valid split or merge category",
                    "error",
                )
                return

            category = arg_list[0]
            category_color = category_colors[category] if category in category_colors else category_colors["unknown"]

            # get top 10 sub categories
            i = 0
            sub_category_list = []
            for sub_category in sorted(
                self.audit_data["AUDIT"][category]["SUB_CATEGORY"],
                key=lambda x: self.audit_data["AUDIT"][category]["SUB_CATEGORY"][x]["COUNT"],
                reverse=True,
            ):

                i += 1
                if i <= 10:
                    sub_category_list.append(
                        {
                            "INDEX": i,
                            "NAME": sub_category,
                            "LIST": [sub_category],
                            "COUNT": self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["COUNT"],
                        }
                    )
                elif i == 11:
                    sub_category_list.append(
                        {
                            "INDEX": i,
                            "NAME": "OTHERS",
                            "LIST": [sub_category],
                            "COUNT": self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["COUNT"],
                        }
                    )
                else:
                    sub_category_list[10]["LIST"].append(sub_category)
                    sub_category_list[10]["COUNT"] += self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category][
                        "COUNT"
                    ]

            # display sub-categories
            if len(arg_list) == 1:
                tbl_title = category + " Categories"
                tbl_columns = []
                tbl_columns.append({"name": "Index", "width": 10, "align": "center"})
                tbl_columns.append({"name": "Category", "width": 25, "align": "left"})
                tbl_columns.append({"name": "Sub-category", "width": 75, "align": "left"})
                tbl_columns.append({"name": "Count", "width": 25, "align": "right"})
                tbl_rows = []
                for sub_category_row in sub_category_list:
                    tbl_rows.append(
                        [
                            colorize(sub_category_row["INDEX"], "row_title"),
                            colorize(category, category_color),
                            sub_category_row["NAME"],
                            fmt_statistic(sub_category_row["COUNT"]),
                        ]
                    )
                self.render_table(tbl_title, tbl_columns, tbl_rows)

                return

            # find the detail records to display
            index_categories = []
            if arg_list[1].isdigit():
                for sub_category_row in sub_category_list:
                    if sub_category_row["INDEX"] == int(arg_list[1]):
                        index_categories = sub_category_row["LIST"]
                        break

            if not index_categories:
                print_message(f"Invalid subcategory for {arg_list[0].lower()}", "error")
                return

            # gather sample records
            sample_records = []
            for sub_category in self.audit_data["AUDIT"][category]["SUB_CATEGORY"]:
                if sub_category in index_categories:
                    sample_records += self.audit_data["AUDIT"][category]["SUB_CATEGORY"][sub_category]["SAMPLE"]

            # display sample records
            current_sample = 0
            while True:
                current_records = list(set([x["newer_id"] for x in sample_records[current_sample]]))
                self.current_review_list = f"Item {current_sample + 1} of {len(sample_records)} for {arg_list[0]} category {arg_list[1]} - {sub_category_row['NAME']}"
                self.showAuditSample(sample_records[current_sample], category_colors)
                while True:
                    if len(current_records) == 1:
                        reply = input(
                            colorize_prompt(
                                "Select (P)revious, (N)ext, (G)oto, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ... "
                            )
                        )
                        special_actions = "HWE"
                    else:
                        reply = input(
                            colorize_prompt("Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ... ")
                        )
                        special_actions = "WE"
                    if reply:
                        remove_from_history()
                    else:
                        reply = "N"
                    if reply.upper().startswith("Q"):
                        break
                    elif reply.upper() == ("S"):
                        self.do_scroll("")
                    elif reply.upper()[0] in "PNG":  # previous, next, goto
                        current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                        break
                    elif reply.upper()[0] in special_actions:
                        if reply.upper().startswith("W2"):
                            self.do_why(",".join(current_records) + " old")
                        elif reply.upper().startswith("W"):
                            self.do_why(",".join(current_records))
                        elif reply.upper().startswith("H"):
                            self.do_how(",".join(current_records))
                            break
                        elif reply.upper().startswith("E"):
                            self.export_report_sample(
                                reply,
                                current_records,
                                f"auditSample-{sample_records[current_sample][0]['audit_id']}.json",
                            )
                if reply.upper().startswith("Q"):
                    break
            self.current_review_list = None

    # ---------------------------
    def showAuditSample(self, arg, category_colors=None):

        audit_records = arg

        tbl_title = "Audit Result ID %s %s" % (
            audit_records[0]["audit_id"],
            audit_records[0]["audit_category"],
        )
        tbl_columns = []
        tbl_columns.append({"name": "DataSource", "width": 30, "align": "left"})
        tbl_columns.append({"name": "Record ID", "width": 30, "align": "left"})
        tbl_columns.append({"name": "Prior ID", "width": 20, "align": "left"})
        tbl_columns.append({"name": "Prior Score", "width": 75, "align": "left"})
        tbl_columns.append({"name": "Newer ID", "width": 20, "align": "left"})
        tbl_columns.append({"name": "Newer Score", "width": 75, "align": "left"})
        tbl_columns.append({"name": "Audit result", "width": 10, "align": "left"})

        entity_list = list(set([x["newer_id"] for x in audit_records]))

        get_flag_list = []
        get_flag_list.append("SZ_ENTITY_INCLUDE_ALL_FEATURES")
        get_flag_list.append("SZ_ENTITY_INCLUDE_ENTITY_NAME")
        get_flag_list.append("SZ_ENTITY_INCLUDE_RECORD_DATA")
        get_flag_list.append("SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO")
        get_flag_list.append("SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS")

        # gather all the record data
        ftypes_used = []
        record_list = []
        entity_list = set([x["newer_id"] for x in audit_records])
        for entity_id in entity_list:
            if entity_id == "unknown":  # bypass missing
                continue
            try:
                json_data = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                # TODO calledDirect not defined
                return -1 if calledDirect else 0

            # get the list of features for the entity
            entity_features = {}
            for ftype_code in json_data["RESOLVED_ENTITY"]["FEATURES"]:
                if ftype_code in ("REL_ANCHOR", "REL_POINTER"):
                    continue
                ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                if ftype_id not in ftypes_used:
                    ftypes_used.append(ftype_id)
                for distinct_feature_record in json_data["RESOLVED_ENTITY"]["FEATURES"][ftype_code]:
                    for feat_record in distinct_feature_record["FEAT_DESC_VALUES"]:
                        lib_feat_id = feat_record["LIB_FEAT_ID"]
                        entity_features[lib_feat_id] = {}
                        entity_features[lib_feat_id]["ftypeId"] = ftype_id
                        entity_features[lib_feat_id]["ftypeCode"] = ftype_code
                        entity_features[lib_feat_id]["featDesc"] = feat_record["FEAT_DESC"]

            # get the list of features for each record
            for record in json_data["RESOLVED_ENTITY"]["RECORDS"]:
                record_features = {}
                for feat_record in record["FEATURES"]:
                    lib_feat_id = feat_record["LIB_FEAT_ID"]
                    if lib_feat_id in entity_features:
                        ftype_id = entity_features[lib_feat_id]["ftypeId"]
                        ftype_code = entity_features[lib_feat_id]["ftypeCode"]
                        if ftype_id not in record_features:
                            record_features[ftype_id] = []
                        record_features[ftype_id].append(entity_features[lib_feat_id])

                small_record = {}
                small_record["DATA_SOURCE"] = record["DATA_SOURCE"]
                small_record["RECORD_ID"] = record["RECORD_ID"]
                small_record["features"] = record_features
                record_list.append(small_record)

        # combine the features with the actual audit records
        updated_records = []
        for audit_record in audit_records:
            if "data_source" in audit_record:
                this_record = [
                    x
                    for x in record_list
                    if x["RECORD_ID"] == audit_record["record_id"] and x["DATA_SOURCE"] == audit_record["data_source"]
                ]
            else:
                this_record = [x for x in record_list if x["RECORD_ID"] == audit_record["record_id"]]

            if len(this_record) != 1:
                audit_record["features"] = {}
                audit_record["record_id"] = "** " + audit_record["record_id"]
            else:
                audit_record["features"] = this_record[0]["features"]
            updated_records.append(audit_record)

        # add the columns to the table format and do the final formatting
        ftypes_used = sorted(ftypes_used)
        for ftype_id in ftypes_used:
            ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
            tbl_columns.append({"name": ftype_code, "width": 50, "align": "left"})

        status_sort_order = {}
        status_sort_order["same"] = "1"
        status_sort_order["new negative"] = "3"
        status_sort_order["new positive"] = "2"
        status_sort_order["missing"] = "4"

        tbl_rows = []
        for audit_record in sorted(
            updated_records,
            key=lambda k: [
                status_sort_order[k["audit_result"]],
                str(k["prior_id"]),
                str(k["newer_id"]),
            ],
        ):

            if category_colors:
                if audit_record["audit_result"].upper() == "NEW POSITIVE":
                    audit_result_color = category_colors["MERGE"]
                elif audit_record["audit_result"].upper() == "NEW NEGATIVE":
                    audit_result_color = category_colors["SPLIT"]
                elif audit_record["audit_result"].upper() == "MISSING":
                    audit_result_color = category_colors["unknown"]
                else:
                    audit_result_color = "bold"
            else:
                audit_result_color = None
            row = []
            row.append(
                colorize(
                    audit_record["data_source"],
                    "dsrc_color" if category_colors else None,
                )
                if "data_source" in audit_record
                else ""
            )
            row.append(audit_record["record_id"])
            row.append(audit_record["prior_id"])
            row.append(audit_record["prior_score"])
            row.append(
                colorize(
                    str(audit_record["newer_id"]),
                    "entity_color" if category_colors else None,
                )
            )
            row.append(audit_record["newer_score"])
            row.append(
                colorize(
                    str(audit_record["audit_result"]),
                    audit_result_color if category_colors else None,
                )
            )

            for ftype_id in ftypes_used:
                column_value = ""
                if ftype_id in audit_record["features"]:
                    column_value = "\n".join([x["featDesc"] for x in audit_record["features"][ftype_id]])
                row.append(column_value)

            tbl_rows.append(row)

        if not category_colors:
            return tbl_columns, tbl_rows
        else:
            self.render_table(tbl_title, tbl_columns, tbl_rows)
            return

    # ---------------------------
    def help_entitySizeBreakdown(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the number of entities by how many records they contain.

        {colorize('Syntax:', 'highlight2')}
            entitySizeBreakdown                    {colorize('with no parameters displays the overall stats', 'dim')}
            entitySizeBreakdown = 3                {colorize('use =, > or < # to select examples of entities of a certain size', 'dim')}
            entitySizeBreakdown > 10 review        {colorize('to just browse the review items of entities greater than size 10', 'dim')}
            entitySizeBreakdown = review name+addr {colorize('to just browse the name+addr review items of any size', 'dim')}

        {colorize('review items:', 'highlight2')}
            Review items are suggestions of records to look at because they contain multiple names, addresses, dobs, etc.
            They may be overmatches or they may just be large entities with lots of values.

        """
            )
        )

    # ---------------------------
    def do_entitySizeBreakdown(self, arg):

        if not self.snapshot_data or (
            not self.snapshot_data.get("ENTITY_SIZE_BREAKDOWN") and not self.snapshot_data.get("TEMP_ESB_STATS")
        ):
            print_message(
                "Please load a json file created with G2Snapshot.py to access this report",
                "warning",
            )
            return

        if not self.snapshot_data.get("ENTITY_SIZE_BREAKDOWN"):
            self.compute_entitySizeBreakdown()

        # display the summary if no arguments
        if not arg:
            tbl_title = "Entity Size Breakdown from %s" % self.snapshot_file
            tbl_columns = []
            tbl_columns.append({"name": "Entity Size", "width": 10, "align": "center"})
            tbl_columns.append({"name": "Entity Count", "width": 10, "align": "center"})
            tbl_columns.append({"name": "Review Count", "width": 10, "align": "center"})
            tbl_columns.append({"name": "Review Features", "width": 75, "align": "left"})

            tbl_rows = []
            for entity_size_data in sorted(
                self.snapshot_data["ENTITY_SIZE_BREAKDOWN"],
                key=lambda k: k["ENTITY_SIZE"],
                reverse=True,
            ):
                row = []
                row.append(colorize(entity_size_data["ENTITY_SIZE_GROUP"], "row_title"))
                row.append(fmt_statistic(entity_size_data["ENTITY_COUNT"]))
                row.append(fmt_statistic(entity_size_data["REVIEW_COUNT"]))
                row.append(" | ".join(colorize(x, "caution") for x in sorted(entity_size_data["REVIEW_FEATURES"])))
                tbl_rows.append(row)
            self.render_table(tbl_title, tbl_columns, tbl_rows)

        else:
            sign = "="
            size = 0
            review_tag = False
            review_features = []
            arg_list = arg.split()
            for token in arg_list:
                if token[0:2] in (">=", "<="):
                    sign = token[0:2]
                    if len(token) > 2 and token[2:].isnumeric():
                        size = int(token[2:])
                elif token[0:1] in (">", "<", "="):
                    sign = token[0:1]
                    if len(token) > 1 and token[1:].isnumeric():
                        size = int(token[1:])
                elif token.isnumeric():
                    size = int(token)
                elif token.upper() == "REVIEW":
                    review_tag = True
                else:
                    review_features.append(token.upper())

            if not size:
                size = 1
                sign = ">"

            sample_records = []
            for entity_size_data in self.snapshot_data["ENTITY_SIZE_BREAKDOWN"]:

                # add these entities if they satisfy the entity size argument
                if sign in ("=", ">=", "<=") and entity_size_data["ENTITY_SIZE"] == size:
                    these_records = entity_size_data["SAMPLE_ENTITIES"]
                elif sign in ("<", "<=") and entity_size_data["ENTITY_SIZE"] < size:
                    these_records = entity_size_data["SAMPLE_ENTITIES"]
                elif sign in (">", ">=") and entity_size_data["ENTITY_SIZE"] > size:
                    these_records = entity_size_data["SAMPLE_ENTITIES"]
                else:
                    continue

                # filter for review features
                if review_tag or review_features:
                    review_records = []
                    for entity_info in these_records:
                        if "REVIEW_FEATURES" not in entity_info:
                            continue
                        if review_features:
                            review_criteria_not_met = False
                            for ftype_code in review_features:
                                if ftype_code not in entity_info["REVIEW_FEATURES"]:
                                    review_criteria_not_met = True
                                    break
                            if review_criteria_not_met:
                                continue
                        review_records.append(entity_info)
                    these_records = review_records

                sample_records.extend(these_records)

            if len(sample_records) == 0:
                print_message("No records found", "warning")
            else:

                current_sample = 0
                while True:
                    self.current_review_list = f"Item {current_sample + 1} of {len(sample_records)} for Entity Size {sample_records[current_sample]['ENTITY_SIZE']}"
                    if "REVIEW_FEATURES" in sample_records[current_sample]:
                        review_items = []
                        for ftype_code in sample_records[current_sample]["REVIEW_FEATURES"]:
                            review_items.append(f"{ftype_code} ({sample_records[current_sample][ftype_code]})")
                        self.current_review_list += ", review for: " + ", ".join(review_items)

                    current_records = [str(sample_records[current_sample]["ENTITY_ID"])]
                    return_code = self.do_get(current_records[0])
                    if return_code != 0:
                        print_message("This entity no longer exists", "error")
                    while True:
                        reply = input(
                            colorize_prompt(
                                "Select (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                            )
                        )
                        if reply:
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply.upper().startswith("Q"):
                            break
                        elif reply.upper() == ("S"):
                            self.do_scroll("")
                        elif reply.upper()[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply.upper()[0] in "DHWE":
                            if reply.upper().startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply.upper().startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply.upper().startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply.upper().startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )
                    if reply.upper().startswith("Q"):
                        break
                self.current_review_list = None

    # ---------------------------
    def compute_entitySizeBreakdown(self):
        esb_data = {}
        for str_entity_size in sorted(self.snapshot_data["TEMP_ESB_STATS"].keys()):
            entity_size = int(str_entity_size)
            if entity_size <= 3:  # super small
                max_exclusive_cnt = 1
                max_name_cnt = 2
                max_addr_cnt = 2
            elif entity_size <= 10:  # small
                max_exclusive_cnt = 1
                max_name_cnt = 3
                max_addr_cnt = 3
            elif entity_size <= 50:  # medium
                max_exclusive_cnt = 1
                max_name_cnt = 10
                max_addr_cnt = 10
            else:  # large
                max_exclusive_cnt = 1  # large
                max_name_cnt = 25
                max_addr_cnt = 25

            # setup for the entity size
            if entity_size < 10:
                entity_size_level = entity_size
            elif entity_size < 100:
                entity_size_level = int(entity_size / 10) * 10
            else:
                entity_size_level = int(entity_size / 100) * 100
            if entity_size_level not in esb_data:
                esb_data[entity_size_level] = {
                    "ENTITY_COUNT": 0,
                    "SAMPLE_ENTITIES": [],
                    "REVIEW_COUNT": 0,
                    "REVIEW_FEATURES": [],
                }
            esb_data[entity_size_level]["ENTITY_COUNT"] += self.snapshot_data["TEMP_ESB_STATS"][str_entity_size][
                "COUNT"
            ]

            # review each entity
            for sample_record in self.snapshot_data["TEMP_ESB_STATS"][str_entity_size]["SAMPLE"]:
                review_features = []
                for raw_attr in sample_record.keys():
                    if raw_attr in ("ENTITY_ID", "ENTITY_SIZE"):
                        continue
                    ftype_code = raw_attr
                    ftype_excl = self.ftype_code_lookup[ftype_code]["FTYPE_EXCL"]
                    distinct_feature_count = sample_record[ftype_code]
                    if ftype_code == "NAME" and distinct_feature_count > max_name_cnt:
                        review_features.append(ftype_code)
                    elif ftype_code == "ADDRESS" and distinct_feature_count > max_addr_cnt:
                        review_features.append(ftype_code)
                    elif ftype_excl == "Yes" and distinct_feature_count > max_exclusive_cnt:
                        review_features.append(ftype_code)
                if review_features:
                    sample_record["REVIEW_FEATURES"] = review_features
                    esb_data[entity_size_level]["REVIEW_FEATURES"] = list(
                        set(esb_data[entity_size_level]["REVIEW_FEATURES"] + review_features)
                    )
                    esb_data[entity_size_level]["REVIEW_COUNT"] += 1
                esb_data[entity_size_level]["SAMPLE_ENTITIES"].append(sample_record)

        self.snapshot_data["ENTITY_SIZE_BREAKDOWN"] = []
        for entity_size_level in sorted(esb_data.keys()):
            entity_size_record = esb_data[entity_size_level]
            entity_size_record["ENTITY_SIZE"] = entity_size_level
            entity_size_record["ENTITY_SIZE_GROUP"] = str(entity_size_level) + (
                "+" if int(entity_size_level) >= 10 else ""
            )
            self.snapshot_data["ENTITY_SIZE_BREAKDOWN"].append(entity_size_record)

        try:
            with open(self.snapshot_file, "w", encoding="utf-8") as f:
                json.dump(self.snapshot_data, f)
        except IOError as err:
            print_message(f"Could not save review to {self.snapshot_file}", "error")

    # ---------------------------
    def help_multiSourceSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the different match levels within each data source.

        {colorize('Syntax:', 'highlight2')}
            multiSourceSummary                               {colorize('with no parameters displays all the combinations', 'dim')}
            multiSourceSummary <dataSourceCode>              {colorize('displays the stats for a particular data source', 'dim')}
        """
            )
        )

    # ---------------------------
    def complete_multSourceSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        # if before_arg == -1:
        #    return # arg not found

        arg = line[before_arg + 1 : endidx]

        possibles = []
        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_multiSourceSummary(self, arg):
        if not self.snapshot_data or not self.snapshot_data.get("MULTI_SOURCE"):
            print_message(
                "Please create a new snapshot with the latest G2Snapshot.py to access this report",
                "error",
            )
            return
        if len(self.snapshot_data["MULTI_SOURCE"]) == 0:
            print_message("No multi-source entities exist!", "warning")
            return

        filter_str = arg
        while True:
            filter_display = f', filtered for "{filter_str}"' if filter_str else ""
            tbl_title = f"Multi Source Summary from {self.snapshot_file}{filter_display}"
            tbl_columns = []
            tbl_columns.append({"name": "Index", "width": 5, "align": "center"})
            tbl_columns.append({"name": "Data Sources", "width": 100, "align": "left"})
            tbl_columns.append({"name": "Records", "width": 15, "align": "right"})

            report_rows = []
            for data_sources_list in sorted(self.snapshot_data["MULTI_SOURCE"]):
                if filter_str and filter_str.upper() not in data_sources_list:
                    continue
                report_rows.append(
                    [
                        data_sources_list,
                        self.snapshot_data["MULTI_SOURCE"][data_sources_list]["COUNT"],
                        self.snapshot_data["MULTI_SOURCE"][data_sources_list]["SAMPLE"],
                    ]
                )
            if not report_rows:
                print_message(f"No records found for {filter_str}", "error")
                input("press any key to continue ... ")
                filter_str = None
                continue

            report_rows = sorted(report_rows, key=lambda k: k[1], reverse=True)
            tblRows = []
            for row in report_rows:
                tblRows.append(
                    [
                        len(tblRows) + 1,
                        colorize(" | ", "dim").join(colorize_dsrc(x) for x in row[0].split("|")),
                        fmt_statistic(row[1]),
                    ]
                )

            self.render_table(tbl_title, tbl_columns, tblRows)

            sample_records = None
            prompt = colorize_prompt("Select Index # to review, data source filter expression, (Q)uit ... ")
            reply = input(prompt)
            if reply:
                remove_from_history()
                if reply.upper().startswith("Q"):
                    return
                if reply.isdigit() and int(reply) > 0 and int(reply) <= len(tblRows):
                    data_sources_list = tblRows[int(reply) - 1][1]
                    sample_records = report_rows[int(reply) - 1][2]

                else:
                    filter_str = reply.upper()
            else:
                filter_str = None

            if not sample_records:
                continue

            current_sample = 0
            while True:
                self.current_review_list = (
                    f"Sample {current_sample + 1} of {len(sample_records)} for {data_sources_list}"
                )
                current_records = str(sample_records[current_sample]).split()
                return_code = self.do_get(str(sample_records[current_sample]))
                if return_code != 0:
                    print_message("This entity no longer exists", "error")

                while True:
                    reply = input(
                        colorize_prompt(
                            "Select (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                        )
                    )
                    special_actions = "DHWE"
                    if reply:
                        remove_from_history()
                    else:
                        reply = "N"

                    if reply.upper().startswith("Q"):
                        break
                    elif reply.upper() == "S":
                        self.do_scroll("")
                    elif reply.upper()[0] in "PNG":  # previous, next, goto
                        current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                        break
                    elif reply.upper()[0] in special_actions:
                        if reply.upper().startswith("D"):
                            self.do_get("detail " + ",".join(current_records))
                        elif reply.upper().startswith("W"):
                            self.do_why(",".join(current_records))
                        elif reply.upper().startswith("H"):
                            self.do_how(",".join(current_records))
                            break
                        elif reply.upper().startswith("E"):
                            self.export_report_sample(
                                reply,
                                current_records,
                                f"{'-'.join(current_records)}.json",
                            )

                if reply.upper().startswith("Q"):
                    break

            self.current_review_list = None

    # ---------------------------
    def select_matching_category(self, principle_data, prior_header):
        all_rows = []
        for principle in principle_data.keys():
            for match_key in principle_data[principle].keys():
                all_rows.append(
                    [
                        principle,
                        match_key,
                        principle_data[principle][match_key]["COUNT"],
                        principle_data[principle][match_key]["SAMPLE"],
                    ]
                )
        max_rows = 10
        filter_str = None
        while True:
            cnt = 0
            report_rows = []
            for row in sorted(all_rows, key=lambda k: k[2], reverse=True):
                if filter_str and filter_str not in str([row[0].upper(), row[1].upper()]):
                    continue
                if cnt < max_rows or not max_rows:
                    cnt += 1
                    report_rows.append([cnt] + row)
                else:
                    report_rows[-1][1] = "remaining principles"
                    report_rows[-1][2] = "remaining match keys"
                    report_rows[-1][3] += row[2]
                    report_rows[-1][4].extend(row[3])

            filter_display = f', filtered for "{filter_str}"' if filter_str else ""
            tbl_title = f"{prior_header}{filter_display}"
            tbl_columns = []
            tbl_columns.append({"name": "Index", "width": 5, "align": "center"})
            tbl_columns.append({"name": "Match key", "width": 50, "align": "left"})
            tbl_columns.append({"name": "Count", "width": 10, "align": "right"})
            tbl_rows = []
            for row in report_rows:
                if row[1] != "remaining principles":
                    color_match_key = colorize_match_data({"matchKey": row[2], "ruleCode": row[1]})
                else:
                    color_match_key = f"{len(all_rows)-max_rows} more match keys"
                tbl_rows.append([row[0], color_match_key, fmt_statistic(row[3])])

            self.render_table(tbl_title, tbl_columns, tbl_rows)
            if len(report_rows) < len(all_rows):
                prompt = colorize_prompt(
                    "Select Index # to review, show (A)ll matchkeys, matchkey filter expression, (Q)uit... "
                )
            else:
                prompt = colorize_prompt("Select Index # to review, matchkey filter expression, (Q)uit ... ")
            reply = input(prompt)
            if reply:
                remove_from_history()
                if reply.upper() in ("Q", "QUIT"):
                    return None
                if reply.isdigit() and int(reply) > 0 and int(reply) <= len(tbl_rows):
                    return report_rows[int(reply) - 1]
                if reply.upper() == "A":
                    max_rows = 0
                    filter_str = None
                else:
                    filter_str = reply.upper()
            # else:
            #    filter_str = None

    # ---------------------------
    def help_principlesUsed(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the principles used.

        {colorize('Syntax:', 'highlight2')}
            principlesUsed                    {colorize('with no parameters displays the stats by category', 'dim')}
            principlesUsed <category>         {colorize('displays the matchkey stats for a certain category such as match, possible_match, etc', 'dim')}
            principlesUsed principles         {colorize('displays the stats for all principles', 'dim')}
            principlesUsed 100                {colorize('displays the matchkey stats for a certain rule', 'dim')}

        """
            )
        )

    # ---------------------------
    def complete_principlesUsed(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        # if before_arg == -1:
        #    return # arg not found

        arg = line[before_arg + 1 : endidx]

        possibles = list(self.category_sort_order.keys())
        possibles.append("PRINCIPLES")
        if hasattr(self, "statsByPrinciple"):
            # TODO statsByPrinciples not defined
            possibles.extend(list(statsByPrinciple.keys()))

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_principlesUsed(self, arg: str) -> None:

        arg_upper = arg.upper().strip() if arg else arg

        if not self.snapshot_data or not self.snapshot_data.get("PRINCIPLES_USED"):
            print_message(
                "Please create a new snapshot with the latest sz_snapshot to access this report",
                "error",
            )
            return

        category_colors = {
            "MATCH": "MATCH",
            "POSSIBLE_MATCH": "POSSIBLE",
            "AMBIGUOUS_MATCH": "AMBIGUOUS",
            "POSSIBLY_RELATED": "RELATED",
            "DISCLOSED_RELATION": "DISCLOSED, DIM",
        }

        principles_by_id = {}
        principles_by_name = {}
        stats_by_category = {}
        stats_by_principle = {}

        # , key=lambda k: self.categorySortOrder[k]):
        for category in self.snapshot_data["PRINCIPLES_USED"].keys():
            if category not in stats_by_category:
                stats_by_category[category] = {"COUNT": 0}

            for principle in self.snapshot_data["PRINCIPLES_USED"][category].keys():
                stats_by_principle[principle] = {"COUNT": 0, "CATEGORY": category}
                ppart = principle.partition(":")
                # Build lookup dicts to enable using either a principle ID or name
                # principle can contain just 'DISCLOSURE with no ID, usually:
                # '120: SF1_PNAME_CSTAB'
                # If there is no : to split on, DISCLOSE is in ppart[0]
                if not ppart[1] and not ppart[2]:
                    principles_by_name[ppart[0]] = -1
                    principles_by_id[-1] = ppart[0]
                else:
                    principles_by_name[ppart[2].strip()] = ppart[0]
                    principles_by_id[ppart[0]] = ppart[2].strip()

                for matchkey in self.snapshot_data["PRINCIPLES_USED"][category][principle].keys():
                    stats_by_category[category]["COUNT"] += self.snapshot_data["PRINCIPLES_USED"][category][principle][
                        matchkey
                    ]["COUNT"]
                    stats_by_principle[principle]["COUNT"] += self.snapshot_data["PRINCIPLES_USED"][category][
                        principle
                    ][matchkey]["COUNT"]

        report_data = ""
        if not arg:
            tbl_columns = []
            tbl_rows = []
            tbl_title = f"Principles Used Report from {self.snapshot_file}"
            tbl_columns.append({"name": "Category", "width": 25, "align": "left"})
            tbl_columns.append({"name": "Count", "width": 25, "align": "right"})
            for category in sorted(stats_by_category.keys(), key=lambda k: self.category_sort_order[k]):
                tbl_rows.append(
                    [
                        colorize(category, category_colors[category]),
                        fmt_statistic(stats_by_category[category]["COUNT"]),
                    ]
                )
            self.render_table(tbl_title, tbl_columns, tbl_rows)

        elif arg_upper.startswith("PRIN"):
            tbl_columns = []
            tbl_rows = []
            tbl_title = f"Principles Used Report from {self.snapshot_file}"
            tbl_columns.append({"name": "Principle", "width": 50, "align": "left"})
            tbl_columns.append({"name": "Category", "width": 25, "align": "left"})
            tbl_columns.append({"name": "Count", "width": 25, "align": "right"})
            for principle in sorted(stats_by_principle.keys()):
                category = stats_by_principle[principle]["CATEGORY"]
                tbl_rows.append(
                    [
                        colorize(principle, category_colors[category]),
                        colorize(category, category_colors[category]),
                        fmt_statistic(stats_by_principle[principle]["COUNT"]),
                    ]
                )
            self.render_table(tbl_title, tbl_columns, tbl_rows)

        elif arg_upper in stats_by_category:
            category = arg_upper
            header = f"Principles used for {category} across all data sources"
            report_data = self.snapshot_data["PRINCIPLES_USED"][category]

        elif (
            # Stats principle or principle ID or name
            arg_upper in stats_by_principle  # '120: SF1_PNAME_CSTAB'
            or ":" in arg_upper  # '120:SF1_PNAME_CSTAB'
            or arg_upper in principles_by_id  # '120'
            or arg_upper in principles_by_name  # 'SF1_PNAME_CSTAB'
        ):
            if arg_upper in stats_by_principle:
                principle = arg_upper
            elif ":" in arg_upper:
                argpart = arg_upper.partition(":")
                principle = f"{argpart[0]}: {argpart[2].strip()}"
            elif arg_upper.isdigit():
                principle = f"{arg_upper}: {principles_by_id[arg_upper]}"
            else:
                principle = f"{principles_by_name[arg_upper]}: {arg_upper}"

            try:
                category = stats_by_principle[principle]["CATEGORY"]
                header = f"Principles used for {principle} across all data sources"
                report_data = {principle: self.snapshot_data["PRINCIPLES_USED"][category][principle]}
            except KeyError:
                print_message(f"Invalid parameter: {arg}", "error")
                self.help_principlesUsed()
                return

        else:
            print_message(f"Invalid parameter: {arg}", "error")
            self.help_principlesUsed()
            return

        # clean up the disclosure match keys
        if report_data and category == "DISCLOSED_RELATION":
            principle = "DISCLOSURE"
            new_report_data = {principle: {}}
            for matchkey in report_data[principle]:
                count = report_data[principle][matchkey]["COUNT"]
                sample = report_data[principle][matchkey]["SAMPLE"]
                disclosures, plus_keys, minus_keys = self.categorize_match_key(matchkey, from_database=True)
                for disclosure in disclosures:
                    if disclosure not in new_report_data[principle]:
                        new_report_data[principle][disclosure] = {
                            "COUNT": count,
                            "SAMPLE": sample,
                        }
                    else:
                        new_report_data[principle][disclosure]["COUNT"] += count
                        new_report_data[principle][disclosure]["SAMPLE"].extend(sample)
            report_data = new_report_data

        if report_data:
            matchlevel_code = category + "_SAMPLE"
            while True:
                report_row = self.select_matching_category(report_data, header)
                if not report_row:
                    break

                current_sample = 0
                sample_records = report_row[4]
                color_matchkey = colorize_match_data({"matchKey": report_row[2]})
                while True:
                    self.current_review_list = (
                        f"Sample {current_sample + 1} of {len(sample_records)} for {category} on {color_matchkey}"
                    )
                    current_records = str(sample_records[current_sample]).split()
                    if matchlevel_code == "MATCH_SAMPLE":
                        return_code = self.do_get("detail " + current_records[0])
                    else:
                        if matchlevel_code == "AMBIGUOUS_MATCH_SAMPLE":
                            for this_entity_id in current_records:
                                ambiguous_list = self.get_ambiguous_entity_set(
                                    this_entity_id
                                )  # returns all the relationships for the truly ambiguous entity
                                if ambiguous_list:
                                    current_records = ambiguous_list
                                    break
                            return_code = self.do_compare(",".join(current_records))
                        else:
                            if len(current_records) > 2:
                                self.current_review_list += colorize(
                                    f"\n(showing 1 of {len(current_records)} qualifying relationships for entity {current_records[0]})",
                                    "reset,dim,italics",
                                )
                                current_records = current_records[:2]
                            return_code = self.do_compare(",".join(current_records))

                    if return_code != 0:
                        print_message("This entity no longer exists", "error")

                    while True:
                        if matchlevel_code in ("SINGLE_SAMPLE", "DUPLICATE_SAMPLE"):
                            reply = input(
                                colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (D)etail, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "DHWE"
                        else:
                            reply = input(
                                colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "WE"

                        if reply:
                            reply_upper = reply.upper()
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply_upper.startswith("Q"):
                            break
                        elif reply_upper == "S":
                            self.do_scroll("")
                        elif reply_upper[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply_upper[0] in special_actions:
                            if reply_upper.startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply_upper.startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply_upper.startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply_upper.startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )

                    if reply_upper.startswith("Q"):
                        break

            self.current_review_list = None

    # ---------------------------
    def help_dataSourceSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the different match levels within each data source.

        {colorize('Syntax:', 'highlight2')}
            dataSourceSummary                               {colorize('with no parameters displays the overall stats', 'dim')}
            dataSourceSummary <dataSourceCode> <matchLevel> {colorize('where 0=Singletons, 1=Matches, 2=Ambiguous, 3=Possibles, 4=Relationships', 'dim')}
        """
            )
        )

    # ---------------------------
    def complete_dataSourceSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        # if before_arg == -1:
        #    return # arg not found

        arg = line[before_arg + 1 : endidx]

        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)
        elif spaces == 2:
            possibles = [
                "singles",
                "duplicates",
                "matches",
                "ambiguous",
                "possibles",
                "relationships",
            ]
        else:
            possibles = []

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_dataSourceSummary(self, arg):
        if not self.snapshot_data or "DATA_SOURCES" not in self.snapshot_data:
            print_message(
                "Please load a json file created with G2Snapshot.py to use this command",
                "warning",
            )
            return

        # display the summary if 0 arguments (all datasources) or 1 argument signifying a single data source
        if not arg or " " not in arg:

            tbl_title = "Data Source Summary from %s" % self.snapshot_file
            tbl_columns = []
            tbl_columns.append({"name": "\nData Source", "width": 25, "align": "left"})
            tbl_columns.append({"name": "\nRecords", "width": 15, "align": "right"})
            tbl_columns.append({"name": "\nEntities", "width": 15, "align": "right"})
            tbl_columns.append({"name": "\nCompression", "width": 15, "align": "right"})
            # tblColumns.append({'name': 'Records\nUnmatched', 'width': 15, 'align': 'right'})
            tbl_columns.append({"name": "Matched\nRecords", "width": 15, "align": "right"})
            tbl_columns.append({"name": "Matched\nEntities", "width": 15, "align": "right"})
            tbl_columns.append(
                {
                    "name": "Related Entities\nAmbiguous Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Related Entities\nPossible Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Related Entities\nPossible Relationships",
                    "width": 15,
                    "align": "right",
                }
            )

            tbl_rows = []
            for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                if arg and not data_source.startswith(arg.upper()):
                    continue
                report_segment = self.snapshot_data["DATA_SOURCES"][data_source]
                row = []
                row.append(colorize_dsrc(data_source))
                row.append(fmt_statistic(report_segment.get("RECORD_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("ENTITY_COUNT", 0)))
                row.append(report_segment.get("COMPRESSION", 0))
                # row.append(fmtStatistic(report_segment.get('SINGLE_COUNT', 0)))
                row.append(fmt_statistic(report_segment.get("DUPLICATE_RECORD_COUNT", 0)))
                # row.append(fmtStatistic(report_segment.get('RECORD_COUNT', 0)-report_segment.get('ENTITY_COUNT', 0)))
                row.append(fmt_statistic(report_segment.get("DUPLICATE_ENTITY_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("AMBIGUOUS_MATCH_RELATION_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("POSSIBLE_MATCH_RELATION_COUNT", 0)))
                row.append(fmt_statistic(report_segment.get("POSSIBLY_RELATED_RELATION_COUNT", 0)))
                tbl_rows.append(row)

            self.render_table(tbl_title, tbl_columns, tbl_rows, combineHeaders=True)
        else:
            arg_tokens = arg.split()
            if len(arg_tokens) != 2:
                print_message(
                    "Arguments missing: data source and match level are required",
                    "warning",
                )
                return

            data_source = arg_tokens[0].upper()
            if data_source not in self.snapshot_data["DATA_SOURCES"]:
                print_message("Invalid data source", "error")
                return

            match_level = arg_tokens[1].upper()
            match_level_code = None
            for match_level_parm in self.valid_match_level_parameters:
                if match_level.startswith(match_level_parm):
                    match_level_code = self.valid_match_level_parameters[match_level_parm]
                    break
            if not match_level_code:
                print_message("Invalid match level", "error")
                return

            try:
                sample_records = sorted(
                    self.snapshot_data["DATA_SOURCES"][data_source][match_level_code],
                    key=lambda x: int(str(x).split()[0]),
                )
            except:
                sample_records = []
            if len(sample_records) == 0:
                print_message("No records found", "warning")
                return

            match_level_base = match_level_code.replace("_SAMPLE", "")
            if not self.snapshot_data["DATA_SOURCES"][data_source].get(
                match_level_code.replace("_SAMPLE", "_PRINCIPLES")
            ):
                print_message(
                    "Outdated snapshot, please create a new one using the latest G2Snapshot.py",
                    "error",
                )
                return

            while True:
                header = f"Matching statistics for {match_level_base} in {data_source}"
                report_row = self.select_matching_category(
                    self.snapshot_data["DATA_SOURCES"][data_source][match_level_code.replace("_SAMPLE", "_PRINCIPLES")],
                    header,
                )
                if not report_row:
                    break

                current_sample = 0
                sample_records = report_row[4]
                color_match_key = colorize_match_data({"matchKey": report_row[2]})
                while True:
                    self.current_review_list = f"Sample {current_sample + 1} of {len(sample_records)} for {match_level_base} on {color_match_key} in {data_source}"
                    current_records = str(sample_records[current_sample]).split()
                    if match_level_code in ("SINGLE_SAMPLE", "DUPLICATE_SAMPLE"):
                        return_code = self.do_get(
                            "detail " + current_records[0],
                            dataSourceFilter=[data_source],
                        )
                    else:
                        if match_level_code == "AMBIGUOUS_MATCH_SAMPLE":
                            for this_entity_id in current_records:
                                ambiguous_list = self.get_ambiguous_entity_set(
                                    this_entity_id
                                )  # returns all the relationships for the truly ambiguous entity
                                if ambiguous_list:
                                    current_records = ambiguous_list
                                    break
                            return_code = self.do_compare(
                                ",".join(current_records),
                                dataSourceFilter=[data_source],
                            )
                        else:
                            if len(current_records) > 2:
                                self.current_review_list += colorize(
                                    f"\n(showing 1 of {len(current_records)} qualifying relationships for entity {current_records[0]})",
                                    "reset,dim,italics",
                                )
                                current_records = current_records[:2]
                            return_code = self.do_compare(
                                ",".join(current_records),
                                dataSourceFilter=[data_source],
                            )

                    if return_code != 0:
                        print_message("This entity no longer exists", "error")

                    while True:
                        if match_level_code in ("SINGLE_SAMPLE", "DUPLICATE_SAMPLE"):
                            reply = input(
                                colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "DHWE"
                        else:
                            reply = input(
                                colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "WE"
                        if reply:
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply.upper().startswith("Q"):
                            break
                        elif reply.upper() == "S":
                            self.do_scroll("")
                        elif reply.upper()[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply.upper()[0] in special_actions:
                            if reply.upper().startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply.upper().startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply.upper().startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply.upper().startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )

                    if reply.upper().startswith("Q"):
                        break

            self.current_review_list = None

    # ---------------------------
    def help_crossSourceSummary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the statistics for the different match levels across data sources.

        {colorize('Syntax:', 'highlight2')}
            crossSourceSummary                                           {colorize('with no parameters displays the overall stats', 'dim')}
            crossSourceSummary <dataSource1>                             {colorize('displays the cross matches for that data source only', 'dim')}
            crossSourceSummary <dataSource1> <dataSource2> <matchLevel>  {colorize('where 1=Matches, 2=Ambiguous, 3=Possibles, 4=Relationships', 'dim')}
        """
            )
        )

    # ---------------------------
    def complete_crossSourceSummary(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        if before_arg == -1:
            return  # arg not found

        arg = line[before_arg + 1 : endidx]

        spaces = line.count(" ")
        if spaces <= 1:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)
        elif spaces == 2:
            possibles = []
            if self.snapshot_data:
                for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
                    possibles.append(data_source)
        elif spaces == 3:
            possibles = [
                "singles",
                "duplicates",
                "matches",
                "ambiguous",
                "possibles",
                "relationships",
            ]
        else:
            possibles = []

        return [i for i in possibles if i.lower().startswith(arg.lower())]

    # ---------------------------
    def do_crossSourceSummary(self, arg):

        if not self.snapshot_data or "DATA_SOURCES" not in self.snapshot_data:
            print_message(
                "Please load a json file created with G2Snapshot.py to use this command",
                "warning",
            )
            return

        # display the summary if no arguments
        if not arg or len(arg.split()) == 1:
            tbl_title = f"Cross Source Summary from {self.snapshot_file}"
            tbl_columns = []
            tbl_columns.append({"name": "From\nData Source", "width": 25, "align": "center"})
            tbl_columns.append({"name": "To\nData Source", "width": 25, "align": "center"})
            tbl_columns.append({"name": "Matched\nRecords", "width": 15, "align": "right"})
            tbl_columns.append({"name": "Matched\nEntities", "width": 15, "align": "right"})
            tbl_columns.append(
                {
                    "name": "Entities with\nAmbiguous Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Entities with\nPossible Matches",
                    "width": 15,
                    "align": "right",
                }
            )
            tbl_columns.append(
                {
                    "name": "Entities with\nPossible Relationships",
                    "width": 15,
                    "align": "right",
                }
            )

            tbl_rows = []
            for data_source_1 in sorted(self.snapshot_data["DATA_SOURCES"]):
                if arg and data_source_1 != arg.upper():
                    continue
                for data_source_2 in sorted(self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"]):
                    report_segment = self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2]
                    row = []
                    row.append(colorize_dsrc(data_source_1))
                    row.append(colorize_dsrc(data_source_2))
                    row.append(fmt_statistic(report_segment.get("MATCH_RECORD_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("MATCH_ENTITY_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("AMBIGUOUS_MATCH_ENTITY_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("POSSIBLE_MATCH_ENTITY_COUNT", 0)))
                    row.append(fmt_statistic(report_segment.get("POSSIBLY_RELATED_ENTITY_COUNT", 0)))
                    tbl_rows.append(row)

            self.render_table(tbl_title, tbl_columns, tbl_rows, combineHeaders=True)
        else:
            arg_tokens = arg.split()
            if len(arg_tokens) != 3:
                print_message(
                    "Arguments missing: two data sources and match level are required",
                    "warning",
                )
                return

            data_source_1 = arg_tokens[0].upper()
            if data_source_1 not in self.snapshot_data["DATA_SOURCES"]:
                print_message(f"Invalid data source: {data_source_1}", "error")
                return

            data_source_2 = arg_tokens[1].upper()
            if data_source_2 not in self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"]:
                print_message(f"Invalid data source: {data_source_2}", "error")
                return

            match_level = arg_tokens[2].upper()
            match_level_code = None
            for match_level_arm in self.valid_match_level_parameters:
                if match_level.startswith(match_level_arm):
                    match_level_code = self.valid_match_level_parameters[match_level_arm]
                    break

            if not match_level_code:
                print_message("Invalid match level", "error")
                return

            # duplicates are matches for cross source
            if match_level_code == "DUPLICATE_SAMPLE":
                match_level_code = "MATCH_SAMPLE"
            try:
                sample_records = sorted(
                    self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2][match_level_code],
                    key=lambda x: int(str(x).split()[0]),
                )
            except:
                sample_records = []

            if len(sample_records) == 0:
                print_message("No records found", "warning")
                return

            match_level_base = match_level_code.replace("_SAMPLE", "")
            if not self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2].get(
                match_level_code.replace("_SAMPLE", "_PRINCIPLES")
            ):
                print_message(
                    "Outdated snapshot, please create a new one using the latest G2Snapshot.py",
                    "error",
                )
                return

            while True:
                header = f"Matching statistics for {match_level_base} between {data_source_1} and {data_source_2}"
                report_row = self.select_matching_category(
                    self.snapshot_data["DATA_SOURCES"][data_source_1]["CROSS_MATCHES"][data_source_2][
                        match_level_code.replace("_SAMPLE", "_PRINCIPLES")
                    ],
                    header,
                )
                if not report_row:
                    break

                current_sample = 0
                sample_records = report_row[4]
                color_match_key = colorize_match_data({"matchKey": report_row[2]})
                while True:
                    self.current_review_list = f"Sample {current_sample + 1} of {len(sample_records)} for {match_level_base} on {color_match_key} between {data_source_1} and {data_source_2}"
                    current_records = str(sample_records[current_sample]).split()
                    if match_level_code in ("MATCH_SAMPLE"):
                        return_code = self.do_get(
                            "detail " + current_records[0],
                            dataSourceFilter=[data_source_1, data_source_2],
                        )
                    else:
                        if match_level_code == "AMBIGUOUS_MATCH_SAMPLE":
                            for this_entity_id in current_records:
                                ambiguous_list = self.get_ambiguous_entity_set(
                                    this_entity_id
                                )  # returns all the relationships for the truly ambiguous entity
                                if ambiguous_list:
                                    current_records = ambiguous_list
                                    break
                            return_code = self.do_compare(
                                ",".join(current_records),
                                dataSourceFilter=[data_source_1, data_source_2],
                            )
                        else:
                            if len(current_records) > 2:
                                self.current_review_list += colorize(
                                    f"\n(showing 2 of {len(current_records)} qualifying relationships for entity {current_records[0]})",
                                    "reset,dim,italics",
                                )
                            return_code = self.do_compare(
                                ",".join(current_records[:3]),
                                dataSourceFilter=[data_source_1, data_source_2],
                            )

                    if return_code != 0:
                        print_message("This entity no longer exists", "error")

                    while True:
                        if match_level_code in ("MATCH_SAMPLE"):
                            reply = input(
                                colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (H)ow, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "DHWE"
                        else:
                            reply = input(
                                colorize_prompt(
                                    "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit ..."
                                )
                            )
                            special_actions = "WE"
                        if reply:
                            remove_from_history()
                        else:
                            reply = "N"

                        if reply.upper().startswith("Q"):
                            break
                        elif reply.upper() == ("S"):
                            self.do_scroll("")
                        elif reply.upper()[0] in "PNG":  # previous, next, goto
                            current_sample = self.move_pointer(reply, current_sample, len(sample_records))
                            break
                        elif reply.upper()[0] in special_actions:
                            if reply.upper().startswith("D"):
                                self.do_get("detail " + ",".join(current_records))
                            elif reply.upper().startswith("W"):
                                self.do_why(",".join(current_records))
                            elif reply.upper().startswith("H"):
                                self.do_how(",".join(current_records))
                                break
                            elif reply.upper().startswith("E"):
                                self.export_report_sample(
                                    reply,
                                    current_records,
                                    f"{'-'.join(current_records)}.json",
                                )
                    if reply.upper().startswith("Q"):
                        break
            self.current_review_list = None

    # ---------------------------
    def help_search(self):
        print(
            textwrap.dedent(
                f"""\

        Search for an entity by its attributes.

        {colorize('Syntax:', 'highlight2')}
            search Joe Smith {colorize('without a json structure performs a search on name alone', 'dim')}
            search {'{'}"name_full": "Joe Smith"{'}'}
            search {'{'}"name_org": "ABC Company"{'}'}
            search {'{'}"name_last": "Smith", "name_first": "Joe", "date_of_birth": "1992-12-10"{'}'}
            search {'{'}"name_org": "ABC Company", "addr_full": "111 First St, Anytown, USA 11111"{'}'}

        {colorize('Notes:', 'highlight2')}
            Searching by name alone may not locate a specific entity.
            Try adding a date of birth, address, or phone number if not found by name alone.
        """
            )
        )

    # ---------------------------
    def do_search(self, arg):
        if not arg:
            self.help_search()
            return

        try:
            parm_data = (
                dict_keys_upper(json.loads(arg))
                if arg.startswith("{")
                else {"PERSON_NAME_FULL": arg, "ORGANIZATION_NAME_ORG": arg}
            )
        except (ValueError, KeyError) as err:
            print_message(f"Invalid json parameter: {err}", "error")
            return

        print("\nSearching ...")
        search_json = parm_data
        search_flag_list = [
            "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
            "SZ_INCLUDE_FEATURE_SCORES",
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_SEARCH_INCLUDE_STATS",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_response = self.execute_sz_api("search_by_attributes", search_flag_list, json.dumps(search_json))
        except SzError as err:
            print_message(err, "error")
            return

        # constants for descriptions and sort orders
        dataSourceOrder = []  # place your data sources here!

        tbl_title = "Search Results"
        tbl_columns = []
        tbl_columns.append({"name": "Index", "width": 5, "align": "center"})
        tbl_columns.append({"name": "Entity ID", "width": 15, "align": "center"})
        tbl_columns.append({"name": "Entity Name", "width": 75, "align": "left"})
        tbl_columns.append({"name": "Data Sources", "width": 50, "align": "left"})
        tbl_columns.append({"name": "Match Key", "width": 50, "align": "left"})
        tbl_columns.append({"name": "Match Score", "width": 15, "align": "center"})
        tbl_columns.append({"name": "Relationships", "width": 15, "align": "left"})

        match_list = []
        search_index = 0
        for resolved_entity_base in json_response["RESOLVED_ENTITIES"]:
            resolved_entity = resolved_entity_base["ENTITY"]["RESOLVED_ENTITY"]
            resolved_entity_match_info = resolved_entity_base["MATCH_INFO"]
            search_index += 1

            # create a list of data sources we found them in
            data_sources = {}
            for record in resolved_entity["RECORDS"]:
                data_source = record["DATA_SOURCE"]
                if data_source not in data_sources:
                    data_sources[data_source] = [record["RECORD_ID"]]
                else:
                    data_sources[data_source].append(record["RECORD_ID"])

            data_source_list = []
            for data_source in data_sources:
                if len(data_sources[data_source]) == 1:
                    data_source_list.append(colorize_dsrc(data_source + ": " + data_sources[data_source][0]))
                else:
                    data_source_list.append(
                        colorize_dsrc(data_source + ": " + str(len(data_sources[data_source])) + " records")
                    )

            disclosed_count = 0
            derived_count = 0
            for relationship in (
                resolved_entity_base["ENTITY"]["RELATED_ENTITIES"]
                if "RELATED_ENTITIES" in resolved_entity_base["ENTITY"]
                else []
            ):
                if relationship["IS_DISCLOSED"] > 0:
                    disclosed_count += 1
                else:
                    derived_count += 1
            relationship_lines = []
            if derived_count > 0:
                relationship_lines.append(f"{derived_count} {colorize('(derived)', 'dim')}")
            if disclosed_count > 0:
                relationship_lines.append(f"{disclosed_count} {colorize('(disclosed)', 'dim')}")

            # determine the matching criteria
            match_key = resolved_entity_match_info["MATCH_KEY"]
            rule_code = resolved_entity_match_info["ERRULE_CODE"]
            # scoring
            best_scores = {}
            best_scores["NAME"] = {}
            best_scores["NAME"]["score"] = 0
            best_scores["NAME"]["value"] = ""
            for feature_code in resolved_entity_match_info["FEATURE_SCORES"]:
                for score_record in resolved_entity_match_info["FEATURE_SCORES"][feature_code]:
                    if feature_code == "NAME":
                        score_code = "BT_FN" if "BT_FN" in score_record["ADDITIONAL_SCORES"] else "GNR_FN"
                    else:
                        score_code = "FULL_SCORE"
                    matching_score = score_record["ADDITIONAL_SCORES"][score_code]
                    matching_value = score_record["CANDIDATE_FEAT_DESC"]
                    if feature_code not in best_scores:
                        best_scores[feature_code] = {}
                        best_scores[feature_code]["score"] = 0
                        best_scores[feature_code]["value"] = "n/a"
                    if matching_score > best_scores[feature_code]["score"]:
                        best_scores[feature_code]["score"] = matching_score
                        best_scores[feature_code]["value"] = matching_value

            # perform scoring (use stored match_score if not overridden in the mapping document)
            matched_score = best_scores["NAME"]["score"]
            matched_name = best_scores["NAME"]["value"]

            weighted_scores = {}
            for feature_code in best_scores:
                weighted_scores[feature_code] = {}
                weighted_scores[feature_code]["threshold"] = 0
                weighted_scores[feature_code]["+weight"] = 100
                weighted_scores[feature_code]["-weight"] = 0
                # if scoredFeatureCount > 1:

            match_score = 0
            for feature_code in best_scores:
                if feature_code in weighted_scores:
                    if best_scores[feature_code]["score"] >= weighted_scores[feature_code]["threshold"]:
                        match_score += int(
                            round(
                                best_scores[feature_code]["score"] * (weighted_scores[feature_code]["+weight"] / 100),
                                0,
                            )
                        )
                    elif "-weight" in weighted_scores[feature_code]:
                        match_score += -weighted_scores[feature_code][
                            "-weight"
                        ]  # actual score does not matter if below the threshold

            # create the possible match entity one-line summary
            row = []
            row.append(str(search_index))  # note this gets re-ordered below
            row.append(str(resolved_entity["ENTITY_ID"]))
            row.append(
                resolved_entity["ENTITY_NAME"]
                + (
                    ("\n" + " aka: " + matched_name)
                    if matched_name and matched_name != resolved_entity["ENTITY_NAME"]
                    else ""
                )
            )
            row.append("\n".join(data_source_list))
            match_data = {}
            match_data["matchKey"] = match_key
            match_data["ruleCode"] = self.getRule_desc(rule_code)
            row.append(colorize_match_data(match_data))
            row.append(match_score)
            row.append("\n".join(relationship_lines))
            match_list.append(row)

        if len(match_list) == 0:
            if "SEARCH_STATISTICS" in json_response:
                if json_response["SEARCH_STATISTICS"][0]["CANDIDATE_KEYS"]["SUMMARY"]["FOUND"] > 0:
                    msg = "\tOne or more entities were found but did not score high enough to be returned"
                    msg += "\n\tPlease include additional or more complete attributes in your search"
                elif json_response["SEARCH_STATISTICS"][0]["CANDIDATE_KEYS"]["SUMMARY"]["GENERIC"] > 0:
                    msg = "\tToo many entities would be returned"
                    msg += "\n\tPlease include additional attributes to narrow the search results"
                elif json_response["SEARCH_STATISTICS"][0]["CANDIDATE_KEYS"]["SUMMARY"]["NOT_FOUND"] > 0:
                    msg = "\tNo entities at all were found"
                    msg += "\n\tPlease search by other attributes for this entity if you feel it should exist"
                else:
                    msg = "\tNo search keys were even generated"
                    msg += "\n\tPlease search by other attributes"

            else:  # older versions do not have statistics
                msg = "\tNo matches found or there were simply too many to return"
                msg += "\n\tPlease include additional search parameters if you feel this entity is in the database"
            print_message(msg, "warning")

        else:
            # sort the list by match score descending
            match_list = sorted(match_list, key=lambda x: x[5], reverse=True)

            # store the last search result and colorize
            self.last_search_result = []
            for i in range(len(match_list)):
                self.last_search_result.append(match_list[i][1])
                match_list[i][0] = colorize(i + 1, "row_title")
                match_list[i][1] = colorize_entity(match_list[i][1])
                match_list[i][2] = match_list[i][2]
            self.render_table(tbl_title, tbl_columns, match_list)

        print("")

    # ---------------------------
    def help_get(self):
        print(
            textwrap.dedent(
                f"""\

        Displays a particular entity by entity_id or by data_source and record_id.

        {colorize('Syntax:', 'highlight2')}
            get <entity_id>               {colorize("looks up an entity's resume by entity ID", 'dim')}
            get <dataSource> <recordID>   {colorize("looks up an entity's resume by data source and record ID", 'dim')}
            get search <search index>     {colorize("looks up an entity's resume by search index (requires a prior search)", 'dim')}
            get detail <entity_id>        {colorize('adding the "detail" tag displays each record rather than a summary by data source', 'dim')}
            get features <entity_id>      {colorize('adding the "features" tag displays the entity features rather than the resume', 'dim')}

        {colorize('Notes:', 'highlight2')}
            {colorize('Add the keyword ', 'dim')}ALL{colorize(' to display all the attributes of the entity if there are more than 50.', 'dim')}
        """
            )
        )

    # ---------------------------
    def do_get(self, arg, **kwargs):
        """# TODO"""
        called_direct = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_get()
            return -1 if called_direct else 0

        # get possible data source list
        data_source_filter = None
        if "dataSourceFilter" in kwargs and self.current_settings["data_source_suppression"] == "on":
            data_source_filter = kwargs["dataSourceFilter"]

        show_detail = False
        show_features = False
        show_all = False
        arg_tokens = []

        for token in arg.split():
            if token.upper() == "DETAIL":
                show_detail = True
            elif token.upper().startswith("FEATURE"):
                show_features = True
            elif token.upper() == "ALL":
                show_all = True
            else:
                arg_tokens.append(token)

        if len(arg_tokens) == 2 and arg_tokens[0].upper() == "SEARCH":
            last_token = arg_tokens[1]
            if not last_token.isdigit() or last_token == "0" or int(last_token) > len(self.last_search_result):
                print_message("Invalid search index from the prior search", "error")
                return -1 if called_direct else 0
            else:
                arg_tokens = [str(self.last_search_result[int(last_token) - 1])]

        if len(arg_tokens) not in (1, 2):
            print_message("Incorrect number of parameters", "warning")
            return -1 if called_direct else 0

        if len(arg_tokens) == 1 and not arg_tokens[0].isnumeric():
            print_message("Entity ID must be numeric", "error")
            return -1 if called_direct else 0

        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
        ]

        try:
            if len(arg_tokens) == 1:
                resolved_json = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(arg_tokens[0]))
            else:
                resolved_json = self.execute_sz_api("get_entity_by_record_id", get_flag_list, arg_tokens)
        except SzError as err:
            print_message(err, "error")
            return -1 if called_direct else 0

        related_entity_count = len(resolved_json["RELATED_ENTITIES"]) if "RELATED_ENTITIES" in resolved_json else 0
        entity_id = str(resolved_json["RESOLVED_ENTITY"]["ENTITY_ID"])
        entity_name = resolved_json["RESOLVED_ENTITY"]["ENTITY_NAME"]
        entity_features = resolved_json["RESOLVED_ENTITY"]["FEATURES"]

        # Build a dict with lib_feat_id as key for all the entity features
        features_by_id = {}
        for feat_cat in entity_features:
            for cat_row in entity_features[feat_cat]:
                features_by_id[cat_row["LIB_FEAT_ID"]] = {
                    "feat_cat": feat_cat,
                    "feat_desc": cat_row["FEAT_DESC"],
                }

                if "USAGE_TYPE" in cat_row:
                    features_by_id[cat_row["LIB_FEAT_ID"]]["usage_type"] = cat_row["USAGE_TYPE"]

        self.last_entity_id = int(entity_id)

        if show_features:
            tbl_columns = []
            tbl_columns.append({"name": "Feature", "width": 30, "align": "left"})
            tbl_columns.append({"name": "Description", "width": 50, "align": "left"})
            tbl_columns.append({"name": "Elements", "width": 100, "align": "left"})
            report_type = "features"
            tbl_title = f"Entity {report_type} for entity {colorize_entity(entity_id)}: {entity_name}"
            tbl_rows = self.get_features(entity_id)
            if tbl_rows:
                self.render_table(tbl_title, tbl_columns, tbl_rows)
            return 0
        else:
            tbl_columns = []
            tbl_columns.append({"name": "Record ID", "width": 50, "align": "left"})
            tbl_columns.append({"name": "Entity Data", "width": 100, "align": "left"})
            tbl_columns.append({"name": "Additional Data", "width": 100, "align": "left"})
            report_type = "detail" if show_detail else "summary"
            tbl_title = f"Entity {report_type} for entity {colorize_entity(entity_id)}: {entity_name}"
            if self.webapp_url:
                tbl_title += f"  {colorize('WebApp:', 'dim')} " + colorize(
                    f"{self.webapp_url}/graph/{entity_id}", "highlight1,underline"
                )

            # summarize by data source
            if report_type == "summary":
                data_sources = {}
                record_list = []
                for record in resolved_json["RESOLVED_ENTITY"]["RECORDS"]:
                    if record["DATA_SOURCE"] not in data_sources:
                        data_sources[record["DATA_SOURCE"]] = []
                    if data_source_filter and record["DATA_SOURCE"] not in data_source_filter:
                        continue
                    data_sources[record["DATA_SOURCE"]].append(record)

                # summarize by data source
                for data_source in sorted(data_sources):
                    if data_sources[data_source]:
                        record_data, entity_data, other_data = self.format_records(
                            data_sources[data_source],
                            report_type,
                            show_all,
                            features_by_id,
                        )
                        row = [record_data, entity_data, other_data]
                    else:
                        row = [data_source, " ** suppressed ** ", ""]
                    record_list.append(row)

            # display each record
            else:
                record_list = []
                for record in sorted(
                    resolved_json["RESOLVED_ENTITY"]["RECORDS"],
                    key=lambda k: (k["DATA_SOURCE"], k["RECORD_ID"]),
                ):
                    if data_source_filter and record["DATA_SOURCE"] not in data_source_filter:
                        continue
                    record_data, entity_data, other_data = self.format_records(
                        record,
                        report_type,
                        show_all,
                        features_by_id,
                    )
                    row = [record_data, entity_data, other_data]
                    record_list.append(row)

            # display if no relationships
            if related_entity_count == 0 or self.current_settings["show_relations_on_get"] == "none":
                # if relatedEntityCount != 0:  #--must add this to table footer somehow
                #    print(f"{relatedEntityCount} related entities")
                self.render_table(tbl_title, tbl_columns, record_list, displayFlag="begin")
                self.current_render_string += f"\u2514\u2500\u2500 {'No' if related_entity_count == 0 else related_entity_count} related entities\n"
                self.show_report("auto")
                return 0

            # otherwise begin the report and add the relationships
            self.render_table(tbl_title, tbl_columns, record_list, displayFlag="begin")
            if related_entity_count == 0:
                self.current_render_string += "\u2514\u2500\u2500 No related entities\n"
                self.show_report("auto")
                return 0

            if self.current_settings["show_relations_on_get"] == "grid":
                relationships = []
                for related_entity in resolved_json["RELATED_ENTITIES"]:
                    relationship = {}
                    relationship["MATCH_LEVEL"] = related_entity["MATCH_LEVEL"]
                    relationship["MATCH_KEY"] = related_entity["MATCH_KEY"]
                    relationship["ERRULE_CODE"] = related_entity["ERRULE_CODE"]
                    relationship["ENTITY_ID"] = related_entity["ENTITY_ID"]
                    relationship["ENTITY_NAME"] = related_entity["ENTITY_NAME"]
                    relationship["DATA_SOURCES"] = []
                    for data_source in related_entity["RECORD_SUMMARY"]:
                        relationship["DATA_SOURCES"].append(
                            f"{colorize_dsrc(data_source['DATA_SOURCE'])} ({data_source['RECORD_COUNT']})"
                        )
                    relationships.append(relationship)

                tbl_title = f"{related_entity_count} related entities"
                tbl_columns = []
                tbl_columns.append({"name": "Entity ID", "width": 15, "align": "left"})
                tbl_columns.append({"name": "Entity Name", "width": 75, "align": "left"})
                tbl_columns.append({"name": "Data Sources", "width": 75, "align": "left"})
                tbl_columns.append({"name": "Match Level", "width": 25, "align": "left"})
                tbl_columns.append({"name": "Match Key", "width": 50, "align": "left"})
                related_record_list = []
                for relationship in sorted(relationships, key=lambda k: k["MATCH_LEVEL"]):
                    row = []
                    row.append(colorize_entity(str(relationship["ENTITY_ID"])))
                    row.append(relationship["ENTITY_NAME"])
                    row.append("\n".join(sorted(relationship["DATA_SOURCES"])))
                    row.append(self.related_match_levels[relationship["MATCH_LEVEL"]])
                    match_data = {}
                    match_data["matchKey"] = relationship["MATCH_KEY"]
                    match_data["ruleCode"] = self.getRule_desc(relationship["ERRULE_CODE"])
                    row.append(colorize_match_data(match_data))
                    related_record_list.append(row)

                self.render_table(
                    tbl_title,
                    tbl_columns,
                    related_record_list,
                    titleJustify="l",
                    displayFlag="end",
                )
            else:
                self.do_tree(entity_id)

        return 0

    # ---------------------------
    def find(self, step, arg):
        starting_id = 0
        data_source = None
        arg_list = arg.split()
        get_flag_list = []
        for parm in arg_list:
            if parm.isdigit():
                starting_id = parm
            else:
                data_source = parm.upper()
                get_flag_list = ["SZ_ENTITY_INCLUDE_RECORD_SUMMARY"]
        if starting_id:
            entity_id = int(starting_id)
        else:
            entity_id = self.last_entity_id + step
        trys = 0
        while True:
            try:
                resolved_json = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, entity_id)
                if data_source:
                    found = False
                    for record in resolved_json["RESOLVED_ENTITY"]["RECORD_SUMMARY"]:
                        if record["DATA_SOURCE"].startswith(data_source):
                            found = True
                            break
                    if found:
                        self.do_get(str(entity_id))
                        break
                    else:
                        raise (Exception("does not contain data source"))
                else:
                    self.do_get(str(entity_id))
                    break
            except:
                entity_id += step
                trys += 1
                if trys == 1000:
                    print("\nsearching ...")
                if entity_id <= 0 or trys >= 100000:
                    if step == -1:
                        print_message("no prior entities", "warning")
                    else:
                        print_message("search for next abandoned after 100k tries", "error")
                    break

    # ---------------------------
    def do_next(self, arg):
        self.find(1, arg)

    def do_n(self, arg):
        remove_from_history()
        self.do_next(arg)

    # ---------------------------
    def do_previous(self, arg):
        self.find(-1, arg)

    def do_p(self, arg):
        remove_from_history()
        self.do_previous(arg)

    # ---------------------------
    def format_records(self, record_list, report_type, show_all, features_by_id):

        data_source = "unknown"
        record_id_list = []
        primary_name_list = []
        other_name_list = []
        attribute_list = []
        identifier_list = []
        address_list = []
        phone_list = []
        other_list = []

        # should only ever be one data source in the list
        for record in [record_list] if type(record_list) != list else record_list:
            data_source = colorize_dsrc(record["DATA_SOURCE"])
            record_id_data = record["RECORD_ID"]
            if report_type == "detail":
                if record["MATCH_KEY"]:
                    match_data = {}
                    match_data["matchKey"] = record["MATCH_KEY"]
                    match_data["ruleCode"] = self.getRule_desc(record["ERRULE_CODE"])
                    record_id_data += "\n" + colorize_match_data(match_data)
            record_id_list.append(record_id_data)

            # Loop through the features on each record
            for feat in record["FEATURES"]:
                lf_id = feat["LIB_FEAT_ID"]
                feature_data = features_by_id[lf_id]

                if feature_data["feat_cat"] == "NAME":
                    name_type = feature_data.get("usage_type")
                    if name_type and name_type == "PRIMARY":
                        primary_name_list.append(colorize_attr(f"PRIMARY: {feature_data['feat_desc']}"))
                    else:
                        other_name_list.append(colorize_attr(f"NAME: {feature_data['feat_desc']}"))

                elif feature_data["feat_cat"] == "ADDRESS":
                    addr_type = feature_data.get("usage_type")
                    address_list.append(
                        colorize_attr(f"{addr_type if addr_type else 'ADDRESS'}: {feature_data['feat_desc']}")
                    )

                elif feature_data["feat_cat"] == "PHONE":
                    phone_type = feature_data.get("usage_type")
                    phone_list.append(
                        colorize_attr(f"{phone_type if phone_type else 'PHONE'}: {feature_data['feat_desc']}")
                    )
                else:
                    attribute_list.append(colorize_attr(f"{feature_data['feat_cat']}: {feature_data['feat_desc']}"))

                # Loop through the features on each record
                unmapped_data = dict(sorted(record["UNMAPPED_DATA"].items()))
                for k, v in unmapped_data.items():
                    # TODO Still need to implement this? Does the V4 API give back internals?
                    #  if not self.isInternalAttribute(item) or reportType == "detail":
                    other_list.append(colorize_attr(f"{k}: {v}"))

        record_data_list = [data_source] + sorted(record_id_list)
        entity_data_list = (
            list(set(primary_name_list))
            + list(set(other_name_list))
            + sorted(set(attribute_list))
            + sorted(set(identifier_list))
            + list(set(address_list))
            + list(set(phone_list))
        )
        other_data_list = sorted(set(other_list))

        if show_all:
            column_height_limit = 999999
        else:
            column_height_limit = 50

        record_data = "\n".join(record_data_list[:column_height_limit])
        if len(record_data_list) > column_height_limit:
            record_data += "\n+%s more " % str(len(record_data_list) - column_height_limit)

        entity_data = "\n".join(entity_data_list[:column_height_limit])
        if len(entity_data_list) > column_height_limit:
            entity_data += "\n+%s more " % str(len(entity_data_list) - column_height_limit)

        other_data = "\n".join(other_data_list[:column_height_limit])
        if len(other_data_list) > column_height_limit:
            other_data += "\n+%s more " % str(len(other_data_list) - column_height_limit)

        return record_data, entity_data, other_data

    # ---------------------------
    def get_features(self, entity_id):
        """# TODO"""
        get_flag_list = ["SZ_ENTITY_INCLUDE_ALL_FEATURES"]
        try:
            json_data = self.execute_sz_api(
                "get_entity_by_entity_id",
                get_flag_list,
                int(entity_id),
            )
        except SzError as err:
            print_message(err, "error")
            return

        # get the features in order
        ordered_feature_list = []
        # sorted(featureArray, key=lambda k: self.featureSequence[k]):
        for ftype_id in self.feature_sequence:
            ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
            for distinct_feature_data in json_data["RESOLVED_ENTITY"]["FEATURES"].get(ftype_code, []):
                for feature_data in distinct_feature_data["FEAT_DESC_VALUES"]:
                    usage_type = feature_data.get("USAGE_TYPE")
                    ordered_feature_list.append(
                        {
                            "ftypeCode": ftype_code,
                            "usageType": distinct_feature_data.get("USAGE_TYPE"),
                            "featureDesc": feature_data.get("FEAT_DESC"),
                            "libFeatId": feature_data["LIB_FEAT_ID"],
                        }
                    )
        tbl_rows = []
        for lib_feat_data in ordered_feature_list:
            ftype_code = lib_feat_data["ftypeCode"]
            usage_type = lib_feat_data["usageType"]
            lib_feat_id = lib_feat_data["libFeatId"]
            feature_desc = lib_feat_data["featureDesc"]

            try:
                response = self.sz_diagnostic.get_feature(lib_feat_id)
            # TODO Should return?
            except SzError as err:
                print(err)
            json_data = json.loads(response)

            ftype_display = colorize_attr(ftype_code)
            if usage_type:
                ftype_display += f" ({usage_type})"
            ftype_display += "\n  " + colorize(f"id: {lib_feat_id}", "dim")

            # standardize the order of the attributes
            for i in range(len(json_data["ELEMENTS"])):
                attr_record = self.ftype_attr_lookup[ftype_code].get(json_data["ELEMENTS"][i]["FELEM_CODE"])
                attr_id = attr_record["ATTR_ID"] if attr_record else 9999999
                json_data["ELEMENTS"][i]["ATTR_ID"] = attr_id

            felem_display_list = []
            for element_data in sorted(
                sorted(json_data["ELEMENTS"], key=lambda k: (k["FELEM_CODE"])),
                key=lambda k: (k["ATTR_ID"]),
            ):
                felem_value_display = element_data["FELEM_VALUE"]
                if element_data["FELEM_CODE"] == "LIBPOSTAL_PARSE":
                    with suppress(Exception):
                        felem_value_dict = json.loads(element_data["FELEM_VALUE"])
                        felem_value_list = []
                        for key in sorted(felem_value_dict.keys()):
                            felem_value_list.append(
                                "  " + colorize(key, "highlight2,dim") + ": " + json.dumps(felem_value_dict[key])
                            )
                        felem_value_display = "\n" + "\n".join(felem_value_list)
                felem_display_list.append(
                    colorize(element_data["FELEM_CODE"], "highlight2") + ": " + felem_value_display
                )

            tbl_rows.append([ftype_display, feature_desc, "\n".join(felem_display_list)])
        return tbl_rows

    # ---------------------------
    def get_ambiguous_entity_set(self, entity_id):
        # get other ambiguous relationships if this is the ambiguous entity
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_OPTION_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data_2 = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return

        ambiguous_entity = "AMBIGUOUS_ENTITY" in json_data_2["RESOLVED_ENTITY"]["FEATURES"]
        if ambiguous_entity and "RELATED_ENTITIES" in json_data_2:
            entity_set = []
            for related_entity in json_data_2["RELATED_ENTITIES"]:
                if related_entity["IS_AMBIGUOUS"] != 0:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            if len(entity_set) > 1:
                return [entity_id] + entity_set
        return

    # ---------------------------
    def get_related_entity_set(self, entity_id, sample_category=""):
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data_2 = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return
        entity_set = []
        for related_entity in json_data_2["RELATED_ENTITIES"]:
            if sample_category == "POSSIBLE_MATCH_SAMPLE":
                if related_entity["MATCH_LEVEL"] <= 2 and related_entity["IS_AMBIGUOUS"] == 0:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            elif sample_category == "POSSIBLY_RELATED_SAMPLE":
                if related_entity["MATCH_LEVEL"] == 3:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            else:
                entity_set.append(str(related_entity["ENTITY_ID"]))
        return [entity_id] + sorted(entity_set, key=lambda x: int(x))

    # ---------------------------
    def help_compare(self):
        print(
            textwrap.dedent(
                f"""\

        Compares a set of entities by placing them side by side in a columnar format.

        {colorize('Syntax:', 'highlight2')}
            compare <entity_id1> <entity_id2>   {colorize('compares the listed entities', 'dim')}
            compare search                      {colorize('places all the search results side by side', 'dim')}
            compare search <top (n)>            {colorize('places the top (n) search results side by side', 'dim')}
       """
            )
        )

    # ---------------------------
    def do_compare(self, arg, **kwargs):
        """# TODO"""
        called_direct = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_compare()
            return -1 if called_direct else 0

        # get possible data source list
        data_source_filter = None
        if "dataSourceFilter" in kwargs and self.current_settings["data_source_suppression"] == "on":
            data_source_filter = kwargs["dataSourceFilter"]

        if isinstance(arg, str) and "SEARCH" in arg.upper():
            entity_list = self.last_search_result
            last_token = arg.split()[len(arg.split()) - 1]
            if last_token.isdigit():
                entity_list = self.last_search_result[: int(last_token)]
        elif "," in arg:
            entity_list = arg.split(",")
        else:
            entity_list = arg.split()

        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
        ]

        compare_list = []
        for entity_id in entity_list:
            try:
                json_data = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except (SzError, ValueError) as err:
                print_message(err, "error")
                return -1 if called_direct else 0

            entity_data = {
                "entityID": json_data["RESOLVED_ENTITY"]["ENTITY_ID"],
                "dataSources": {},
                "nameData": [],
                "attributeData": [],
                "identifierData": [],
                "addressData": [],
                "phoneData": [],
                "relationshipData": [],
                "otherData": [],
                "crossRelations": [],
                "otherRelations": [],
            }

            entity_features = json_data["RESOLVED_ENTITY"]["FEATURES"]
            # Build a dict with lib_feat_id as key for all the entity features
            features_by_id = {}
            for feat_code, feat_code_rows in entity_features.items():
                for row in feat_code_rows:
                    features_by_id[row["LIB_FEAT_ID"]] = {
                        "feat_code": feat_code,
                        "feat_desc": row["FEAT_DESC"],
                    }

                    if "USAGE_TYPE" in row:
                        features_by_id[row["LIB_FEAT_ID"]]["usage_type"] = row["USAGE_TYPE"]

            for record in json_data["RESOLVED_ENTITY"]["RECORDS"]:
                if record["DATA_SOURCE"] not in entity_data["dataSources"]:
                    if data_source_filter and record["DATA_SOURCE"] not in data_source_filter:
                        entity_data["dataSources"][record["DATA_SOURCE"]] = ["** suppressed **"]
                    else:
                        entity_data["dataSources"][record["DATA_SOURCE"]] = [record["RECORD_ID"]]
                else:
                    if not data_source_filter or record["DATA_SOURCE"] in data_source_filter:
                        entity_data["dataSources"][record["DATA_SOURCE"]].append(record["RECORD_ID"])

                if data_source_filter and record["DATA_SOURCE"] not in data_source_filter:
                    continue

                # Loop through the features on each record
                for features in record["FEATURES"]:
                    lib_id = features["LIB_FEAT_ID"]
                    feature_data = features_by_id[lib_id]
                    feat_code = feature_data["feat_code"]
                    feat_desc = feature_data["feat_desc"]
                    feat_type = feature_data.get("usage_type")
                    feat_type_desc = f"{feat_type}: {feat_desc}"
                    feat_code_desc = f"{feat_code}: {feat_desc}"

                    if feat_code == "NAME":
                        if feat_type_desc not in entity_data["nameData"]:
                            entity_data["nameData"].append(feat_type_desc)

                    elif feat_code == "ADDRESS":
                        if feat_type_desc not in entity_data["addressData"]:
                            entity_data["addressData"].append(feat_type_desc)

                    elif feat_code == "PHONE":
                        if feat_type_desc not in entity_data["phoneData"]:
                            entity_data["phoneData"].append(feat_type_desc)

                    elif self.ftype_lookup_attr_class[feat_code] == "ATTRIBUTE":
                        if feat_code_desc not in entity_data["attributeData"]:
                            entity_data["attributeData"].append(feat_code_desc)

                    elif self.ftype_lookup_attr_class[feat_code] == "IDENTIFIER":
                        if feat_code_desc not in entity_data["identifierData"]:
                            entity_data["identifierData"].append(feat_code_desc)

                # Loop through the unmapped data on each record
                unmapped_data = dict(sorted(record["UNMAPPED_DATA"].items()))
                for type_, value in unmapped_data.items():
                    type_and_value = f"{type_}: {value}"
                    # TODO - Ant is the isInternalAttribute check required?
                    if not self.is_internal_attribute(type_) and type_and_value not in entity_data["otherData"]:
                        entity_data["otherData"].append(type_and_value)

            for related_entity in json_data["RELATED_ENTITIES"]:
                if str(related_entity["ENTITY_ID"]) in entity_list:
                    entity_data["crossRelations"].append(
                        related_entity
                    )  # '%s\n %s\n to %s' % (relatedEntity['MATCH_KEY'][1:], relatedEntity['ERRULE_CODE'], relatedEntity['ENTITY_ID']))
                else:
                    entity_data["otherRelations"].append(
                        related_entity
                    )  # {"MATCH_LEVEL": self.relatedMatchLevels[relatedEntity['MATCH_LEVEL']], "MATCH_KEY": relatedEntity['MATCH_KEY'][1:], "ERRULE_CODE": relatedEntity['ERRULE_CODE'], "ENTITY_ID": relatedEntity['ENTITY_ID'], "ENTITY_NAME": relatedEntity['ENTITY_NAME']})

            compare_list.append(entity_data)

        # determine if there are any relationships in common
        for entity_data_1 in compare_list:
            entity_data_1["relsInCommon"] = []
            for entity_data_2 in compare_list:
                if entity_data_2["entityID"] == entity_data_1["entityID"]:
                    continue
                for relation_1 in entity_data_1["otherRelations"]:
                    for relation_2 in entity_data_2["otherRelations"]:
                        common_relation = False
                        if relation_1["ENTITY_ID"] == relation_2["ENTITY_ID"]:
                            common_relation = True
                        if common_relation and relation_1 not in entity_data_1["relsInCommon"]:
                            entity_data_1["relsInCommon"].append(relation_1)

        # create the column data arrays
        data_sources_row = []
        name_data_row = []
        attribute_data_row = []
        identifier_data_row = []
        address_data_row = []
        phone_data_row = []
        relationship_data_row = []
        other_data_row = []
        cross_rels_row = []
        common_rels_row = []

        for entity_data in compare_list:
            data_sources_list = []
            for data_source in sorted(entity_data["dataSources"]):
                if len(entity_data["dataSources"][data_source]) == 1:
                    data_sources_list.append(
                        colorize_dsrc(data_source + ": " + entity_data["dataSources"][data_source][0])
                    )
                else:
                    data_sources_list.append(
                        colorize_dsrc(
                            data_source + ": " + str(len(entity_data["dataSources"][data_source])) + " records"
                        )
                    )
            data_sources_row.append("\n".join(data_sources_list))

            name_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["nameData"])]))
            attribute_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["attributeData"])]))
            identifier_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["identifierData"])]))
            address_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["addressData"])]))
            phone_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["phoneData"])]))
            relationship_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["relationshipData"])]))
            other_data_row.append("\n".join([colorize_attr(x) for x in sorted(entity_data["otherData"])]))

            cross_rels_list = []
            for relation in sorted(entity_data["crossRelations"], key=lambda x: x["ENTITY_ID"]):
                match_data = {}
                match_data["matchKey"] = relation["MATCH_KEY"]
                match_data["ruleCode"] = self.getRule_desc(relation["ERRULE_CODE"])
                if len(compare_list) > 2:
                    match_data["entityId"] = relation["ENTITY_ID"]
                cross_rels_list.append(colorize_match_data(match_data))
            cross_rels_row.append("\n".join(cross_rels_list))

            common_rels_list = []
            for relation in sorted(entity_data["relsInCommon"], key=lambda x: x["ENTITY_ID"]):
                match_data = {}
                match_data["matchKey"] = relation["MATCH_KEY"]
                match_data["ruleCode"] = self.getRule_desc(relation["ERRULE_CODE"])
                match_data["entityId"] = relation["ENTITY_ID"]
                match_data["entityName"] = relation["ENTITY_NAME"]
                common_rels_list.append(colorize_match_data(match_data))
            common_rels_row.append("\n".join(common_rels_list))

        # initialize table
        column_width = 75
        tbl_title = "Comparison of listed entities"
        tbl_columns = []
        tbl_columns.append({"name": "Entity ID", "width": 16, "align": "left"})
        url_row = []
        for entity_id in entity_list:
            column_header = colorize_entity(str(entity_id))
            tbl_columns.append({"name": column_header, "width": column_width, "align": "left"})
            if self.webapp_url:
                url_row.append(colorize(f"{self.webapp_url}/graph/{entity_id}", "highlight1,underline"))

        # set the row titles
        row_titles = {
            "urlRow": "WebApp url",
            "dataSourceRow": "Sources",
            "nameDataRow": "Names",
            "attributeDataRow": "Attributes",
            "identifierDataRow": "Identifiers",
            "addressDataRow": "Addresses",
            "phoneDataRow": "Phones",
            "otherDataRow": "Other",
            "crossRelsRow": "Cross relations",
            "commonRelsRow": "Common relations",
        }

        for row_title in row_titles:
            row_titles[row_title] = colorize(row_titles[row_title], "row_title")

        # add the data
        tbl_rows = []
        if self.webapp_url:
            tbl_rows.append([row_titles["urlRow"]] + url_row)
        tbl_rows.append([row_titles["dataSourceRow"]] + data_sources_row)
        if len("".join(cross_rels_row)) > 0:
            tbl_rows.append([row_titles["crossRelsRow"]] + cross_rels_row)
        if len("".join(name_data_row)) > 0:
            tbl_rows.append([row_titles["nameDataRow"]] + name_data_row)
        if len("".join(attribute_data_row)) > 0:
            tbl_rows.append([row_titles["attributeDataRow"]] + attribute_data_row)
        if len("".join(identifier_data_row)) > 0:
            tbl_rows.append([row_titles["identifierDataRow"]] + identifier_data_row)
        if len("".join(address_data_row)) > 0:
            tbl_rows.append([row_titles["addressDataRow"]] + address_data_row)
        if len("".join(phone_data_row)) > 0:
            tbl_rows.append([row_titles["phoneDataRow"]] + phone_data_row)
        if len("".join(other_data_row)) > 0:
            tbl_rows.append([row_titles["otherDataRow"]] + other_data_row)
        # if len(''.join(relationshipDataRow)) > 0:
        #    tblRows.append(['Disclosed Rels'] + relationshipDataRow)
        if len("".join(common_rels_row)) > 0:
            tbl_rows.append([row_titles["commonRelsRow"]] + common_rels_row)

        self.render_table(tbl_title, tbl_columns, tbl_rows)

        return 0

    # ---------------------------
    def help_tree(self):
        print(
            textwrap.dedent(
                f"""\

        Displays an entity tree from a particular entity's point of view.

        {colorize('Syntax:', 'highlight2')}
            tree <entity_id>                  {colorize('displays the first degree relationships of an entity', 'dim')}
            tree <entity_id> degree <n>       {colorize('displays relationships of an entity out to <n> degrees', 'dim')}
            tree <entity_id> degree <n> all   {colorize('adding the "all" tag disables the default limit of 10 per category', 'dim')}
        """
            )
        )

    # ---------------------------
    def do_tree(self, arg, **kwargs):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_tree()
            return -1 if caller else 0

        root_entity_id = None
        build_out_degree = 1
        max_children_display = 25
        arg_list = arg.split()
        if arg_list[-1].upper() == "ALL":
            max_children_display = 999999
            arg_list.pop(-1)
        if len(arg_list) in (1, 3, 4):
            if arg_list[0].isdigit():
                root_entity_id = int(arg_list[0])
            if len(arg_list) == 3 and arg_list[1].upper() == "DEGREE" and arg_list[2].isdigit():
                build_out_degree = int(arg_list[2])
        if not root_entity_id:
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return

        entity_parameter = json.dumps({"ENTITIES": [{"ENTITY_ID": root_entity_id}]})

        # these are default thresholds
        max_degree = 0  # really only used for entity paths
        max_entities = 10000  # for safety

        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data = self.execute_sz_api(
                "find_network_by_entity_id",
                get_flag_list,
                [[root_entity_id], max_degree, build_out_degree, max_entities],
            )
        except SzError as err:
            print_message(err, "error")
            return

        nodes = {}
        missing_entities = []
        current_parent_list = [
            {
                "NEXT_RELATED_ENTITY_I": 0,
                "RELATED_ENTITY_LIST": [root_entity_id],
                "PRIOR_ENTITY_LIST": [root_entity_id],
            }
        ]

        while current_parent_list:
            # decrement degree if done with this list
            current_parent_data = current_parent_list[-1]
            if current_parent_data["NEXT_RELATED_ENTITY_I"] == len(current_parent_data["RELATED_ENTITY_LIST"]):
                current_parent_list.pop()
                continue

            # get next related entity
            entity_id = current_parent_data["RELATED_ENTITY_LIST"][current_parent_data["NEXT_RELATED_ENTITY_I"]]
            current_parent_list[-1]["NEXT_RELATED_ENTITY_I"] += 1
            nodes[entity_id] = {}
            nodes[entity_id]["RELATED_ENTITY_LIST"] = []

            # entity_data = self.getEntityFromEntities(json_data["ENTITIES"], entity_id)
            entity_data = self.get_entity_from_entities(json_data["ENTITIES"], entity_id)
            if not entity_data:
                missing_entities.append(entity_id)
                nodes[entity_id]["ENTITY_NAME"] = "not found!"
                continue

            nodes[entity_id]["ENTITY_NAME"] = entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            nodes[entity_id]["RECORD_SUMMARY"] = entity_data["RESOLVED_ENTITY"]["RECORD_SUMMARY"]
            nodes[entity_id]["RELATED_ENTITY_COUNT"] = 0

            rel_class_list = [
                ["Ambiguous matches", "AM_COUNT", "AM_CATEGORIES"],
                ["Possible matches", "PM_COUNT", "PM_CATEGORIES"],
                ["Possible relationships", "PR_COUNT", "PR_CATEGORIES"],
                ["Disclosed relationships", "DR_COUNT", "DR_CATEGORIES"],
            ]

            for rel_class_fields in rel_class_list:
                nodes[entity_id][rel_class_fields[1]] = 0
                nodes[entity_id][rel_class_fields[2]] = {}

            # categorize relationships
            for relationship in entity_data.get("RELATED_ENTITIES", []):
                related_id = relationship["ENTITY_ID"]

                # bypass nodes already rendered at prior levels
                if related_id in current_parent_list[-1]["PRIOR_ENTITY_LIST"]:
                    continue

                nodes[entity_id]["RELATED_ENTITY_COUNT"] += 1
                nodes[entity_id]["RELATED_ENTITY_LIST"].append(related_id)

                # disclosed_keys, plus_keys, minus_keys = self.categorizeMatchkey(
                disclosed_keys, plus_keys, minus_keys = self.categorize_match_key(relationship["MATCH_KEY"])

                if relationship["IS_DISCLOSED"]:
                    rel_class_index = 3
                    key = colorize("+".join(sorted(disclosed_keys)), "highlight2")
                elif relationship["IS_AMBIGUOUS"]:
                    rel_class_index = 0
                    key = colorize("+".join(sorted(plus_keys)), "good") + (
                        colorize("-" + "-".join(minus_keys), "bad") if minus_keys else ""
                    )
                # elif relationship["MATCH_LEVEL"] < 3:
                elif relationship["MATCH_LEVEL_CODE"] in ("RESOLVED", "POSSIBLY_SAME"):
                    rel_class_index = 1
                    key = colorize("+".join(sorted(plus_keys)), "good") + (
                        colorize("-" + "-".join(minus_keys), "bad") if minus_keys else ""
                    )
                else:
                    rel_class_index = 2
                    key = colorize("+".join(sorted(plus_keys)), "good")

                nodes[entity_id][rel_class_list[rel_class_index][1]] += 1
                if key not in nodes[entity_id][rel_class_list[rel_class_index][2]]:
                    nodes[entity_id][rel_class_list[rel_class_index][2]][key] = []
                nodes[entity_id][rel_class_list[rel_class_index][2]][key].append(related_id)

            # remove related entities at prior level
            related_entity_list = []
            if nodes[entity_id]["RELATED_ENTITY_LIST"]:
                for related_id in nodes[entity_id]["RELATED_ENTITY_LIST"]:
                    if related_id not in current_parent_list[-1]["PRIOR_ENTITY_LIST"]:
                        related_entity_list.append(related_id)
                nodes[entity_id]["RELATED_ENTITY_LIST"] = related_entity_list

            # start a new parent if any children left
            if related_entity_list:
                current_parent_list.append(
                    {
                        "ENTITY_ID": entity_id,
                        "NEXT_RELATED_ENTITY_I": 0,
                        "RELATED_ENTITY_LIST": related_entity_list,
                        "PRIOR_ENTITY_LIST": current_parent_list[-1]["PRIOR_ENTITY_LIST"] + related_entity_list,
                    }
                )

        # create the tree view
        tree_nodes = {}

        root_node = Node(root_entity_id)
        root_node.node_desc = self.entity_node_desc(nodes, root_entity_id)
        tree_nodes[root_entity_id] = root_node

        current_degree_list = [{"node": root_node, "entity_id": root_entity_id, "next_child": 0}]

        while current_degree_list:
            # determine what relationships to build under a relationship class/category tree
            if current_degree_list[-1]["next_child"] == 0:
                # print('\t' * (len(current_degree_list) - 1), 'entity:', current_degree_list[-1]['entity_id'])
                entity_id = current_degree_list[-1]["entity_id"]
                related_ids_to_build = []

                for rel_class_fields in rel_class_list:
                    class_name = rel_class_fields[0]
                    count_key = rel_class_fields[1]
                    category_key = rel_class_fields[2]

                    if nodes[entity_id][count_key] > 0:
                        class_node = Node(f"{nodes[entity_id]}-{class_name}")
                        # colorized_class_name = colorize(class_name, 'highlight1')
                        # class_node.node_desc = f'{colorized_class_name} ({nodes[entity_id][count_key]})'
                        class_node.node_desc = f"{class_name} ({nodes[entity_id][count_key]})"

                        for category in sorted(nodes[entity_id][category_key].keys()):
                            category_node = Node(f"{nodes[entity_id]}-{category}")
                            category_node.node_desc = f"{category} ({len(nodes[entity_id][category_key][category])})"
                            cnt = 0
                            for related_id in sorted(nodes[entity_id][category_key][category]):
                                entity_node = Node(related_id)
                                # entity_node.node_desc = self.entityNodeDesc(
                                entity_node.node_desc = self.entity_node_desc(nodes, related_id)
                                tree_nodes[related_id] = entity_node
                                category_node.add_child(entity_node)

                                related_ids_to_build.append(related_id)
                                cnt += 1
                                if cnt == max_children_display:
                                    if len(nodes[entity_id][category_key][category]) > cnt:
                                        additional_node = Node(f"{nodes[entity_id]}-{category}-additional")
                                        additional_node.node_desc = (
                                            f"+{len(nodes[entity_id][category_key][category])-cnt} more!"
                                        )
                                        category_node.add_child(additional_node)
                                    break

                            class_node.add_child(category_node)
                        current_degree_list[-1]["node"].add_child(class_node)
                current_degree_list[-1]["children"] = related_ids_to_build

            if current_degree_list[-1]["next_child"] >= len(current_degree_list[-1]["children"]):
                current_degree_list.pop()
                continue

            related_id = current_degree_list[-1]["children"][current_degree_list[-1]["next_child"]]
            current_degree_list[-1]["next_child"] += 1

            # print('\t' * len(current_degree_list), 'related:', related_id, current_degree_list[-1]['prior_level_nodes'])

            # start a new list of children if any
            if len(current_degree_list) < build_out_degree and nodes[related_id]["RELATED_ENTITY_COUNT"] > 0:
                current_degree_list.append(
                    {
                        "node": tree_nodes[related_id],
                        "entity_id": related_id,
                        "next_child": 0,
                    }
                )

        if caller:
            tree_str = root_node.render_tree()
            self.current_render_string = self.current_render_string + tree_str[tree_str.find("\n") + 1 :]
            self.show_report("auto")
        else:
            print()
            print(root_node.render_tree())
            print()
        return

    # ---------------------------
    def entity_node_desc(self, nodes, node_id):
        if node_id not in nodes:
            return f"{node_id} not found!"

        node_desc = colorize_entity(node_id) + " "

        if "RECORD_SUMMARY" in nodes[node_id]:
            node_desc += (
                " | ".join(
                    colorize_dsrc(f"{ds['DATA_SOURCE']} ({ds['RECORD_COUNT']})")
                    for ds in nodes[node_id]["RECORD_SUMMARY"]
                )
                + " "
            )

        if "ENTITY_NAME" in nodes[node_id]:
            node_desc += nodes[node_id]["ENTITY_NAME"]
        else:
            node_desc += "no name"

        return node_desc

    # ---------------------------
    def get_entity_from_entities(self, _entity_list, _entity_id):
        # print(json.dumps(_entity_list[0:100]))
        item_list = [item for item in _entity_list if item["RESOLVED_ENTITY"]["ENTITY_ID"] == _entity_id]
        if item_list:
            return item_list[0]
        return None

    # ---------------------------
    def categorize_match_key(self, match_key, **kwargs):
        # match_key example:
        #  'SOME_REL_DOMAIN(FATHER,SPOUSE:SON,SPOUSE)+ADDRESS+PHONE-DOB (Ambiguous)'
        match_key = match_key.replace(" (Ambiguous)", "")
        disclosed_keys = []
        plus_keys = []
        minus_keys = []
        key_list = re.split(r"(\+|\-)", match_key)
        all_disclosures = []

        i = 1
        while i < len(key_list):
            if key_list[i] in ("+"):
                i += 1
                this_key = key_list[i]
                # derived
                if "(" not in this_key:
                    plus_keys.append(this_key)
                # disclosed
                else:
                    if kwargs.get("from_database") is True:
                        # format: REL_POINTER(DOMAIN:|MIN:|MAX:PRINCIPAL)
                        try:
                            l1 = this_key.find("DOMAIN:")
                            l2 = this_key.find("MIN:")
                            l3 = this_key.find("MAX:")
                            domain = this_key[l1 + 7 : l2 - 1]
                            role1 = this_key[l2 + 4 : l3 - 1]
                            role2 = this_key[l3 + 4 : -1]
                            all_disclosures.append(f"{domain}({role1}:{role2})")
                        except:
                            print(this_key)
                    else:
                        # format: DOMAIN(ROLE:ROLE)
                        both_side_roles = this_key[this_key.find("(") + 1 : this_key.find(")")].split(":")
                        # left side of colon is from this entity's point of view
                        # but if blank, must use right side as both sides not required
                        roles_to_use = both_side_roles[0] if both_side_roles[0] else both_side_roles[1]
                        disclosed_keys += roles_to_use.split(",")
            elif key_list[i] in ("-"):
                i += 1
                this_key = key_list[i]
                minus_keys.append(this_key)

            i += 1
        if kwargs.get("from_database") is True:
            return all_disclosures, plus_keys, minus_keys
        else:
            return disclosed_keys, plus_keys, minus_keys

    # ---------------------------
    def help_why(self):
        print(
            textwrap.dedent(
                f"""\

        Shows the internal values and scores used to determine why a set of records resolved or only related.

        {colorize('Syntax:', 'highlight2')}
            why <entity_id1>                                            {colorize('shows why the records in a single entity resolved together', 'dim')}
            why <entity_id1> <entity_id2>                               {colorize('shows why two or more different entities did not resolve', 'dim')}
            why <data_source1> <record_id1> <data_source2> <record_id2> {colorize('shows if the two data source records could resolve or relate', 'dim')}

        {colorize('Color legend:', 'highlight2')}
            {colorize('green', 'good')} indicates the values matched and contributed to the overall score
            {colorize('red', 'bad')} indicates the values did not match and hurt the overall score
            {colorize('yellow', 'caution')} indicates the values did not match but did not hurt the overall score
            {colorize('cyan', 'highlight2')} indicates the values only helped get the record on the candidate list
            {colorize('dimmed', 'dim')} values were ignored (see the bracket legend below)

        {colorize('Bracket legend:', 'highlight2')}
            [99] indicates how many entities share this value
            [~] indicates that this value was not used to find candidates as too many entities share it
            [!] indicates that this value was not even scored as too many entities share it
            [#] indicates that this value was suppressed in favor of a more complete value\n
        """
            )
        )

    # ---------------------------
    def do_why(self, arg):
        calledDirect = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_why()
            return -1 if calledDirect else 0

        # see if already a list ... it will be if it came from audit
        if isinstance(arg, list):
            entity_list = arg
        else:
            old_why_not = False
            if arg.upper().endswith(" OLD"):
                old_why_not = True
                arg = arg[0:-4]

            if isinstance(arg, str) and "SEARCH" in arg.upper():
                last_token = arg.split()[len(arg.split()) - 1]
                if last_token.isdigit():
                    entity_list = self.last_search_result[: int(last_token)]
                else:
                    entity_list = self.last_search_result
            elif "," in arg:
                entity_list = arg.split(",")
            else:
                entity_list = arg.split()

            if not all(x.isnumeric() for x in entity_list) and not entity_list[0].upper() in self.dsrc_code_lookup:
                print_message(
                    "Invalid parameter: expected one or more numeric entity IDs",
                    "caution",
                )
                return -1 if calledDirect else 0

        if len(entity_list) == 1:
            why_type = "whyEntity"
            tbl_title = f"Why for entity: {colorize_entity(entity_list[0])}"
            first_row_title = "INTERNAL_ID"
            entity_data = self.why_entity(entity_list)

        elif len(entity_list) == 2 and not old_why_not:
            why_type = "whyNot1"
            tbl_title = "Why not for listed entities"
            first_row_title = "ENTITY_ID"
            entity_data = self.why_not_2(entity_list)

        elif len(entity_list) == 4 and entity_list[0].upper() in self.dsrc_code_lookup:
            why_type = "whyRecords"
            tbl_title = f"Why for record: {colorize_dsrc(entity_list[0].upper())}: {entity_list[1]} vs {colorize_dsrc(entity_list[2].upper())}: {entity_list[3]}"
            first_row_title = "INTERNAL_ID"
            entity_data = self.why_records(entity_list)

        else:
            why_type = "whyNot2"
            tbl_title = "Why not for listed entities"
            first_row_title = "ENTITY_ID"
            entity_data = self.why_not_many(entity_list)

        if not entity_data:
            return -1 if calledDirect else 0

        tbl_columns = [
            {
                "name": colorize(first_row_title, "row_title"),
                "width": 50,
                "align": "left",
            }
        ]
        tbl_rows = []

        data_source_row = ["DATA_SOURCES"]
        match_key_row = ["WHY_RESULT"]
        cross_relations_row = ["RELATIONSHIPS"]
        feature_array = {}
        for entity_id in sorted(entity_data.keys()):
            # add the column
            color = "entity_color" if first_row_title == "ENTITY_ID" else "dim"
            tbl_columns.append({"name": colorize(entity_id, color), "width": 75, "align": "left"})

            # add the data sources
            data_source_row.append("\n".join(sorted(entity_data[entity_id]["dataSources"])))

            # add the cross relationships
            if "crossRelations" in entity_data[entity_id]:
                relation_list = []
                for relationship in [
                    x
                    for x in sorted(
                        entity_data[entity_id]["crossRelations"],
                        key=lambda k: k["entityId"],
                    )
                ]:
                    if len(entity_list) <= 2:  # suppress to entity if only 2
                        del relationship["entityId"]
                    relation_list.append(colorize_match_data(relationship))
                cross_relations_row.append("\n".join(relation_list))

            # add the matchKey
            if "whyKey" not in entity_data[entity_id] or not entity_data[entity_id]["whyKey"]:
                # can only happen with the old multiple entity why
                match_key_row.append(colorize("Not found!", "bad"))
            elif not isinstance(entity_data[entity_id]["whyKey"], list):
                match_key_row.append(colorize_match_data(entity_data[entity_id]["whyKey"]))
            else:
                temp_list = []
                for why_key in [x for x in sorted(entity_data[entity_id]["whyKey"], key=lambda k: k["entityId"])]:
                    if "entityId" in why_key and len(entity_list) <= 2:  # suppress to entity if only 2
                        del why_key["entityId"]
                    temp_list.append(colorize_match_data(why_key))
                match_key_row.append("\n".join(temp_list))

            # prepare the feature rows
            why_key = entity_data[entity_id]["whyKey"]
            for lib_feat_id in entity_data[entity_id]["features"]:
                feature_data = entity_data[entity_id]["features"][lib_feat_id]
                ftype_id = feature_data["ftypeId"]
                formatted_feature = self.why_format_feature(feature_data, why_key)
                if ftype_id not in feature_array:
                    feature_array[ftype_id] = {}
                if entity_id not in feature_array[ftype_id]:
                    feature_array[ftype_id][entity_id] = []
                feature_array[ftype_id][entity_id].append(formatted_feature)

        # prepare the table
        tbl_rows.append(data_source_row)
        if len(cross_relations_row) > 1:
            tbl_rows.append(cross_relations_row)
        tbl_rows.append(match_key_row)

        # add the feature rows
        for ftype_id in sorted(feature_array, key=lambda k: self.feature_sequence[k]):
            feature_row = [(self.ftype_lookup[ftype_id]["FTYPE_CODE"] if ftype_id in self.ftype_lookup else "unknown")]
            for entity_id in sorted(entity_data.keys()):
                if entity_id not in feature_array[ftype_id]:
                    feature_row.append("")
                else:
                    feature_list = []
                    for feature_dict in sorted(
                        sorted(
                            feature_array[ftype_id][entity_id],
                            key=lambda k: (k["featDesc"]),
                        ),
                        key=lambda k: (k["sortOrder"]),
                    ):
                        feature_list.append(feature_dict["formattedFeatDesc"])
                    feature_row.append("\n".join(feature_list))
            tbl_rows.append(feature_row)

        # colorize the first column
        for i in range(len(tbl_rows)):
            tbl_rows[i][0] = colorize(tbl_rows[i][0], "row_title")

        # display the table
        self.render_table(tbl_title, tbl_columns, tbl_rows, displayFlag="No")
        self.show_report("auto", from_how_or_why=True)

        return 0

    # ---------------------------
    def why_entity(self, entity_list):
        # TODO
        print("\nWhy on a single entity isn't currently implemented in V4 beta. Other why commands are implemented.\n")

        # why_flag_list = ["SZ_WHY_ENTITY_DEFAULT_FLAGS"]
        # try:
        #     json_data = self.execute_sz_api("why_entity_by_entity_id", why_flag_list, int(entity_list[0]))
        # # except Exception as err:
        # except SzError as err:
        #     print_message(err, "error")
        #     return None

        # entity_data = {}
        # for why_result in json_data["WHY_RESULTS"]:
        #     internal_id = why_result["INTERNAL_ID"]
        #     entity_id = why_result["ENTITY_ID"]
        #     this_id = internal_id  # will eventually be entityId when why not function is added
        #     entity_data[this_id] = {}

        #     records = self.why_fmt_record_list(why_result["FOCUS_RECORDS"])
        #     features = self.why_get_features(json_data, entity_id, internal_id)
        #     if "MATCH_INFO" not in why_result:
        #         why_key = None
        #     else:
        #         why_key, features = self.why_add_match_info(features, why_result["MATCH_INFO"])

        #     entity_data[this_id]["dataSources"] = records
        #     entity_data[this_id]["whyKey"] = why_key
        #     entity_data[this_id]["features"] = features

        # return entity_data

    # ---------------------------
    def why_records(self, entity_list):
        whyFlagList = [
            "SZ_WHY_ENTITIES_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]
        try:
            json_data = self.execute_sz_api(
                "why_records",
                whyFlagList,
                [entity_list[0], entity_list[1], entity_list[2], entity_list[3]],
            )
        except SzError as err:
            print_message(err, "error")
            return

        entity_data = {}
        for why_result in json_data["WHY_RESULTS"]:
            # get the first record
            internal_id = why_result["INTERNAL_ID"]
            entity_id = why_result["ENTITY_ID"]
            this_id = internal_id  # will eventually be entityId when why not function is added
            entity_data[this_id] = {}

            records = self.why_fmt_record_list(why_result["FOCUS_RECORDS"])
            features = self.why_get_features(json_data, entity_id, internal_id)
            if "MATCH_INFO" not in why_result:
                why_key = None
            else:
                why_key, features = self.why_add_match_info(features, why_result["MATCH_INFO"])

            entity_data[this_id]["dataSources"] = records
            entity_data[this_id]["whyKey"] = why_key
            entity_data[this_id]["features"] = features

            # get the second record
            internal_id = why_result["INTERNAL_ID_2"]
            entity_id = why_result["ENTITY_ID_2"]
            this_id = internal_id  # will eventually be entityId when why not function is added
            entity_data[this_id] = {}

            records = self.why_fmt_record_list(why_result["FOCUS_RECORDS_2"])
            features = self.why_get_features(json_data, entity_id, internal_id)
            if "MATCH_INFO" not in why_result:
                why_key = None
            else:
                why_key, features = self.why_add_match_info(features, why_result["MATCH_INFO"])

            entity_data[this_id]["dataSources"] = records
            entity_data[this_id]["whyKey"] = why_key
            entity_data[this_id]["features"] = features

            break  # there can only really be one, so lets be done!

        return entity_data

    # ---------------------------
    def why_not_2(self, entity_list):

        why_flag_list = ["SZ_WHY_ENTITIES_DEFAULT_FLAGS"]
        try:
            json_data = self.execute_sz_api(
                "why_entities",
                why_flag_list,
                [int(entity_list[0]), int(entity_list[1])],
            )
        except SzError as err:
            print_message(err, "error")
            return

        entity_data = {}
        for why_result in json_data["WHY_RESULTS"]:
            for this_id in [why_result["ENTITY_ID"], why_result["ENTITY_ID_2"]]:
                entity_data[this_id] = {}
                best_entity = None
                for resolved_entity in json_data["ENTITIES"]:
                    if resolved_entity["RESOLVED_ENTITY"]["ENTITY_ID"] == this_id:
                        best_entity = resolved_entity
                        break
                if not best_entity:
                    print("\nInternal error: resolved entity %s missing!\n" % this_id)
                    return None

                records = self.why_fmt_record_list(best_entity["RESOLVED_ENTITY"]["RECORDS"])
                features = {}
                for ftype_code in best_entity["RESOLVED_ENTITY"]["FEATURES"]:
                    for distinct_feature_record in best_entity["RESOLVED_ENTITY"]["FEATURES"][ftype_code]:
                        for feat_record in distinct_feature_record["FEAT_DESC_VALUES"]:
                            lib_feat_id = feat_record["LIB_FEAT_ID"]
                            if lib_feat_id not in features:
                                features[lib_feat_id] = {}
                                features[lib_feat_id]["ftypeId"] = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                                features[lib_feat_id]["ftypeCode"] = ftype_code
                                features[lib_feat_id]["featDesc"] = feat_record["FEAT_DESC"]
                                features[lib_feat_id]["isCandidate"] = feat_record["USED_FOR_CAND"]
                                features[lib_feat_id]["isScored"] = feat_record["USED_FOR_SCORING"]
                                features[lib_feat_id]["entityCount"] = feat_record["ENTITY_COUNT"]
                                features[lib_feat_id]["candidateCapReached"] = feat_record["CANDIDATE_CAP_REACHED"]
                                features[lib_feat_id]["scoringCapReached"] = feat_record["SCORING_CAP_REACHED"]
                                features[lib_feat_id]["scoringWasSuppressed"] = feat_record["SUPPRESSED"]

                if "MATCH_INFO" not in why_result:
                    why_key = None
                else:
                    why_key, features = self.why_add_match_info(features, why_result["MATCH_INFO"])

                entity_data[this_id]["dataSources"] = records
                entity_data[this_id]["whyKey"] = why_key
                entity_data[this_id]["features"] = features

                entity_data[this_id]["crossRelations"] = []
                for related_entity in best_entity["RELATED_ENTITIES"]:
                    if str(related_entity["ENTITY_ID"]) in entity_list:
                        relationship = {}
                        relationship["entityId"] = related_entity["ENTITY_ID"]
                        relationship["matchKey"] = related_entity["MATCH_KEY"]
                        relationship["ruleCode"] = self.getRule_desc(related_entity["ERRULE_CODE"])
                        entity_data[this_id]["crossRelations"].append(relationship)

        return entity_data

    # ---------------------------
    def why_not_many(self, entity_list):

        why_flag_list = [
            "SZ_WHY_ENTITY_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
        ]

        master_ftype_list = []
        entity_data = {}
        for entity_id in entity_list:
            entity_data[entity_id] = {}
            try:
                json_data = self.execute_sz_api("why_entity_by_entity_id", why_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                return

            # add the data sources and create search json
            search_json = {}
            entity_data[entity_id]["dataSources"] = []
            for record in json_data["ENTITIES"][0]["RESOLVED_ENTITY"]["RECORDS"]:
                entity_data[entity_id]["dataSources"].append("%s: %s" % (record["DATA_SOURCE"], record["RECORD_ID"]))
                if not search_json:
                    search_json = record["JSON_DATA"]
                else:  # merge the json records
                    root_attributes = {}
                    for root_attribute in record["JSON_DATA"]:
                        if not isinstance(record["JSON_DATA"][root_attribute], list):
                            root_attributes[root_attribute] = record["JSON_DATA"][root_attribute]
                        else:
                            if root_attribute not in search_json:
                                search_json[root_attribute] = []
                            for sub_record in record["JSON_DATA"][root_attribute]:
                                search_json[root_attribute].append(sub_record)
                    if root_attributes:
                        if "ROOT_ATTRIBUTES" not in search_json:
                            search_json["ROOT_ATTRIBUTES"] = []
                        search_json["ROOT_ATTRIBUTES"].append(root_attributes)

            # get info for these features from the resolved entity section
            entity_data[entity_id]["features"] = {}
            for ftype_code in json_data["ENTITIES"][0]["RESOLVED_ENTITY"]["FEATURES"]:
                for feat_record in json_data["ENTITIES"][0]["RESOLVED_ENTITY"]["FEATURES"][ftype_code]:
                    for feat_values in feat_record["FEAT_DESC_VALUES"]:
                        lib_feat_id = feat_values["LIB_FEAT_ID"]
                        if lib_feat_id not in entity_data[entity_id]["features"]:
                            entity_data[entity_id]["features"][lib_feat_id] = {}
                            entity_data[entity_id]["features"][lib_feat_id]["ftypeId"] = self.ftype_code_lookup[
                                ftype_code
                            ]["FTYPE_ID"]
                            entity_data[entity_id]["features"][lib_feat_id]["ftypeCode"] = ftype_code
                            entity_data[entity_id]["features"][lib_feat_id]["featDesc"] = feat_values["FEAT_DESC"]
                            entity_data[entity_id]["features"][lib_feat_id]["isCandidate"] = feat_values[
                                "USED_FOR_CAND"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["isScored"] = feat_values[
                                "USED_FOR_SCORING"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["entityCount"] = feat_values["ENTITY_COUNT"]
                            entity_data[entity_id]["features"][lib_feat_id]["candidateCapReached"] = feat_values[
                                "CANDIDATE_CAP_REACHED"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["scoringCapReached"] = feat_values[
                                "SCORING_CAP_REACHED"
                            ]
                            entity_data[entity_id]["features"][lib_feat_id]["scoringWasSuppressed"] = feat_values[
                                "SUPPRESSED"
                            ]
                            if entity_data[entity_id]["features"][lib_feat_id]["ftypeId"] not in master_ftype_list:
                                master_ftype_list.append(entity_data[entity_id]["features"][lib_feat_id]["ftypeId"])

            # see how this entity is related to the others
            get_flag_list = ["SZ_ENTITY_BRIEF_DEFAULT_FLAGS"]
            try:
                json_data2 = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                return

            entity_data[entity_id]["crossRelations"] = []
            for related_entity in json_data2["RELATED_ENTITIES"]:
                if str(related_entity["ENTITY_ID"]) in entity_list:
                    relationship = {}
                    relationship["entityId"] = related_entity["ENTITY_ID"]
                    relationship["matchKey"] = related_entity["MATCH_KEY"]
                    relationship["ruleCode"] = self.getRule_desc(related_entity["ERRULE_CODE"])
                    entity_data[entity_id]["crossRelations"].append(relationship)

            # search for this entity to get the scores against the others
            search_flag_list = [
                "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
                "SZ_INCLUDE_FEATURE_SCORES",
                "SZ_ENTITY_INCLUDE_ENTITY_NAME",
                "SZ_ENTITY_INCLUDE_RECORD_DATA",
            ]
            try:
                json_data2 = self.execute_sz_api("search_by_attributes", search_flag_list, json.dumps(search_json))
            except SzError as err:
                print_message(err, "error")
                return

            entity_data[entity_id]["whyKey"] = []
            for resolved_entity_base in json_data2["RESOLVED_ENTITIES"]:
                resolved_entity = resolved_entity_base["ENTITY"]["RESOLVED_ENTITY"]
                resolved_entity_match_info = resolved_entity_base["MATCH_INFO"]
                if str(resolved_entity["ENTITY_ID"]) in entity_list and str(resolved_entity["ENTITY_ID"]) != entity_id:
                    why_key = {}
                    why_key["matchKey"] = resolved_entity_match_info["MATCH_KEY"]
                    why_key["ruleCode"] = self.getRule_desc(resolved_entity_match_info["ERRULE_CODE"])
                    why_key["entityId"] = resolved_entity["ENTITY_ID"]
                    entity_data[entity_id]["whyKey"].append(why_key)
                    for feature_code in resolved_entity_match_info["FEATURE_SCORES"]:
                        # get the best score for the feature
                        best_score_record = None
                        for score_record in resolved_entity_match_info["FEATURE_SCORES"][feature_code]:
                            # print (json.dumps(scoreRecord, indent=4))
                            if not best_score_record:
                                best_score_record = score_record
                            elif "GNR_FN" in score_record and score_record["GNR_FN"] > best_score_record["GNR_FN"]:
                                best_score_record = score_record
                            elif "BT_FN" in score_record and score_record["BT_FN"] > best_score_record["BT_FN"]:
                                best_score_record = score_record
                            elif (
                                "FULL_SCORE" in score_record
                                and score_record["FULL_SCORE"] > best_score_record["FULL_SCORE"]
                            ):
                                best_score_record = score_record
                        # update the entity feature
                        for lib_feat_id in entity_data[entity_id]["features"]:
                            # print ('-' * 50)
                            # print(entityData[entityId]['features'][libFeatId])
                            if entity_data[entity_id]["features"][lib_feat_id][
                                "ftypeCode"
                            ] == feature_code and entity_data[entity_id]["features"][lib_feat_id]["featDesc"] in (
                                best_score_record["INBOUND_FEAT"],
                                best_score_record["CANDIDATE_FEAT"],
                            ):
                                match_score = 0
                                match_level = "DIFF"
                                if "GNR_FN" in best_score_record:
                                    match_score = best_score_record["GNR_FN"]
                                    if "GNR_ON" in best_score_record and best_score_record["GNR_ON"] >= 0:
                                        match_score_display = "org:%s" % best_score_record["GNR_ON"]
                                    else:
                                        match_score_display = "score:%s" % best_score_record["GNR_FN"]
                                        if "GNR_GN" in best_score_record and best_score_record["GNR_GN"] >= 0:
                                            match_score_display += "|giv:%s" % best_score_record["GNR_GN"]
                                        if "GNR_SN" in best_score_record and best_score_record["GNR_SN"] >= 0:
                                            match_score_display += "|sur:%s" % best_score_record["GNR_SN"]
                                    if match_score == 100:
                                        match_level = "SAME"
                                    else:
                                        if "NAME" in resolved_entity_match_info["MATCH_KEY"]:
                                            match_level = "CLOSE"
                                elif "BT_FN" in best_score_record:
                                    match_score = best_score_record["BT_FN"]
                                    if "BT_ON" in best_score_record and best_score_record["BT_ON"] > 0:
                                        match_score_display = "org:%s" % best_score_record["BT_ON"]
                                    else:
                                        match_score_display = "full:%s" % best_score_record["BT_FN"]
                                    if match_score == 100:
                                        match_level = "SAME"
                                    else:
                                        if "NAME" in resolved_entity_match_info["MATCH_KEY"]:
                                            match_level = "CLOSE"
                                else:
                                    match_score = best_score_record["FULL_SCORE"]
                                    match_score_display = str(best_score_record["FULL_SCORE"])
                                    if match_score == 100:
                                        match_level = "SAME"
                                    else:
                                        cfrtn_record = self.cfrtn_lookup[
                                            self.cfunc_lookup[self.scored_ftype_codes[feature_code]["CFUNC_ID"]][
                                                "CFUNC_ID"
                                            ]
                                        ]
                                        if match_score >= cfrtn_record["CLOSE_SCORE"]:
                                            match_level = "CLOSE"

                                if (
                                    "matchScore" not in entity_data[entity_id]["features"][lib_feat_id]
                                    or match_score > entity_data[entity_id]["features"][lib_feat_id]["matchScore"]
                                ):
                                    entity_data[entity_id]["features"][lib_feat_id]["wasScored"] = "Yes"
                                    entity_data[entity_id]["features"][lib_feat_id]["matchedFeatId"] = 0
                                    entity_data[entity_id]["features"][lib_feat_id]["matchedFeatDesc"] = (
                                        best_score_record["CANDIDATE_FEAT"]
                                        if entity_data[entity_id]["features"][lib_feat_id]["featDesc"]
                                        == best_score_record["INBOUND_FEAT"]
                                        else best_score_record["INBOUND_FEAT"]
                                    )
                                    entity_data[entity_id]["features"][lib_feat_id]["matchScore"] = match_score
                                    entity_data[entity_id]["features"][lib_feat_id][
                                        "matchScoreDisplay"
                                    ] = match_score_display
                                    entity_data[entity_id]["features"][lib_feat_id]["matchLevel"] = match_level
                                break

        # find matching features whether scored or not (accounts for candidate keys as well)
        for entity_id in entity_list:
            for lib_feat_id in entity_data[entity_id]["features"]:
                for entity_id_1 in entity_list:
                    if entity_id != entity_id_1 and lib_feat_id in entity_data[entity_id_1]["features"]:
                        entity_data[entity_id]["features"][lib_feat_id]["wasCandidate"] = (
                            "Yes" if entity_data[entity_id]["features"][lib_feat_id]["isCandidate"] == "Y" else "No"
                        )
                        entity_data[entity_id]["features"][lib_feat_id]["matchScore"] = 100
                        entity_data[entity_id]["features"][lib_feat_id]["matchLevel"] = "SAME"
                        break

        return entity_data

    # ---------------------------
    def why_fmt_record_list(self, record_list):
        records_by_source = {}
        for record in record_list:
            if record["DATA_SOURCE"] not in records_by_source:
                records_by_source[record["DATA_SOURCE"]] = []
            records_by_source[record["DATA_SOURCE"]].append(record["RECORD_ID"])
        record_display = []
        for data_source in sorted(records_by_source.keys()):
            colored_data_source = colorize_dsrc(data_source)
            if len(records_by_source[data_source]) > 1:
                record_display.append(f"{colored_data_source}: {len(records_by_source[data_source])} records")
            else:
                for record_id in sorted(records_by_source[data_source]):
                    record_display.append(f"{colored_data_source}: {record_id}")
        return record_display

    # ---------------------------
    def feature_counter_display(self, feature_data):
        counter_display = "["
        if feature_data["candidateCapReached"] == "Y":
            counter_display += "~"
        if feature_data["scoringCapReached"] == "Y":
            counter_display += "!"
        if feature_data["scoringWasSuppressed"] == "Y":
            counter_display += "#"
        counter_display += str(feature_data["entityCount"]) + "]"
        return counter_display

    # ---------------------------
    def why_format_feature(self, feature_data, why_key):

        feature_data["formattedFeatDesc"] = feature_data["featDesc"].strip()
        ftype_code = feature_data["ftypeCode"]
        feature_data["counterDisplay"] = self.feature_counter_display(feature_data)
        feature_data["formattedFeatDesc"] += " " + feature_data["counterDisplay"]
        feature_data["formattedFeatDesc1"] = feature_data["formattedFeatDesc"]

        dimmit = any(c in feature_data["counterDisplay"] for c in ["~", "!", "#"])
        feature_data["sortOrder"] = 3
        if "wasScored" in feature_data:
            if feature_data["matchLevel"] in ("SAME", "CLOSE"):
                feature_data["sortOrder"] = 1
                feature_data["featColor"] = "good"
            else:
                feature_data["sortOrder"] = 2
                if not why_key:
                    feature_data["featColor"] = "bad"
                elif isinstance(why_key, dict) and ("-" + ftype_code) not in why_key["matchKey"]:
                    feature_data["featColor"] = "caution"
                elif isinstance(why_key, list) and ("-" + ftype_code) not in why_key[0]["matchKey"]:
                    feature_data["featColor"] = "caution"
                else:
                    feature_data["featColor"] = "bad"
            # if dimmit:
            #    featureData['featColor'] += ',dim'
            feature_data["formattedFeatDesc1"] = feature_data["formattedFeatDesc"]
            feature_data["formattedFeatDesc"] = colorize(feature_data["formattedFeatDesc"], feature_data["featColor"])

            # note: addresses may score same tho not exact!
            if feature_data["matchLevel"] != "SAME" or feature_data["matchedFeatDesc"] != feature_data["featDesc"]:
                feature_data["formattedFeatDesc"] += "\n" + colorize(
                    f"\u2514\u2500\u2500 {feature_data['matchedFeatDesc']} ({feature_data['matchScoreDisplay']})",
                    feature_data["featColor"],
                )

        elif "matchScore" in feature_data:  # must be same and likely a candidate builder
            feature_data["sortOrder"] = 1
            feature_data["featColor"] = "highlight2" + (",dim" if dimmit else "")
            feature_data["formattedFeatDesc1"] = feature_data["formattedFeatDesc"]
            feature_data["formattedFeatDesc"] = colorize(feature_data["formattedFeatDesc"], feature_data["featColor"])

        else:
            if ftype_code == "AMBIGUOUS_ENTITY":
                if feature_data["formattedFeatDesc"].startswith(" ["):
                    feature_data["formattedFeatDesc"] = "Ambiguous!"
                feature_data["formattedFeatDesc1"] = colorize(feature_data["formattedFeatDesc"], "bad")
                feature_data["formattedFeatDesc"] = colorize(feature_data["formattedFeatDesc"], "bad")

        # sort rejected matches lower
        if dimmit:
            feature_data["sortOrder"] += 0.5

        return feature_data

    # ---------------------------
    def why_get_features(self, json_data, entity_id, internal_id=None):
        best_entity = None
        best_record = None
        for resolved_entity in json_data["ENTITIES"]:
            if resolved_entity["RESOLVED_ENTITY"]["ENTITY_ID"] == entity_id:
                for dsrc_record in resolved_entity["RESOLVED_ENTITY"]["RECORDS"]:
                    if dsrc_record["INTERNAL_ID"] == internal_id:
                        best_entity = resolved_entity
                        best_record = dsrc_record
                        break

        if not best_record or "FEATURES" not in best_record:
            print("\nno features found for resolved entity %s, internal ID %s\n" % (entity_id, internal_id))
            return {}

        features = self.buildout_record_features(best_record["FEATURES"], best_entity["RESOLVED_ENTITY"]["FEATURES"])
        return features

    # ---------------------------
    def buildout_record_features(self, recordFeatures, featureData):
        features = {}
        for feat_record in recordFeatures:
            lib_feat_id = feat_record["LIB_FEAT_ID"]
            usage_type = feat_record.get("USAGE_TYPE", "")
            if lib_feat_id not in features:
                features[feat_record["LIB_FEAT_ID"]] = {}
                features[lib_feat_id]["ftypeId"] = -1
                features[lib_feat_id]["ftypeCode"] = "unknown"
                features[lib_feat_id]["usageType"] = usage_type
                features[lib_feat_id]["featDesc"] = "missing %s" % lib_feat_id
                features[lib_feat_id]["isCandidate"] = "N"
                features[lib_feat_id]["isScored"] = "N"
                features[lib_feat_id]["entityCount"] = -1
                features[lib_feat_id]["candidateCapReached"] = "N"
                features[lib_feat_id]["scoringCapReached"] = "N"
                features[lib_feat_id]["scoringWasSuppressed"] = "N"

        for ftype_code in featureData:
            for distinct_feature_record in featureData[ftype_code]:
                for feat_record in distinct_feature_record["FEAT_DESC_VALUES"]:
                    lib_feat_id = feat_record["LIB_FEAT_ID"]
                    if lib_feat_id in features:
                        features[lib_feat_id]["ftypeId"] = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                        features[lib_feat_id]["ftypeCode"] = ftype_code
                        # disabled here in favor of the record level usage type
                        # features[libFeatId]['usageType'] = distinctFeatureRecord.get('USAGE_TYPE','')
                        features[lib_feat_id]["featDesc"] = feat_record["FEAT_DESC"]
                        features[lib_feat_id]["isCandidate"] = feat_record["USED_FOR_CAND"]
                        features[lib_feat_id]["isScored"] = feat_record["USED_FOR_SCORING"]
                        features[lib_feat_id]["entityCount"] = feat_record["ENTITY_COUNT"]
                        features[lib_feat_id]["candidateCapReached"] = feat_record["CANDIDATE_CAP_REACHED"]
                        features[lib_feat_id]["scoringCapReached"] = feat_record["SCORING_CAP_REACHED"]
                        features[lib_feat_id]["scoringWasSuppressed"] = feat_record["SUPPRESSED"]

        return features

    # ---------------------------
    def why_add_match_info(self, features, matchInfo, default_side="INBOUND"):
        other_side = "CANDIDATE" if default_side == "INBOUND" else "INBOUND"

        why_key = {}
        why_key["matchKey"] = matchInfo["WHY_KEY"]
        why_key["ruleCode"] = self.getRule_desc(matchInfo["WHY_ERRULE_CODE"])
        why_key["anyCandidates"] = False

        # update from candidate section of why
        if "CANDIDATE_KEYS" in matchInfo:
            for ftype_code in matchInfo["CANDIDATE_KEYS"]:
                ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
                for feat_record in matchInfo["CANDIDATE_KEYS"][ftype_code]:
                    lib_feat_id = feat_record["FEAT_ID"]
                    if lib_feat_id not in features:
                        print("warning: candidate feature %s not in record!" % lib_feat_id)
                        continue
                    features[lib_feat_id]["ftypeCode"] = ftype_code
                    features[lib_feat_id]["ftypeId"] = ftype_id
                    features[lib_feat_id]["wasCandidate"] = "Yes"
                    features[lib_feat_id]["matchScore"] = 100
                    features[lib_feat_id]["matchLevel"] = "SAME"
                    why_key["anyCandidates"] = True

        # update from scoring section of why
        for ftype_code in matchInfo["FEATURE_SCORES"]:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            best_score_record = {}
            for feat_record in matchInfo["FEATURE_SCORES"][ftype_code]:
                # if featRecord.get('scoringWasSuppressed','No') == 'Yes':
                #    continue
                # BUG WHERE INBOUND/CANDIDATE IS SOMETIMES REVERSED...
                if feat_record[default_side + "_FEAT_ID"] in features:
                    lib_feat_id = feat_record[default_side + "_FEAT_ID"]
                    matched_feat_id = feat_record[other_side + "_FEAT_ID"]
                    matched_feat_desc = feat_record[other_side + "_FEAT_DESC"]
                elif feat_record[other_side + "_FEAT_ID"] in features:
                    lib_feat_id = feat_record[other_side + "_FEAT_ID"]
                    matched_feat_id = feat_record[default_side + "_FEAT_ID"]
                    matched_feat_desc = feat_record[default_side + "_FEAT_DESC"]
                else:
                    print("warning: scored feature %s not in either record!" % lib_feat_id)
                    continue

                feat_record = self.why_set_match_score(feat_record)
                match_score = feat_record["MATCH_SCORE"]
                match_score_display = feat_record["MATCH_SCORE_DISPLAY"]
                match_level = feat_record["SCORE_BUCKET"]
                feat_behavior = feat_record["SCORE_BEHAVIOR"]

                if "matchScore" not in best_score_record or match_score > best_score_record["matchScore"]:
                    best_score_record["libFeatId"] = lib_feat_id
                    best_score_record["matchScore"] = match_score
                    best_score_record["matchScoreDisplay"] = match_score_display
                    best_score_record["matchLevel"] = match_level
                    best_score_record["matchedFeatId"] = matched_feat_id
                    best_score_record["matchedFeatDesc"] = matched_feat_desc
                    best_score_record["featBehavior"] = feat_behavior

            # and bestScoreRecord['libFeatId'] in features) or not : #--adjusted for how
            if best_score_record:
                lib_feat_id = best_score_record["libFeatId"]
                if lib_feat_id not in features:  # adjusted for how
                    # input(f'hit how adjustment on {libFeatId}, press any key')
                    features[lib_feat_id] = {}
                features[lib_feat_id]["libFeatId"] = lib_feat_id
                features[lib_feat_id]["ftypeId"] = ftype_id
                features[lib_feat_id]["ftypeCode"] = ftype_code
                features[lib_feat_id]["wasScored"] = "Yes"
                features[lib_feat_id]["matchScore"] = best_score_record["matchScore"]
                features[lib_feat_id]["matchScoreDisplay"] = best_score_record["matchScoreDisplay"]
                features[lib_feat_id]["matchLevel"] = best_score_record["matchLevel"]
                features[lib_feat_id]["matchedFeatId"] = best_score_record["matchedFeatId"]
                features[lib_feat_id]["matchedFeatDesc"] = best_score_record["matchedFeatDesc"]
                features[lib_feat_id]["featBehavior"] = best_score_record["featBehavior"]

        return why_key, features

    # ---------------------------
    def why_set_match_score(self, feat_record):
        if "GNR_FN" in feat_record["ADDITIONAL_SCORES"]:
            match_score = feat_record["ADDITIONAL_SCORES"]["GNR_FN"]
            if "GNR_ON" in feat_record and feat_record["GNR_ON"] >= 0:
                match_score_display = "org:%s" % feat_record["GNR_ON"]
            else:
                # matchScoreDisplay = "full:%s" % featRecord["GNR_FN"]
                match_score_display = f"full:{feat_record['ADDITIONAL_SCORES']['GNR_FN']}"
                if "GNR_GN" in feat_record and feat_record["GNR_GN"] >= 0:
                    match_score_display += "|giv:%s" % feat_record["GNR_GN"]
                if "GNR_SN" in feat_record and feat_record["GNR_SN"] >= 0:
                    match_score_display += "|sur:%s" % feat_record["GNR_SN"]
        elif "BT_FN" in feat_record:
            match_score = feat_record["BT_FN"]
            if "BT_ON" in feat_record and feat_record["BT_ON"] > 0:
                match_score_display = "org:%s" % feat_record["BT_ON"]
            else:
                match_score_display = "full:%s" % feat_record["BT_FN"]
        else:
            match_score = feat_record["ADDITIONAL_SCORES"]["FULL_SCORE"]
            match_score_display = "full:" + str(feat_record["ADDITIONAL_SCORES"]["FULL_SCORE"])

        feat_record["MATCH_SCORE"] = match_score
        feat_record["MATCH_SCORE_DISPLAY"] = match_score_display

        return feat_record

    # ---------------------------
    def help_how(self):
        entity_id = colorize_entity("<entity_id>")
        print(
            textwrap.dedent(
                f"""\

            Shows shows how the records in a single entity came together.

            {colorize('Syntax:', 'highlight2')}
                how {entity_id}            {colorize('shows a summary of the resolution process', 'dim')}
                how {entity_id} concise    {colorize('shows the matching features as part of the tree view', 'dim')}
                how {entity_id} table  {colorize('shows the matching features in a table', 'dim')}

            {colorize('How to read:', 'highlight2')}
                A how report documents each step of the resolution process for an entity so if
                an entity has 100s records there will be 100s of steps. Each step will either
                create a virtual entity, add to it or combine it with other virtual entities
                that were created created along the way.

                For instance, there may be a set of records (a virtual entity) that match on name
                and address and another set that match on name and phone before a record with the
                same name, address and phone combines the two virtual entities into one!

            {colorize('Pro tip!', 'good')}
                The overview section helps you locate interesting resolution steps that you
                can search for in the concise or formatted view.  You can search for ...
                    - a particular step number such as step "2"
                    - a virtual entity_id such as {colorize_entity('V123-S2', 'dim')}
                        {colorize('(the -S number after the virtual entity ID is the step number that updated it.  Try', 'italics')}
                            {colorize('searching for just the V number before the dash to find all steps that include it.)', 'italics')}
                    - any other string such as a match_key, principle code, specific name, address, etc
             """
            )
        )

    # ---------------------------
    def do_how(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_how()
            return -1 if caller else 0

        how_display_level = "overview"
        for level in ["summary", "concise", "table", "verbose"]:
            if level in arg:
                how_display_level = level
                arg = arg.replace(level, "").strip()

        try:
            entity_id = int(arg)
        except:
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return -1 if caller else 0

        # do get first
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]

        try:
            get_entity_data = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0

        stat_pack = {
            "steps": {},
            "features": {},
            "rules": {},
            "ftype_counter": {},
            "rule_counter": {},
        }

        # build record feature matrix
        total_record_count = 0
        total_feature_count = 0
        features_by_record = {}
        for record_data in get_entity_data["RESOLVED_ENTITY"]["RECORDS"]:
            total_record_count += 1
            if record_data["DATA_SOURCE"] not in features_by_record:
                features_by_record[record_data["DATA_SOURCE"]] = {}
            features_by_record[record_data["DATA_SOURCE"]][record_data["RECORD_ID"]] = self.buildout_record_features(
                record_data["FEATURES"],
                get_entity_data["RESOLVED_ENTITY"]["FEATURES"],
            )

            # accumulate feature stats
            for lib_feat_id in features_by_record[record_data["DATA_SOURCE"]][record_data["RECORD_ID"]]:
                feature_data = features_by_record[record_data["DATA_SOURCE"]][record_data["RECORD_ID"]][lib_feat_id]
                ftype_id = feature_data["ftypeId"]
                counter_display = self.feature_counter_display(feature_data)
                feat_desc = f"{colorize(lib_feat_id, 'dim')}: {feature_data['featDesc']} {counter_display}"

                if ftype_id not in stat_pack["features"]:
                    stat_pack["features"][ftype_id] = {}
                if ftype_id not in stat_pack["ftype_counter"]:
                    stat_pack["ftype_counter"][ftype_id] = {}
                    stat_pack["ftype_counter"][ftype_id]["featureCount"] = 0
                    stat_pack["ftype_counter"][ftype_id]["candidateCapReached"] = 0
                    stat_pack["ftype_counter"][ftype_id]["scoringCapReached"] = 0
                    stat_pack["ftype_counter"][ftype_id]["scoringWasSuppressed"] = 0
                if feat_desc not in stat_pack["features"][ftype_id]:
                    total_feature_count += 1
                    stat_pack["features"][ftype_id][feat_desc] = 1
                    stat_pack["ftype_counter"][ftype_id]["featureCount"] += 1
                    for threshold in [
                        "candidateCapReached",
                        "scoringCapReached",
                        "scoringWasSuppressed",
                    ]:
                        if feature_data[threshold] == "Y":
                            stat_pack["ftype_counter"][ftype_id][threshold] += 1
                else:
                    stat_pack["features"][ftype_id][feat_desc] += 1

        how_flag_list = ["SZ_HOW_ENTITY_DEFAULT_FLAGS"]
        try:
            json_data = self.execute_sz_api("how_entity_by_entity_id", how_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0

        entity_name = get_entity_data["RESOLVED_ENTITY"].get("ENTITY_NAME", "name not mapped")
        how_header = (
            "\n"
            + colorize(
                f"How report for entity {colorize_entity(entity_id)}: {entity_name}",
                "table_title",
            )
            + "\n"
        )
        if (
            json_data["HOW_RESULTS"]["FINAL_STATE"].get("NEED_REEVALUATION", 0)
            or len(json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]) > 1
        ):
            final_entity_count = len(json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"])
            how_header += "\n" + colorize(f"{final_entity_count} final entities, reevaluation needed!", "bad") + "\n"
            # - maybe start with concise view if multiple
            # if how_display_level == 'overview'
            #     how_display_level = 'concise'

        # annotate steps and create aggregate dictionary
        stat_pack["largest_combine_steps"] = {}
        stat_pack["lowest_feature_scores"] = {}
        stat_pack["name_not_scored"] = []

        step_count = 0
        aggregate_nodes = {}
        resolution_steps = {}
        for step_data in json_data["HOW_RESULTS"]["RESOLUTION_STEPS"]:
            step_count += 1
            step_num = step_data["STEP"]

            step_data["MATCH_INFO"]["WHY_KEY"] = step_data["MATCH_INFO"]["MATCH_KEY"]
            step_data["MATCH_INFO"]["WHY_ERRULE_CODE"] = step_data["MATCH_INFO"]["ERRULE_CODE"]
            for virtual_entity_num in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]:
                default_side = (
                    "INBOUND"
                    if step_data["INBOUND_VIRTUAL_ENTITY_ID"] == step_data[virtual_entity_num]["VIRTUAL_ENTITY_ID"]
                    else "CANDIDATE"
                )
                step_data[virtual_entity_num].update(
                    self.get_virtual_entity_data(step_data[virtual_entity_num], features_by_record)
                )
                features = step_data[virtual_entity_num]["features"]
                why_key, features = self.why_add_match_info(features, step_data["MATCH_INFO"], default_side)
                step_data[virtual_entity_num]["features"] = features

            step_data["singleton_nodes"] = []
            step_data["aggregate_nodes"] = []
            for virtual_entity in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]:
                if step_data[virtual_entity]["node_type"] == "singleton":
                    step_data["singleton_nodes"].append(step_data[virtual_entity]["VIRTUAL_ENTITY_ID"])
                else:
                    step_data["aggregate_nodes"].append(step_data[virtual_entity]["VIRTUAL_ENTITY_ID"])

            if len(step_data["singleton_nodes"]) == 2:
                step_data["step_type"] = "Create virtual entity"
            elif len(step_data["aggregate_nodes"]) == 2:
                step_data["step_type"] = "Combine virtual entities"
                lowest_member_count = (
                    step_data["VIRTUAL_ENTITY_1"]["member_count"]
                    if step_data["VIRTUAL_ENTITY_1"]["member_count"] < step_data["VIRTUAL_ENTITY_2"]["member_count"]
                    else step_data["VIRTUAL_ENTITY_2"]["member_count"]
                )
                total_member_count = (
                    step_data["VIRTUAL_ENTITY_1"]["member_count"] + step_data["VIRTUAL_ENTITY_2"]["member_count"]
                )
                if lowest_member_count not in stat_pack["largest_combine_steps"]:
                    stat_pack["largest_combine_steps"][lowest_member_count] = [[step_num, total_member_count]]
                else:
                    stat_pack["largest_combine_steps"][lowest_member_count].append([step_num, total_member_count])
            else:
                step_data["step_type"] = "Add record to virtual entity"

            if step_data["step_type"] not in stat_pack["steps"]:
                stat_pack["steps"][step_data["step_type"]] = 1
            else:
                stat_pack["steps"][step_data["step_type"]] += 1

            step_data["MATCH_INFO"]["matchKey"] = step_data["MATCH_INFO"]["MATCH_KEY"]
            step_data["MATCH_INFO"]["ruleCode"] = self.getRule_desc(step_data["MATCH_INFO"]["ERRULE_CODE"])
            formatted_match_key, formatted_errule_code = colorize_match_data(step_data["MATCH_INFO"]).split("\n ")
            step_data["MATCH_INFO"]["formatted_match_key"] = formatted_match_key
            step_data["MATCH_INFO"]["formatted_errule_code"] = formatted_errule_code
            if formatted_errule_code not in stat_pack["rules"]:
                stat_pack["rules"][formatted_errule_code] = {}
                stat_pack["rule_counter"][formatted_errule_code] = 1
            else:
                stat_pack["rule_counter"][formatted_errule_code] += 1
            if formatted_match_key not in stat_pack["rules"][formatted_errule_code]:
                stat_pack["rules"][formatted_errule_code][formatted_match_key] = 1
            else:
                stat_pack["rules"][formatted_errule_code][formatted_match_key] += 1

            # format the features and find the lowest scoring
            for lib_feat_id in step_data["VIRTUAL_ENTITY_2"]["features"]:
                feature_data = step_data["VIRTUAL_ENTITY_2"]["features"][lib_feat_id]
                feature_data = self.why_format_feature(feature_data, step_data["MATCH_INFO"])
                step_data["VIRTUAL_ENTITY_2"]["features"][lib_feat_id] = feature_data

            name_was_scored = False
            for lib_feat_id in step_data["VIRTUAL_ENTITY_1"]["features"]:
                feature_data = step_data["VIRTUAL_ENTITY_1"]["features"][lib_feat_id]
                feature_data = self.why_format_feature(feature_data, step_data["MATCH_INFO"])
                step_data["VIRTUAL_ENTITY_1"]["features"][lib_feat_id] = feature_data

                ftype_id = feature_data["ftypeId"]
                ftype_code = feature_data["ftypeCode"]
                if feature_data.get("wasScored", "No") == "Yes" and ftype_code in step_data["MATCH_INFO"]["MATCH_KEY"]:
                    match_score = feature_data["matchScore"]
                    if ftype_id not in stat_pack["lowest_feature_scores"]:
                        stat_pack["lowest_feature_scores"][ftype_id] = {}
                    if match_score not in stat_pack["lowest_feature_scores"][ftype_id]:
                        stat_pack["lowest_feature_scores"][ftype_id][match_score] = [step_num]
                    else:
                        stat_pack["lowest_feature_scores"][ftype_id][match_score].append(step_num)
                    if ftype_code == "NAME":
                        name_was_scored = True
            if not name_was_scored:
                stat_pack["name_not_scored"].append(step_num)

            resolution_steps[step_num] = step_data
            new_virtual_id = step_data.get("RESULT_VIRTUAL_ENTITY_ID", None)
            if new_virtual_id:
                # if new_virtual_id in aggregate_nodes:
                # print(json.dumps(step_data, indent=4))
                # print(f'\nunexpected: multiple steps for {new_virtual_id} {step_num} and ' + aggregate_nodes[new_virtual_id]['final_step'])
                # input('wait')
                aggregate_nodes[new_virtual_id] = {
                    "final_step": step_num,
                    "all_steps": [],
                }

        # start from the end and combine the prior steps that just add another singleton
        orphan_final_entity_data = {}
        render_node_list = []
        for final_virtual_data in json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]:
            final_virtual_id = final_virtual_data["VIRTUAL_ENTITY_ID"]
            render_node_list.append({"node_id": final_virtual_id, "parent_node": "root", "step_num": 999999})

            current_aggregate_list = [final_virtual_id]
            while current_aggregate_list:
                current_node_id = current_aggregate_list[-1]

                # if there are no steps for this final node it became a orphan singleton
                if current_node_id not in aggregate_nodes:
                    orphan_final_entity_data[current_node_id] = self.get_virtual_entity_data(
                        final_virtual_data, features_by_record
                    )
                    current_aggregate_list.pop()
                else:
                    # keep going down chain until two singletons or two aggregates
                    aggregate_node_id = current_node_id
                    while True:
                        prior_step = aggregate_nodes[aggregate_node_id]["final_step"]
                        aggregate_nodes[current_node_id]["all_steps"].append(prior_step)
                        if len(resolution_steps[prior_step]["aggregate_nodes"]) == 1:
                            aggregate_node_id = resolution_steps[prior_step]["aggregate_nodes"][0]
                        else:
                            break

                    # if ended on step with two aggregates, each must be traversed
                    current_aggregate_list.pop()
                    if len(resolution_steps[prior_step]["aggregate_nodes"]) == 2:
                        for aggregate_node_id in resolution_steps[prior_step]["aggregate_nodes"]:
                            step_num = (
                                int(aggregate_node_id[aggregate_node_id.find("S") + 1 :])
                                if "S" in aggregate_node_id
                                else 0
                            )
                            current_aggregate_list.append(aggregate_node_id)
                            render_node_list.append(
                                {
                                    "node_id": aggregate_node_id,
                                    "parent_node": current_node_id,
                                    "step_num": step_num,
                                }
                            )

        # create overview tree
        summary_node = Node("summary")
        summary_node.node_desc = colorize("SUMMARY", "highlight1")

        resolution_node = Node("resolution")
        resolution_node.node_desc = self.how_format_statistic_header("RESOLUTION SUMMARY")
        summary_node.add_child(resolution_node)

        category_node = Node("steps")
        category_node.node_desc = self.how_format_statistic("Resolution steps", step_count)
        for item in stat_pack["steps"]:
            item_node = Node(item)
            item_node.node_desc = colorize(self.how_format_statistic(item, stat_pack["steps"][item]), "italics")
            category_node.add_child(item_node)
        resolution_node.add_child(category_node)

        interesting_step_list = []
        for step_num in stat_pack["name_not_scored"]:
            interesting_step_list.append([step_num, "name not scored"])
        for ftype_id in sorted(stat_pack["lowest_feature_scores"]):
            ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
            cntr = 0
            for lowest_score in sorted(stat_pack["lowest_feature_scores"][ftype_id]):
                if lowest_score < 90:
                    for step_num in stat_pack["lowest_feature_scores"][ftype_id][lowest_score]:
                        interesting_step_list.append([step_num, f"{ftype_code} scored {lowest_score}"])
                    cntr += 1
                if cntr == 2:
                    break
        cntr = 0
        for lowest_member_count in sorted(stat_pack["largest_combine_steps"], reverse=True):
            for large_step_info in sorted(
                stat_pack["largest_combine_steps"][lowest_member_count],
                key=lambda k: k[1],
                reverse=True,
            ):
                step_num = large_step_info[0]
                highest_member_count = large_step_info[1] - lowest_member_count
                interesting_step_list.append(
                    [
                        step_num,
                        f"Combines a group of {lowest_member_count} with a group of {highest_member_count}",
                    ]
                )
            cntr += 1
            if cntr == 2:
                break
        if interesting_step_list:
            interesting_step_data = {}
            for step_num, reason in interesting_step_list:
                if step_num not in interesting_step_data:
                    interesting_step_data[step_num] = [reason]
                else:
                    interesting_step_data[step_num].append(reason)

            category_node = Node("interesting steps")
            category_node.node_desc = self.how_format_statistic("Steps of interest", len(interesting_step_data))
            for step_num in sorted(interesting_step_data.keys()):
                step_prefix = f"Step {step_num} - "
                interesting_step_node = Node(step_num)
                interesting_step_node.node_desc = ""
                for reason in interesting_step_data[step_num]:
                    interesting_step_node.node_desc += step_prefix + reason
                    step_prefix = " " * len(step_prefix)
                category_node.add_child(interesting_step_node)
            resolution_node.add_child(category_node)

        category_node = Node("rules")
        category_node.node_desc = "Principles used"
        resolution_node.add_child(category_node)
        for rule_info in sorted(stat_pack["rule_counter"].items(), key=lambda item: item[1], reverse=True):
            rule = rule_info[0]
            rule_node = Node(rule)
            rule_cnt = colorize(f"({rule_info[1]})", "highlight2")
            rule_node.node_desc = f"{rule} {rule_cnt}"
            category_node.add_child(rule_node)
            for match_key_info in sorted(stat_pack["rules"][rule].items(), key=lambda item: item[1], reverse=True):
                match_key = match_key_info[0]
                match_key_node = Node(match_key)
                match_key_cnt = colorize(f"({match_key_info[1]})", "highlight2")
                match_key_node.node_desc = f"{match_key} {match_key_cnt}"
                rule_node.add_child(match_key_node)

        category_node = Node("entity")
        category_node.node_desc = self.how_format_statistic_header("ENTITY SUMMARY")
        summary_node.add_child(category_node)

        for stat_data in [
            ["Total record count", total_record_count],
            ["Total feature count", total_feature_count],
        ]:
            item_node = Node(stat_data[0])
            item_node.node_desc = self.how_format_statistic(stat_data[0], stat_data[1])
            category_node.add_child(item_node)

        for ftype_id in sorted(stat_pack["features"], key=lambda k: self.feature_sequence[k]):
            ftype_node = Node(ftype_id)
            ftype_cnt = colorize(
                f"({stat_pack['ftype_counter'][ftype_id]['featureCount']})",
                "highlight2",
            )
            ftype_node.node_desc = f"{colorize_attr(self.ftype_lookup[ftype_id]['FTYPE_CODE'])} {ftype_cnt}"
            category_node.add_child(ftype_node)
            feat_desc_info_list = sorted(
                stat_pack["features"][ftype_id].items(),
                key=lambda item: item[1],
                reverse=True,
            )
            cnt = 0
            for feat_desc_info in feat_desc_info_list:
                cnt += 1
                if cnt in (
                    1,
                    2,
                    len(feat_desc_info_list),
                    len(feat_desc_info_list) - 1,
                ):
                    feat_desc = feat_desc_info[0]
                    feat_node = Node(feat_desc)
                    feat_cnt = colorize(f"({feat_desc_info[1]})", "highlight2")
                    if any(i in feat_desc for i in ["[~", "[!", "[#"]):
                        feat_desc = colorize(feat_desc, "dim")
                    feat_node.node_desc = f"{feat_desc} {feat_cnt}"
                    ftype_node.add_child(feat_node)
                elif cnt == 3 and len(feat_desc_info_list) > 4:
                    ftype_node.add_child(Node("~~~"))

        # start rendering nodes based on requested view and filter
        tree_nodes = {}
        filter_str = None
        while True:
            tree_nodes["root"] = Node("root")
            tree_nodes["root"].node_desc = colorize("RESOLUTION STEPS", "bold")
            for render_node_data in sorted(render_node_list, key=lambda x: x["step_num"], reverse=True):
                render_node_id = render_node_data["node_id"]
                parent_node_id = render_node_data["parent_node"]

                # describe the node
                colored_node_id = colorize_entity(render_node_id)
                if parent_node_id == "root":
                    num_final_nodes = len(json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"])
                    final_node_index = 0
                    for final_state_data in json_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]:
                        final_node_index += 1
                        if final_state_data["VIRTUAL_ENTITY_ID"] == render_node_id:
                            break
                    if num_final_nodes == 1:
                        render_node_desc = colorize(f"{colored_node_id}: final entity", "dim")
                    else:
                        render_node_desc = colorize(
                            f"{colored_node_id}: final entity {final_node_index} of {num_final_nodes}",
                            "dim",
                        )
                else:
                    render_node_desc = colorize(f"{colored_node_id}: interim entity", "dim")

                tree_nodes[render_node_id] = Node(render_node_id)
                tree_nodes[render_node_id].node_desc = render_node_desc
                tree_nodes[parent_node_id].add_child(tree_nodes[render_node_id])
                tree_nodes[render_node_id].add_parent(tree_nodes[parent_node_id])

                # there are no prior steps, this final node is a singleton
                if render_node_id not in aggregate_nodes:
                    orphan_entity_data = orphan_final_entity_data[render_node_id]
                    step_node_id = f"orphan-{render_node_id}"
                    tree_nodes[step_node_id] = Node(step_node_id)
                    tree_nodes[step_node_id].node_desc = "Singleton"
                    tree_nodes[step_node_id].node_text = (
                        f"{orphan_entity_data['colored_desc']} {orphan_entity_data['entity_name']}"
                    )
                    tree_nodes[render_node_id].add_child(tree_nodes[step_node_id])
                    tree_nodes[step_node_id].add_parent(tree_nodes[render_node_id])

                # go through all the steps that built this node
                else:
                    for step_num in sorted(aggregate_nodes[render_node_id]["all_steps"], reverse=True):
                        step_data = resolution_steps[step_num]
                        step_node_id = f"Step {step_num}"
                        step_node_desc = step_node_id + ": " + step_data["step_type"]
                        step_node_desc += f" on {step_data['MATCH_INFO']['formatted_match_key']} {step_data['MATCH_INFO']['formatted_errule_code']}"

                        # always ensure lone singleton is on the left
                        if (
                            step_data["VIRTUAL_ENTITY_1"]["node_type"] != "singleton"
                            and step_data["VIRTUAL_ENTITY_2"]["node_type"] == "singleton"
                        ):
                            left_virtual_entity = "VIRTUAL_ENTITY_2"
                            right_virtual_entity = "VIRTUAL_ENTITY_1"
                        else:
                            left_virtual_entity = "VIRTUAL_ENTITY_1"
                            right_virtual_entity = "VIRTUAL_ENTITY_2"

                        left_features = step_data[left_virtual_entity]["features"]
                        right_features = step_data[right_virtual_entity]["features"]

                        # find the best matching record for each side
                        #  to make selection of best matching feature less arbitrary
                        left_matching_record_list = {}
                        right_matching_record_list = {}
                        for lib_feat_id in left_features:
                            if left_features[lib_feat_id].get("wasScored", "No") == "Yes":
                                for record_key in left_features[lib_feat_id]["record_list"]:
                                    if record_key not in left_matching_record_list:
                                        left_matching_record_list[record_key] = []
                                    left_matching_record_list[record_key].append(lib_feat_id)

                                matched_feat_id = left_features[lib_feat_id]["matchedFeatId"]
                                if matched_feat_id in right_features:
                                    for record_key in right_features[matched_feat_id]["record_list"]:
                                        if record_key not in right_matching_record_list:
                                            right_matching_record_list[record_key] = []
                                        right_matching_record_list[record_key].append(matched_feat_id)
                                else:
                                    record_key = "MISSING!"
                                    input(
                                        f"note1: step {step_num}, right side missing {lib_feat_id} {left_features[lib_feat_id].get('ftypeCode', '?')} \"{left_features[lib_feat_id].get('featDesc', '?')}\", press any key ..."
                                    )
                                    if record_key not in right_matching_record_list:
                                        right_matching_record_list[record_key] = []
                                    right_matching_record_list[record_key].append(matched_feat_id)

                        best_left_record_key = sorted(
                            sorted(
                                [
                                    {"key": i, "len": len(left_matching_record_list[i])}
                                    for i in left_matching_record_list
                                ],
                                key=lambda k: k["key"],
                            ),
                            key=lambda k: k["len"],
                            reverse=True,
                        )[0]["key"]
                        best_right_record_key = sorted(
                            sorted(
                                [
                                    {
                                        "key": i,
                                        "len": len(right_matching_record_list[i]),
                                    }
                                    for i in right_matching_record_list
                                ],
                                key=lambda k: k["key"],
                            ),
                            key=lambda k: k["len"],
                            reverse=True,
                        )[0]["key"]

                        # gather the features to display by type for each side
                        features_by_type = {}
                        for side_data in [
                            [
                                "left",
                                left_features,
                                right_features,
                                best_left_record_key,
                                best_right_record_key,
                            ],
                            [
                                "right",
                                right_features,
                                left_features,
                                best_right_record_key,
                                best_left_record_key,
                            ],
                        ]:
                            side = side_data[0]
                            features1 = side_data[1]
                            features2 = side_data[2]
                            best_record_key1 = side_data[3]
                            best_record_key2 = side_data[4]

                            for lib_feat_id in features1:
                                feature_data = features1[lib_feat_id]

                                ftype_id = feature_data["ftypeId"]
                                if ftype_id not in features_by_type:
                                    features_by_type[ftype_id] = {
                                        "left": [],
                                        "right": [],
                                    }

                                # get the best record keys for each side
                                matched_feat_id = feature_data.get("matchedFeatId")
                                if matched_feat_id:
                                    if best_record_key1 in features1[lib_feat_id]["record_list"]:
                                        feature_data["record_key1"] = best_record_key1
                                    else:
                                        feature_data["record_key1"] = features1[lib_feat_id]["record_list"][0]

                                    if matched_feat_id not in features2:
                                        feature_data["record_key2"] = "ERROR" + self.dsrc_record_sep + "MISSING"
                                        input(
                                            f"note: step {step_num}, {side} side missing {matched_feat_id} {feature_data.get('ftypeCode', '?')} \"{feature_data.get('featDesc', '?')}\", press any key ..."
                                        )

                                    else:
                                        if best_record_key2 in features2[matched_feat_id]["record_list"]:
                                            feature_data["record_key2"] = best_record_key2
                                        else:
                                            feature_data["record_key2"] = features2[matched_feat_id]["record_list"][0]

                                # skip unmatched if not showing full detail
                                elif how_display_level != "verbose":
                                    continue

                                features_by_type[ftype_id][side].append(feature_data)

                        colored_virtual_id1 = colorize_entity(
                            step_data[left_virtual_entity]["VIRTUAL_ENTITY_ID"], "dim"
                        )
                        colored_virtual_id2 = colorize_entity(
                            step_data[right_virtual_entity]["VIRTUAL_ENTITY_ID"], "dim"
                        )

                        if how_display_level == "concise":
                            step_node_desc += f"\n{colored_virtual_id1} {step_data[left_virtual_entity]['colored_desc']} {step_data[left_virtual_entity]['entity_name']}"
                            if not step_data["step_type"].startswith("Add"):
                                step_node_desc += f"\n{colored_virtual_id2} {step_data[right_virtual_entity]['colored_desc']} {step_data[right_virtual_entity]['entity_name']}"

                            step_node_text = ""
                            for ftype_id in sorted(
                                features_by_type.keys(),
                                key=lambda k: self.feature_sequence[k],
                            ):
                                for feature_data in sorted(
                                    sorted(
                                        features_by_type[ftype_id]["left"],
                                        key=lambda k: (k["featDesc"]),
                                    ),
                                    key=lambda k: (k["sortOrder"]),
                                ):
                                    color_ftype_code = colorize_attr(feature_data["ftypeCode"])
                                    color_record_key_1 = colorize_dsrc1(
                                        ": ".join(feature_data["record_key1"].split(self.dsrc_record_sep))
                                    )
                                    color_record_key_2 = colorize_dsrc1(
                                        ": ".join(feature_data["record_key2"].split(self.dsrc_record_sep))
                                    )
                                    colored_match_score = colorize(
                                        f"({feature_data['matchScoreDisplay']})",
                                        feature_data["featColor"],
                                    )
                                    step_node_text += f"{color_ftype_code}: {color_record_key_1} - {feature_data['featDesc']} | {color_record_key_2} - {feature_data['matchedFeatDesc']} {colored_match_score}\n"
                        elif how_display_level != "summary":
                            row_title = colorize("VIRTUAL_ID", "dim")
                            tbl_title = None
                            tbl_columns = []
                            tbl_columns.append({"name": row_title, "width": 20, "align": "left"})
                            tbl_columns.append(
                                {
                                    "name": colored_virtual_id1,
                                    "width": 70,
                                    "align": "left",
                                }
                            )
                            tbl_columns.append(
                                {
                                    "name": colorize("scores", "dim"),
                                    "width": 10,
                                    "align": "center",
                                }
                            )
                            tbl_columns.append(
                                {
                                    "name": colored_virtual_id2,
                                    "width": 70,
                                    "align": "left",
                                }
                            )
                            tbl_rows = []

                            row_title = colorize("DATA_SOURCES", "row_title")
                            tbl_row = [row_title]
                            for virtual_entity_data in [
                                [left_virtual_entity, best_left_record_key],
                                [right_virtual_entity, best_right_record_key],
                            ]:
                                virtual_entity = virtual_entity_data[0]
                                best_record_key = virtual_entity_data[1]
                                if step_data[virtual_entity]["node_type"] == "singleton":
                                    dsrc_display = step_data[virtual_entity]["colored_desc"]
                                else:
                                    dsrc_display = (
                                        step_data[virtual_entity]["node_desc"]
                                        + "\n best: "
                                        + colorize_dsrc1(": ".join(best_record_key.split(self.dsrc_record_sep)))
                                    )
                                tbl_row.append(dsrc_display)
                            tbl_row.insert(2, "")  # for score column
                            tbl_rows.append(tbl_row)

                            for ftype_id in sorted(
                                features_by_type.keys(),
                                key=lambda k: self.feature_sequence[k],
                            ):
                                if not features_by_type[ftype_id]["left"] and not features_by_type[ftype_id]["right"]:
                                    continue  # removes unscored if not full
                                ftype_code = self.ftype_lookup[ftype_id]["FTYPE_CODE"]
                                colored_ftype_code = colorize_attr(ftype_code)

                                # get the right side values
                                scored_right = {}
                                unscored_right = []
                                for feature_data in sorted(
                                    sorted(
                                        features_by_type[ftype_id]["right"],
                                        key=lambda k: (k["featDesc"]),
                                    ),
                                    key=lambda k: (k["sortOrder"]),
                                ):
                                    if feature_data.get("wasScored"):
                                        scored_right[feature_data["libFeatId"]] = feature_data
                                    else:
                                        unscored_right.append(feature_data["formattedFeatDesc1"])

                                # add all the scored ones from the lefts point of view
                                unscored_left = []
                                for feature_data in sorted(
                                    sorted(
                                        features_by_type[ftype_id]["left"],
                                        key=lambda k: (k["featDesc"]),
                                    ),
                                    key=lambda k: (k["sortOrder"]),
                                ):
                                    if feature_data.get("wasScored"):
                                        feature_score = "\n".join(
                                            colorize(item, feature_data["featColor"])
                                            for item in feature_data["matchScoreDisplay"].split("|")
                                        )

                                        feature_desc1 = feature_data["formattedFeatDesc1"]
                                        if step_data[left_virtual_entity]["node_type"] != "singleton":
                                            from_desc = "from: " + colorize_dsrc1(
                                                ": ".join(feature_data["record_key1"].split(self.dsrc_record_sep))
                                            )
                                            if feature_data["record_key1"] == best_left_record_key:
                                                from_desc = colorize(from_desc, "dim")
                                            feature_desc1 += "\n " + from_desc

                                        if feature_data["matchedFeatId"] not in scored_right:
                                            feature_desc2 = colorize(
                                                f"Internal error: {feature_data['matchedFeatId']} missing from {colored_virtual_id2}",
                                                "bad",
                                            )
                                            # input(feature_desc2 + ', press enter')
                                        else:
                                            feature_desc2 = scored_right[feature_data["matchedFeatId"]][
                                                "formattedFeatDesc1"
                                            ]
                                        if step_data[right_virtual_entity]["node_type"] != "singleton":
                                            from_desc = "from: " + colorize_dsrc1(
                                                ": ".join(feature_data["record_key2"].split(self.dsrc_record_sep))
                                            )
                                            if feature_data["record_key2"] == best_right_record_key:
                                                from_desc = colorize(from_desc, "dim")
                                            feature_desc2 += "\n " + from_desc

                                        tbl_rows.append(
                                            [
                                                colored_ftype_code,
                                                feature_desc1,
                                                feature_score,
                                                feature_desc2,
                                            ]
                                        )
                                    else:
                                        unscored_left.append(feature_data["formattedFeatDesc1"])

                                if unscored_right or unscored_left:
                                    tbl_rows.append(
                                        [
                                            colored_ftype_code,
                                            "\n".join(unscored_left),
                                            "",
                                            "\n".join(unscored_right),
                                        ]
                                    )

                            self.render_table(tbl_title, tbl_columns, tbl_rows, displayFlag="No")
                            step_node_text = self.current_render_string

                        tree_nodes[step_node_id] = Node(step_node_id)
                        tree_nodes[step_node_id].node_desc = step_node_desc
                        tree_nodes[step_node_id].node_text = step_node_text
                        tree_nodes[render_node_id].add_child(tree_nodes[step_node_id])
                        tree_nodes[step_node_id].add_parent(tree_nodes[render_node_id])

            if how_display_level == "overview":
                how_report = summary_node.render_tree(filter_str)
            elif tree_nodes["root"].children:  # will be no children if singleton
                if filter_str and filter_str.startswith("~node~"):
                    filter_str = filter_str[6:]
                    # steps don't actually have children, must go to the parent entity and show tree from there
                    if tree_nodes[filter_str].children:
                        parent_node = tree_nodes[filter_str]
                    else:
                        parent_node = tree_nodes[filter_str].parents[0]
                    if parent_node.parents:
                        parent_node = parent_node.parents[0]
                    if parent_node.node_id != "root":
                        temp_node = Node("~~~")
                    else:
                        temp_node = parent_node
                    temp_node.add_child(parent_node)
                    how_report = temp_node.render_tree(filter_str)
                elif len(tree_nodes["root"].children) > 1:
                    tree_nodes["root"].node_desc = "Final entities"
                    how_report = tree_nodes["root"].render_tree(filter_str)
                else:
                    how_report = tree_nodes["root"].children[0].render_tree(filter_str)
            else:
                how_report = "There are no resolution steps to display!"

            if filter_str and filter_str not in how_report:
                input(f"\n{filter_str} was not found, press enter to continue")
                filter_str = None
            else:
                self.current_render_string = (
                    how_header
                    + ("\nFiltered for " + colorize(filter_str, "fg_white,bg_red") + "\n" if filter_str else "")
                    + "\n"
                    + how_report
                )

            self.show_report("auto", search=filter_str, from_how_or_why=True)

            reply = input(colorize_prompt("\nSelect (O)verview, (C)oncise view, (T)able view, (S)earch or (Q)uit ... "))
            if reply:
                remove_from_history()
            else:
                continue

            if reply.upper() in ("Q", "QUIT"):
                break
            elif reply.upper() == ("O"):
                how_display_level = "overview"
                filter_str = None
            elif reply.upper() == ("C"):
                how_display_level = "concise"
            elif reply.upper() == ("T"):
                how_display_level = "table"
            elif reply.upper() == ("S"):
                if len(reply) > 1:
                    filter_str = reply[1:].strip()
                else:
                    filter_str = input(
                        "\nEnter a step number, a virtual entity ID, any other string or leave blank to clear filter ... "
                    )
                    remove_from_history()
            elif reply.isnumeric():
                filter_str = reply

            elif len(reply) > 1:
                filter_str = reply

            # check if they entered a valid step number
            if filter_str and filter_str.isnumeric():
                filter_str = f"Step {filter_str}"
                if filter_str not in tree_nodes:
                    input(f"\nStep {filter_str} not found, press enter to continue")
                    filter_str = None

            # check if they entered a node_id
            if filter_str and filter_str in tree_nodes:
                filter_str = f"~node~{filter_str}"

            if filter_str:
                how_display_level = "concise" if how_display_level == "overview" else how_display_level
        print()

        return

    # ---------------------------
    def get_virtual_entity_data(self, raw_virtual_entity_data, features_by_record):
        virtual_entity_data = {"id": raw_virtual_entity_data["VIRTUAL_ENTITY_ID"]}
        virtual_entity_data["record_count"] = 0
        virtual_entity_data["member_count"] = 0
        virtual_entity_data["records"] = {}
        virtual_entity_data["features"] = {}
        best_name_candidates = {"PRIMARY": "", "OTHER": ""}
        for member_data in raw_virtual_entity_data["MEMBER_RECORDS"]:
            virtual_entity_data["member_count"] += 1
            for record in sorted(member_data["RECORDS"], key=lambda k: k["DATA_SOURCE"] + k["RECORD_ID"]):
                virtual_entity_data["record_count"] += 1
                if record["DATA_SOURCE"] not in virtual_entity_data["records"]:
                    virtual_entity_data["records"][record["DATA_SOURCE"]] = []
                virtual_entity_data["records"][record["DATA_SOURCE"]].append(record["RECORD_ID"])

                # creates the master feature list for the virtual entity (accumulating which records have which features)
                record_key = record["DATA_SOURCE"] + self.dsrc_record_sep + record["RECORD_ID"]
                for lib_feat_id in features_by_record.get(record["DATA_SOURCE"], {}).get(record["RECORD_ID"], []):
                    if lib_feat_id not in virtual_entity_data["features"]:
                        virtual_entity_data["features"][lib_feat_id] = dict(
                            features_by_record[record["DATA_SOURCE"]][record["RECORD_ID"]][lib_feat_id]
                        )
                        virtual_entity_data["features"][lib_feat_id]["record_list"] = [record_key]
                    elif record_key not in virtual_entity_data["features"][lib_feat_id]["record_list"]:
                        virtual_entity_data["features"][lib_feat_id]["record_list"].append(record_key)

                    if virtual_entity_data["features"][lib_feat_id]["ftypeCode"] == "NAME":
                        this_name = virtual_entity_data["features"][lib_feat_id]["featDesc"]
                        this_usage_type = (
                            "PRIMARY"
                            if virtual_entity_data["features"][lib_feat_id]["usageType"] == "PRIMARY"
                            else "OTHER"
                        )
                        if len(this_name) > len(best_name_candidates[this_usage_type]):
                            best_name_candidates[this_usage_type] = this_name
        virtual_entity_data["entity_name"] = (
            best_name_candidates["PRIMARY"] if best_name_candidates["PRIMARY"] else best_name_candidates["OTHER"]
        )

        # a member is an obs_ent, despite how many records it has
        if len(raw_virtual_entity_data["MEMBER_RECORDS"]) == 1:
            additional_note = ""
            if virtual_entity_data["record_count"] > 1:  # its got additional pure dupes
                additional_note = colorize(
                    " +" + str(virtual_entity_data["record_count"] - 1) + " pure dupes",
                    "dim",
                )

            virtual_entity_data["node_type"] = "singleton"
            record = raw_virtual_entity_data["MEMBER_RECORDS"][0]["RECORDS"][0]
            virtual_entity_data["node_desc"] = record["DATA_SOURCE"] + ": " + record["RECORD_ID"] + additional_note
            virtual_entity_data["colored_desc"] = colorize_dsrc1(
                record["DATA_SOURCE"] + ": " + record["RECORD_ID"] + additional_note
            )

        else:
            virtual_entity_data["node_type"] = "aggregate"
            virtual_entity_data["node_desc"] = " | ".join(
                colorize_dsrc1(ds + " (" + str(len(virtual_entity_data["records"][ds])) + ")")
                for ds in sorted(virtual_entity_data["records"].keys())
            )
            virtual_entity_data["colored_desc"] = virtual_entity_data["node_desc"]

        return virtual_entity_data

    # ---------------------------
    def how_format_statistic_header(self, header):
        return colorize(header, "highlight2")

    # ---------------------------
    def how_format_statistic(self, stat, cnt):
        return stat + " " + colorize("(" + str(cnt) + ")", "highlight2")

    # ---------------------------
    def help_score(self):
        print(
            textwrap.dedent(
                f"""\

        Compares any two features and shows the scores returned.

        {colorize('Syntax:', 'highlight2')}
            score [{'{'}"name_last": "Smith", "name_first": "Joseph"{'}'}, {'{'}"name_last": "Smith", "name_first": "Joe"{'}'}]
            score [{'{'}"addr_full": "111 First St, Anytown, USA"{'}'}, {'{'}"addr_full": "111 First Street, Anytown"{'}'}]
            score [{'{'}"passport_number": "1231234", "passport_country": "US"{'}'}, {'{'}"passport_number": "1231234", "passport_country": "USA"{'}'}]

        {colorize('Notes:', 'highlight2')}
            Use the keyword "force" to force the two records to find each other by adding a trusted_id.
        """
            )
        )

    # ---------------------------
    def do_score(self, arg):
        if not arg:
            self.help_score()
            return

        force_trusted_id = "FORCE" in [x.upper() for x in arg.split()]
        if force_trusted_id:
            arg = " ".join([x for x in arg.split() if x.upper() != "FORCE"])

        try:
            json_data = json.loads(arg)
        except (ValueError, KeyError) as err:
            print_message(f"Invalid json parameter: {err}", "error")
            return

        if not isinstance(json_data, list) or len(json_data) != 2:
            print_message("json parameter must be a list of two features to compare", "error")
            return

        record1json = dict_keys_upper(json_data[0])
        record2json = dict_keys_upper(json_data[1])

        # use the test data source and entity type
        record1json["RECORD_TYPE"] = "SCORE_TEST"
        record2json["RECORD_TYPE"] = "SCORE_TEST"

        if force_trusted_id:
            record1json["TRUSTED_ID_TYPE"] = "SCORE"
            record1json["TRUSTED_ID_NUMBER"] = "TEST"
            record2json["TRUSTED_ID_TYPE"] = "SCORE"
            record2json["TRUSTED_ID_NUMBER"] = "TEST"

        # add the records
        try:
            self.sz_engine.add_record("TEST", "SCORE_RECORD_1", json.dumps(record1json))
            self.sz_engine.add_record("TEST", "SCORE_RECORD_2", json.dumps(record2json))
        except SzError as err:
            print_message(err, "error")
            return

        self.do_why("TEST SCORE_RECORD_1 TEST SCORE_RECORD_2")

        # delete the two temporary records
        try:
            self.sz_engine.delete_record("TEST", "SCORE_RECORD_1")
            self.sz_engine.delete_record("TEST", "SCORE_RECORD_2")
        except SzError as err:
            print_message(err, "error")
            return

        return

    # ---------------------------
    def help_assign(self):
        print(
            textwrap.dedent(
                f"""\

        Assigns records from a particular entity to a trusted_id in order to move them to another entity

        {colorize('Syntax:', 'highlight2')}
            assign <trusted_id_attribute> <trusted_id_value> to <entity_id> <name_spec>

        {colorize('Example:', 'highlight2')}
            assign trusted_id_number 1001 to 7 "ABC Company"
        """
            )
        )

    # ---------------------------
    def xx_assign(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_merge()
            return -1 if caller else 0

        if "," in arg:
            arg_list = next(csv.reader([arg], delimiter=",", quotechar='"', skipinitialspace=True))
        else:
            arg_list = next(csv.reader([arg], delimiter=" ", quotechar='"', skipinitialspace=True))

        if len(arg_list) != 5:
            print_message("Incorrect syntax (be sure to quote parameters with spaces)", "error")
            self.help_merge()
            return -1 if caller else 0

        trusted_id_type = arg_list[0]
        trusted_id_number = arg_list[1]
        from_entity_id = int(arg_list[3])
        name_spec = arg_list[4]

        get_entity_flags = [
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURE_IDS",
        ]

        try:
            entity_data = self.execute_sz_api("get_entity_by_entity_id", get_entity_flags, from_entity_id)
        except Exception as err:
            print_message(err, "error")
            return -1 if caller else 0

        qualifying_names = []
        qualifying_feature_ids = []
        for feature_data in entity_data["RESOLVED_ENTITY"]["FEATURES"].get("NAME", []):
            for values_data in feature_data["FEAT_DESC_VALUES"]:
                if name_spec.upper() in values_data["FEAT_DESC"].upper() or name_spec == "*":
                    qualifying_names.append(values_data["FEAT_DESC"])
                    qualifying_feature_ids.append(values_data["LIB_FEAT_ID"])

        if len(qualifying_names) == 0:
            print_message("No features with that name match this entity", "error")
            return -1 if caller else 0

        qualifying_records = []
        for record_data in entity_data["RESOLVED_ENTITY"]["RECORDS"]:
            if name_spec == "*":
                qualifying_records.append(record_data)
            else:
                for feature_data in record_data["FEATURES"]:
                    if feature_data["LIB_FEAT_ID"] in qualifying_feature_ids:
                        qualifying_records.append(record_data)
                        break

        if len(qualifying_records) == 0:
            print_message("No records with that name match this entity", "error")
            return -1 if caller else 0

        question = (
            f"\n{len(qualifying_feature_ids)} names affecting {len(qualifying_records)} records will be assigned, "
            "OK"
            " to proceed ..."
        )
        reply = input(question)
        if reply.upper() != "OK":
            print_message("Assign aborted", "warning")
            return -1 if caller else 0
        else:
            remove_from_history()

        print()
        for record_data in qualifying_records:
            data_source = record_data["DATA_SOURCE"]
            record_id = record_data["RECORD_ID"]
            json_data = dict(record_data["JSON_DATA"])
            json_data[trusted_id_type] = trusted_id_number
            print(f"updating {data_source}: {record_id} ...")
            try:
                self.sz_engine.add_record(data_source, record_id, json.dumps(json_data))
            except SzError as err:
                print_message(err, "error")
                break

        print("\nResulting entity ... \n")
        get_record_data = qualifying_records[0]["DATA_SOURCE"] + " " + qualifying_records[0]["RECORD_ID"]
        try:
            resolved_json = self.execute_sz_api("get_entity_by_record_id", [], get_record_data.split())
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0
        self.do_get(get_record_data)

    # ---------------------------
    def help_merge(self):
        print(
            textwrap.dedent(
                f"""\

        Merges any two entities or records.

        {colorize('Syntax:', 'highlight2')}
            merge 1, 2, "reason for merge"
            merge data_source1, record_id1, data_source2, record_id2, "reason for merge"
        """
            )
        )

    # ---------------------------
    def xx_merge(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_merge()
            return -1 if caller else 0

        feedback_data = {"type": "merge"}
        if "," in arg:
            arg_list = next(csv.reader([arg], delimiter=",", quotechar='"', skipinitialspace=True))
        else:
            arg_list = next(csv.reader([arg], delimiter=" ", quotechar='"', skipinitialspace=True))
        if len(arg_list) in (2, 4):
            reason = input("\nPlease provide a reason for the merge ... ")
            if reason:
                arg_list.append(f'"{reason}"')
                remove_from_history()
            else:
                print_message("Merge aborted, a reason is required", "warning")
                return -1 if caller else 0

        if len(arg_list) == 3:
            feedback_data["level"] = "entity"
            feedback_data["entity_id1"] = int(arg_list[0])
            feedback_data["entity_id2"] = int(arg_list[1])
            feedback_data["reason"] = arg_list[2]
        elif len(arg_list) == 5:
            feedback_data["level"] = "record"
            feedback_data["data_source1"] = arg_list[0]
            feedback_data["record_id1"] = arg_list[1]
            feedback_data["data_source2"] = arg_list[2]
            feedback_data["record_id2"] = arg_list[3]
            feedback_data["reason"] = arg_list[4]
        else:
            print_message("Invalid number of parameters", "error")
            self.help_merge()
            return -1 if caller else 0

        record_list = []
        get_record_flags = [
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FORMATTED_DATA",
        ]
        if feedback_data["level"] == "entity":
            get_entity_flags = [
                "SZ_ENTITY_INCLUDE_ENTITY_NAME",
                "SZ_ENTITY_INCLUDE_RECORD_DATA",
            ]

            try:
                resolved_json_1 = self.execute_sz_api(
                    "get_entity_by_entity_id",
                    get_entity_flags,
                    feedback_data["entity_id1"],
                )
                resolved_json_2 = self.execute_sz_api(
                    "get_entity_by_entity_id",
                    get_entity_flags,
                    feedback_data["entity_id2"],
                )
            except SzError as err:
                print_message(err, "error")
                return -1 if caller else 0

            entity_id1 = feedback_data["entity_id1"]
            entity_id2 = feedback_data["entity_id2"]
            entity_name1 = resolved_json_1["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_name2 = resolved_json_2["RESOLVED_ENTITY"]["ENTITY_NAME"]
            record_count1 = len(resolved_json_1["RESOLVED_ENTITY"]["RECORDS"])
            record_count2 = len(resolved_json_2["RESOLVED_ENTITY"]["RECORDS"])
            record_list += resolved_json_1["RESOLVED_ENTITY"]["RECORDS"]
            record_list += resolved_json_2["RESOLVED_ENTITY"]["RECORDS"]
            print(
                textwrap.dedent(
                    f"""\

            Merge:
                Entity {colorize_entity(entity_id1)}: {entity_name1} ({colorize_dsrc(str(record_count1) + ' records')})
                Entity {colorize_entity(entity_id2)}: {entity_name2} ({colorize_dsrc(str(record_count2) + ' records')})
                Reason: {feedback_data['reason']}
            """
                )
            )
            reply = input('Type "OK" to merge these entities ... ')
            if reply.upper() != "OK":
                print_message("Merge aborted", "warning")
                return -1 if caller else 0
            else:
                remove_from_history()

        else:
            record_list.append(
                {
                    "DATA_SOURCE": feedback_data["data_source1"],
                    "RECORD_ID": feedback_data["record_id1"],
                }
            )
            record_list.append(
                {
                    "DATA_SOURCE": feedback_data["data_source2"],
                    "RECORD_ID": feedback_data["record_id2"],
                }
            )

        # get merge log
        last_id = 0
        for record in self.feedback_log:
            last_id = record["id"] if record["id"] > last_id else last_id
        feedback_data["id"] = last_id + 1
        feedback_data["datetime"] = datetime.now().strftime("%m/%d/%Y %H:%M:%S")
        feedback_data["json_records"] = []
        feedback_data["record_list"] = []

        print("\nRecords:")
        for record_data in record_list:
            try:
                record_json = self.execute_sz_api(
                    "get_record",
                    get_record_flags,
                    [record_data["DATA_SOURCE"], record_data["RECORD_ID"]],
                )
            except SzError as err:
                print_message(err, "error")
                return -1 if caller else 0

            json_data = record_json["JSON_DATA"]
            # if 'DATA_SOURCE' not in json_data:
            #    json_data['DATA_SOURCE'] = record_data['DATA_SOURCE']
            # if 'RECORD_ID' not in json_data:
            #    json_data['RECORD_ID'] = record_data['RECORD_ID']
            feedback_data["json_records"].append(json_data)
            feedback_data["record_list"].append(
                {
                    "DATA_SOURCE": record_data["DATA_SOURCE"],
                    "RECORD_ID": record_data["RECORD_ID"],
                }
            )
            record_name = (
                record_json["NAME_DATA"][0] if len(record_json.get("NAME_DATA", [])) > 0 else "no name on record"
            )
            print(
                f"  {colorize_dsrc(record_json['DATA_SOURCE'] + ': ' + record_json['RECORD_ID'])} {colorize_attr(record_name)}"
            )
        if feedback_data["level"] != "entity":
            reply = input('\nType "OK" to merge these records ... ')
            if reply.upper() != "OK":
                print_message("Merge aborted", "warning")
                return -1 if caller else 0
            else:
                remove_from_history()

        print("\nMerging records ...")
        for json_data in feedback_data["json_records"]:
            new_json = dict(json_data)
            if "feedback" not in new_json:
                new_json["feedback"] = []
            new_json["feedback"].append(
                {
                    "TRUSTED_ID_TYPE": feedback_data["type"],
                    "TRUSTED_ID_NUMBER": feedback_data["id"],
                }
            )
            try:
                self.sz_engine.add_record(new_json["DATA_SOURCE"], new_json["RECORD_ID"], json.dumps(new_json))
            except SzError as err:
                print(str(err))
                break
                # --TODO: undo what was done

        print("\nResulting entity ... \n")
        get_record_data = (
            feedback_data["record_list"][0]["DATA_SOURCE"] + " " + feedback_data["record_list"][0]["RECORD_ID"]
        )
        try:
            resolved_json = self.execute_sz_api("get_entity_by_record_id", [], get_record_data.split())
        except SzError as err:
            print_message(err, "error")
            return -1 if caller else 0

        feedback_data["resulting_entity_id"] = resolved_json["RESOLVED_ENTITY"]["ENTITY_ID"]

        self.feedback_log.append(feedback_data)
        self.feedback_updated = True

        self.do_get(get_record_data)

    # ---------------------------
    def render_table(self, tbl_title, tbl_columns, tbl_rows, **kwargs):

        # display flags (start/append/done) allow for multiple tables to be displayed together and scrolled as one
        # such as an entity and its relationships

        # possible kwargs
        display_flag = kwargs.get("displayFlag")
        title_color = kwargs.get("titleColor", "table_title")
        title_justify = kwargs.get("titleJustify", "l")
        header_color = kwargs.get("headerColor", "column_header")
        combine_headers = kwargs.get("combineHeaders", False)

        # setup the table
        table_object = PrettyTable()
        # tableObject.title = tblTitle
        table_object.hrules = PRETTY_TABLE_ALL
        if PRETTYTABLE_STYLE_AVAILABLE:
            table_object.set_style(SINGLE_BORDER)
        else:
            table_object.horizontal_char = "\u2500"
            table_object.vertical_char = "\u2502"
            table_object.junction_char = "\u253C"

        field_name_list = []
        column_header_list = []
        for column_data in tbl_columns:
            field_name_list.append(column_data["name"])
            column_header_list.append(
                "\n".join(colorize(str(x), "column_header") for x in str(column_data["name"]).split("\n"))
            )
        table_object.field_names = field_name_list

        table_object.header = False  # make first row header to allow for stacked column header names
        table_object.add_row(column_header_list)

        total_row_cnt = 0
        for row in tbl_rows:
            total_row_cnt += 1
            row[0] = "\n".join([i for i in str(row[0]).split("\n")])
            table_object.add_row(row)

        # format with data in the table
        for column_data in tbl_columns:
            # tableObject.max_width[str(columnData['name'])] = columnData['width']
            table_object.align[column_data["name"]] = column_data["align"][0:1].lower()

        table_str = table_object.get_string()
        if combine_headers:
            table_str = self.combine_table_headers(table_str)

        # write to a file so can be viewed with less
        # also write to the lastTableData variable in case cannot write to file
        fmt_table_string = ""
        if tbl_title:
            fmt_table_string = colorize(tbl_title, title_color) + "\n"
        fmt_table_string += table_str + "\n"

        write_mode = "w"
        if display_flag in ("append", "end"):
            fmt_table_string = "\n" + fmt_table_string
            write_mode = "a"

        if write_mode == "w":
            self.current_render_string = fmt_table_string
        else:
            self.current_render_string = self.current_render_string + fmt_table_string

        # display if a single table or done accumulating tables to display
        if not display_flag or display_flag == "end":
            print("")
            self.show_report("auto")
            print("")
        return

    # ---------------------------
    def combine_table_headers(self, report_str):
        report = report_str.split("\n")
        col_sep = report[1][0]
        old_header1 = report[1].replace(Colors.COLUMN_HEADER, "").replace(Colors.RESET, "")
        colorize_characters_width = len(colorize("", "column_header"))
        headers1 = old_header1.split(col_sep)
        prior_header_len = 0
        new_header1 = col_sep
        new_header1_colored = col_sep
        for i in range(len(headers1)):
            if i > 0 and i < len(headers1) - 1:
                if (
                    i == len(headers1) - 2
                    or headers1[i].strip() != headers1[i - 1].strip()
                    or len(headers1[i - 1].strip()) == 0
                ):
                    if i == len(headers1) - 2:
                        prior_header_len += len(headers1[i]) + 1
                    if prior_header_len > 0:
                        new_header1 += f"{headers1[i-1]:^{prior_header_len-1}}{col_sep}"
                        new_header1_colored += f"{colorize(headers1[i-1], 'column_header'):^{prior_header_len-1+colorize_characters_width}}{col_sep}"
                        prior_header_len = 0
                prior_header_len += len(headers1[i]) + 1

        new_header0 = report[0]
        for i in range(len(old_header1)):
            if old_header1[i] == col_sep and new_header1[i] != col_sep:
                new_header0 = new_header0[0:i] + new_header0[i - 1] + new_header0[i + 1 :]

        new_report = [new_header0, new_header1_colored]
        new_report.extend(report[2:])

        return "\n".join(new_report)

    # ---------------------------
    def show_report(self, arg=None, **kwargs):
        if not self.current_render_string:
            return

        print()
        if self.current_review_list:
            self.current_render_string = (
                colorize(self.current_review_list, "bold") + "\n\n" + self.current_render_string
            )

        from_how_or_why = kwargs.get("from_how_or_why")
        if self.current_settings["auto_scroll"] == "off" and not from_how_or_why:
            screen_width = os.get_terminal_size()[0] - 1
            for line in self.current_render_string.split("\n"):
                if len(re.sub(r"\\x1b\[\d*;\d*;\d*m", "", line)) < screen_width:
                    print(f" {line}")
                else:
                    nline = ""
                    nline_len = 1
                    formatting = False
                    for char in line:
                        nline += char
                        if char == "\033":
                            formatting = True
                        elif formatting and char == "m":
                            formatting = False
                        elif not formatting:
                            nline_len += 1
                        if nline_len >= screen_width:
                            break
                    print(f" {nline}{Colors.RESET}")
            return

        # note: the F allows less to auto quit if output fits on screen
        #  if they purposely went into scroll mode, we should not auto-quit!
        if arg == "auto":
            less_options = "-FMXSR"
        else:
            less_options = "-MXSR"

        # --start with a search
        search = kwargs.get("search")
        if search:
            less_options + " /" + search

        # try pipe to less on small enough files (pipe buffer usually 1mb and fills up on large entity displays)
        less = subprocess.Popen(["less", less_options], stdin=subprocess.PIPE)
        with suppress(Exception):
            less.stdin.write(self.current_render_string.encode())
            less.stdin.close()
            less.wait()
        print()

    # -----------------------------
    def do_scroll(self, arg):
        print()
        if not self.current_render_string:
            return
        # TODO - Not used?
        if arg == "auto":
            lessOptions = "FMXSR"
        else:
            lessOptions = "MXSR"

        # try pipe to less on small enough files (pipe buffer usually 1mb and fills up on large entity displays)
        less = subprocess.Popen(["less", "-FMXSR"], stdin=subprocess.PIPE)
        try:
            less.stdin.write(self.current_render_string.encode())
        except IOError:
            pass
        less.stdin.close()
        less.wait()
        print()

    # ---------------------------
    def help_export(self):
        print(
            textwrap.dedent(
                f"""\

        Exports the json records that make up the selected entities for debugging, reloading, etc.

        {colorize('Syntax:', 'highlight2')}
            export <entity_id>, <entity_id> degree <n> to <fileName> additive
            export search to <fileName>
            export search <search index> to <fileName>\n
        """
            )
        )

    # ---------------------------
    def do_export(self, arg):
        caller = sys._getframe().f_back.f_code.co_name != "onecmd"
        if not arg:
            self.help_export()
            return -1 if caller else 0

        entity_list = []
        file_name = None
        max_degree = 0
        additive = False

        arg = arg.replace(",", " ")
        arglist = arg.split()
        i = 0
        while i < len(arglist):
            this_token = arglist[i].upper()
            next_token = arglist[i + 1] if i + 1 < len(arglist) else ""
            if this_token == "TO":
                if next_token:
                    file_name = next_token
                    i += 1

            elif this_token == "SEARCH":
                if next_token.isdigit():
                    if int(next_token) > len(self.last_search_result):
                        print_message("Invalid search index", "error")
                        return -1 if caller else 0
                    else:
                        # TODO What is lastToken? Errors if entering: export search 2
                        entity_list.append(self.last_search_result[int(lastToken) - 1])
                        i += 1
                else:
                    entity_list = self.last_search_result
            elif this_token == "DEGREE":
                if next_token.isdigit():
                    max_degree = int(next_token)
                    i += 1
            elif this_token.upper().startswith("ADD"):
                additive = True

            elif this_token.isdigit():
                entity_list.append(int(this_token))
            else:
                print_message(f"unknown command token: {this_token}", "warning")
            i += 1

        if not entity_list:
            print_message("No entities found", "warning")
            return

        if not file_name:
            if len(entity_list) == 1:
                file_name = str(entity_list[0]) + ".json"
            else:
                file_name = "records.json"
        try:
            f = open(file_name, "a" if additive else "w", encoding="utf-8")
        except IOError as err:
            print_message(err, "error")
            return

        get_flag_list = [
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
        ]
        if max_degree > 0:
            get_flag_list.append("SZ_ENTITY_INCLUDE_ALL_RELATIONS")

        exported_entity_list = []
        record_count = 0
        current_degree = 0
        current_entity_list = entity_list
        while current_degree <= max_degree:
            next_entity_list = []
            for entity_id in current_entity_list:
                exported_entity_list.append(entity_id)

                try:
                    json_data = self.execute_sz_api("get_entity_by_entity_id", get_flag_list, int(entity_id))
                except SzError as err:
                    print_message(err, "error")
                    return

                for record_data in json_data["RESOLVED_ENTITY"]["RECORDS"]:
                    f.write(json.dumps(record_data["JSON_DATA"]) + "\n")
                    record_count += 1

                if "RELATED_ENTITIES" in json_data:
                    for related_data in json_data["RELATED_ENTITIES"]:
                        if (
                            related_data["ENTITY_ID"] not in exported_entity_list
                            and related_data["ENTITY_ID"] not in next_entity_list
                        ):
                            next_entity_list.append(related_data["ENTITY_ID"])

            current_degree += 1
            if next_entity_list:
                current_entity_list = next_entity_list
            else:
                break

        f.close

        print_message(f"{record_count} records written to {file_name}", "success")

    # ---------------------------
    def getRule_desc(self, errule_code):
        return (
            "Principle " + str(self.errule_code_lookup[errule_code]["ERRULE_ID"]) + ": " + errule_code
            if errule_code in self.errule_code_lookup
            else ""
        )

    # ---------------------------
    def get_config_data(self, table, field=None, value=None):

        record_list = []
        for i in range(len(self.cfg_data["G2_CONFIG"][table])):
            if field and value:
                if self.cfg_data["G2_CONFIG"][table][i][field] == value:
                    record_list.append(self.cfg_data["G2_CONFIG"][table][i])
            else:
                # TODO Config change to SZ_CONFIG in V4?
                record_list.append(self.cfg_data["G2_CONFIG"][table][i])
        return record_list

    # ---------------------------
    def get_attribute_json(self, attribute_record):

        if "ADVANCED" not in attribute_record:
            attribute_record["ADVANCED"] = 0
        if "INTERNAL" not in attribute_record:
            attribute_record["INTERNAL"] = 0

        json_string = "{"
        json_string += '"id": "%s"' % attribute_record["ATTR_ID"]
        json_string += ', "attribute": "%s"' % attribute_record["ATTR_CODE"]
        json_string += ', "class": "%s"' % attribute_record["ATTR_CLASS"]
        json_string += ', "feature": "%s"' % attribute_record["FTYPE_CODE"]
        json_string += ', "element": "%s"' % attribute_record["FELEM_CODE"]
        json_string += ', "required": "%s"' % attribute_record["FELEM_REQ"].title()
        json_string += ', "default": "%s"' % attribute_record["DEFAULT_VALUE"]
        json_string += ', "advanced": "%s"' % ("Yes" if attribute_record["ADVANCED"] == 1 else "No")
        json_string += ', "internal": "%s"' % ("Yes" if attribute_record["INTERNAL"] == 1 else "No")
        json_string += "}"

        return json_string

    # ---------------------------
    def is_internal_attribute(self, attrStr):
        if ":" in attrStr:
            attrStr = attrStr.split(":")[0]
        attr_records = self.get_config_data("CFG_ATTR", "ATTR_CODE", attrStr.upper())
        if attr_records and attr_records[0]["INTERNAL"].upper().startswith("Y"):
            return True
        return False


# --------------------------------------
# def show_debug(call: str, output: str = "") -> None:
#     """# TODO"""
#     if debugOutput.upper() in ("S", "SCR", "SCREEN") and output:
#         print(f"- {call} -\n")
#         print(f"{output}\n")
#         return

#     try:
#         with open(debugOutput, "a", encoding="utf-8") as f:
#             f.write(f"- {call} -\n")
#             f.write(f"{output}\n\n")
#     except IOError as err:
#         print(f"cannot write to {debugOutput}: {err}")


# --------------------------------------
def fmt_statistic(amt):
    amt = int(amt)
    if amt > 1000000:
        return "{:,.2f}m".format(round(amt / 1000000, 2))

    return "{:,}".format(amt)


# --------------------------------------
def dict_keys_upper(dict):
    return {k.upper(): v for k, v in dict.items()}


# --------------------------------------
def remove_from_history(idx=0):
    if readline:
        if not idx:
            idx = readline.get_current_history_length() - 1
        readline.remove_history_item(idx)


# --------------------------------------
def _append_slash_if_dir(p):
    if p and os.path.isdir(p) and p[-1] != os.sep:
        return p + os.sep
    else:
        return p


def main() -> None:
    """main"""

    cli_args = parse_cli_args()

    snapshotFileName = cli_args.snapshot_file_name
    auditFileName = cli_args.audit_file_name

    # validate snapshot file if specified
    if snapshotFileName and not os.path.exists(snapshotFileName):
        print_message("Snapshot file not found", "error")
        sys.exit(1)

    # validate audit file if specified
    if auditFileName and not os.path.exists(auditFileName):
        print_message("Audit file not found", "error")
        sys.exit(1)

    splash = colorize("\n  ____|  __ \\     \\    \n", "DIM")
    splash += colorize("  __|    |   |   _ \\   ", "DIM") + "Senzing G2\n"
    splash += colorize("  |      |   |  ___ \\  ", "DIM") + "Exploratory Data Analysis\n"
    splash += colorize(" _____| ____/ _/    _\\ \n", "DIM")
    print(splash)

    # Check we can locate an engine configuration
    engine_config = get_engine_config(cli_args.ini_file_name)

    try:
        sz_abstract_factory = SzAbstractFactory("sz_explorer", engine_config, verbose_logging=cli_args.debugTrace)

    except SzError as err:
        print_message(err, "error")
        sys.exit(1)

    SzCmdShell(cli_args, sz_abstract_factory, engine_config).cmdloop()


if __name__ == "__main__":
    main()
