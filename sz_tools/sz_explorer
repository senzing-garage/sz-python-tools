#! /usr/bin/env python3

import argparse
import atexit
import cmd
import glob
import inspect
import json
import os
import pathlib
import re
import readline
import subprocess
import sys
import textwrap
import traceback
from contextlib import suppress
from typing import Any, Dict, List, Union

from _sz_database import SzDatabase
from _tool_helpers import (
    Colors,
    colorize_cmd_prompt,
    combine_engine_flags,
    get_char,
    get_char_with_prompt,
    get_engine_config,
)
from senzing import SzError
from senzing_core import SzAbstractFactoryCore

MODULE_NAME = pathlib.Path(__file__).stem
LF = "\n"
LFTAB = "\n\t"

try:
    import prettytable
except ImportError as ex:
    print(f"\n{ex}\nPlease install the Python prettytable module (e.g. pip install prettytable)")
    sys.exit(1)


def print_exception(ex):
    print_message(f"{ex}, press any key to continue", "error")
    if get_char() in "tTdD":
        print(traceback.format_exc())
        print()


def print_message(msg_text, msg_type_or_color=""):
    msg_type = ""
    if msg_type_or_color.upper() == "ERROR":
        msg_type = "ERROR:"
        msg_color = "FG_RED"
    elif msg_type_or_color.upper() == "WARNING":
        msg_type = "WARNING:"
        msg_color = "FG_YELLOW"
    elif msg_type_or_color.upper() == "INFO":
        msg_color = "FG_CYAN"
    elif msg_type_or_color.upper() == "SUCCESS":
        msg_color = "FG_GREEN"
    else:
        msg_color = msg_type_or_color
    if msg_type:
        print(f"\n{colorize(msg_type, msg_color)} {msg_text}\n")
    else:
        print(f"\n{colorize(msg_text, msg_color)}\n")


# -------------------
# colorizers
# -------------------


def colorize(in_string, color_list="None"):
    return Colors.apply(in_string, color_list) if color_list else in_string


def colorize_attr(attr_str, attr_color="attr_color"):
    if ":" in attr_str:
        attr_name = attr_str[0 : attr_str.find(":") + 1]
        attr_value = attr_str[attr_str.find(":") + 1 :].strip()
        return colorize(attr_name, attr_color) + " " + attr_value
    return colorize(attr_str, attr_color)


def colorize_dsrc(dsrc_str):
    if ":" in dsrc_str:
        return colorize_attr(dsrc_str, "dsrc_color")
    return colorize(dsrc_str, "dsrc_color")


def colorize_entity(entity_str, added_color=None):
    entity_color = "entity_color" + ("," + added_color if added_color else "")
    if ":" in str(entity_str):
        return colorize_attr(entity_str, entity_color)
    return colorize(entity_str, entity_color)


def colorize_match_key(match_key):
    if " (Ambiguous)" in match_key:
        match_key = match_key.replace(" (Ambiguous)", "")
        ambiguous_tag = " " + colorize("(Ambiguous)", "bad")
    else:
        ambiguous_tag = ""
    plus_keys = []
    minus_keys = []
    rel_keys = []
    prior_key = ""
    for key in re.split(r"(\+|\-)", match_key):
        if key in ("+", ""):
            prior_key = "+"
        elif key == "-":
            prior_key = "-"
        elif prior_key == "-":
            minus_keys.append(key)
        else:
            if "(" in key:
                rel_keys.append(key)
            else:
                plus_keys.append(key)
    colored_key = ""
    if plus_keys:
        colored_key += colorize("+".join(plus_keys), "good")
    if minus_keys:
        colored_key += colorize("-" + "-".join(minus_keys), "bad")
    if rel_keys:
        colored_key += colorize("+" + "+".join(rel_keys), "highlight2")

    return colored_key + ambiguous_tag


def wrap_text(_str, max_width, _color=None):
    if len(_str) < max_width or max_width < 1:
        return [colorize(_str, _color)]
    else:
        _list = []
        wrapper = textwrap.TextWrapper(width=max_width - 1)
        for line in wrapper.wrap(text=_str):
            prefix = " " if _list else ""
            _list.append(colorize(prefix + line, _color))
        return _list


def view_report(report, **kwargs):
    if kwargs.get("extra_header"):
        report = f'{kwargs["extra_header"]}\n\n{report}'
    print()
    if kwargs.get("no_scroll"):
        screen_width = os.get_terminal_size()[0] - 1
        for line in report.split("\n"):
            if len(re.sub(r"\\x1b\[\d*;\d*;\d*m", "", line)) < screen_width:
                print(f" {line}")
            else:
                nline = ""
                nline_len = 1
                formatting = False
                for char in line:
                    nline += char
                    if char == "\033":
                        formatting = True
                    elif formatting and char == "m":
                        formatting = False
                    elif not formatting:
                        nline_len += 1
                    if nline_len >= screen_width:
                        break
                print(f" {nline}{Colors.RESET}")
        return

    if kwargs.get("force_scroll"):
        less_options = "-MXSR"
    else:
        less_options = "-FMXSR"

    less = subprocess.Popen(["less", less_options], stdin=subprocess.PIPE)
    with suppress(Exception):
        less.stdin.write(report.encode())
        less.stdin.close()
        less.wait()
    print()


def scroll(report, **kwargs):
    print()
    less_options = "-MXSR"
    less = subprocess.Popen(["less", less_options], stdin=subprocess.PIPE)
    try:
        less.stdin.write(report.encode())
    except IOError:
        pass
    less.stdin.close()
    less.wait()
    print()


class eda_node(object):

    def __init__(self, node_id):
        self.node_id = node_id
        self.node_desc = node_id
        self.node_text = None
        self.node_data = None
        self.children = []
        self.parents = []
        self.counter1 = 0

    def add_child(self, obj):
        self.children.append(obj)

    def add_parent(self, obj):
        self.parents.append(obj)

    def render_tree(self):
        tree = ""
        tree += self.node_desc + "\n"
        if self.node_text:
            tree += self.node_text + "\n"
        parents = [{"node": self, "display_children": self.children}]
        while parents:
            if len(parents[-1]["display_children"]) == 0:
                parents.pop()
                continue
            next_node = parents[-1]["display_children"][0]
            parents[-1]["display_children"].pop(0)

            prefix = ""
            for i, _ in enumerate(parents):
                last_child = len(parents[i]["display_children"]) == 0
                if i < len(parents) - 1:  # prior level
                    prefix += "    " if last_child else "\u2502   "
                else:
                    prefix += "\u2514\u2500\u2500 " if last_child else "\u251c\u2500\u2500 "

            node_desc = next_node.node_desc
            for line in node_desc.split("\n"):
                tree += prefix + line + "\n"
                if prefix[-4:] == "\u251c\u2500\u2500 ":
                    prefix = prefix[0:-4] + "\u2502   "
                elif prefix[-4:] == "\u2514\u2500\u2500 ":
                    prefix = prefix[0:-4] + "    "

            if next_node.node_text:
                node_text = next_node.node_text
                for line in node_text.split("\n"):
                    tree += prefix + line + "\n"

            if next_node.children:
                prior_parents = [x["node"].node_id for x in parents]
                display_children = [x for x in next_node.children if x.node_id not in prior_parents]
                parents.append({"node": next_node, "display_children": display_children})

        return tree


class eda_table:
    def __init__(self):
        self.title = ""
        self.columns = []
        self.rows = []
        # self.border_style = "default"

    def hide_last_char(self, field_name):
        # INVISIBLE = "\033[08m"
        return field_name[0:-1] + "\033[08m" + field_name[-1] + "\033[0m"

    def render_table(self, **kwargs):
        org_mode = kwargs.get("org_mode")
        super_header = kwargs.get("super_header")
        no_lines = kwargs.get("no_lines")
        side_header = kwargs.get("side_header")
        table_object = prettytable.PrettyTable()

        if org_mode:
            table_object.horizontal_char = "\u2500"
            table_object.vertical_char = "\u2502"
            table_object.junction_char = "\u253c"
        else:
            if hasattr(prettytable, "TableStyle"):
                table_object.set_style(prettytable.TableStyle.SINGLE_BORDER)
            else:
                table_object.set_style(prettytable.SINGLE_BORDER)
        if not no_lines:
            if hasattr(prettytable, "HRuleStyle"):
                table_object.hrules = prettytable.HRuleStyle.ALL
            else:
                table_object.hrules = prettytable.ALL

        field_name_list = []
        column_header_list = []
        for column_data in self.columns:
            field_name_list.append(column_data["name"])
            if side_header and column_data["name"] != self.columns[0]["name"]:
                column_header_list.append("\n".join(str(x) for x in str(column_data["name"]).split("\n")))
            else:
                column_header_list.append(
                    "\n".join(Colors.apply(str(x), "column_header") for x in str(column_data["name"]).split("\n"))
                )
        table_object.field_names = field_name_list
        if not no_lines:
            table_object.header = False
            table_object.add_row(column_header_list)

        total_row_cnt = 0
        for row in self.rows:
            total_row_cnt += 1
            row[0] = "\n".join([i for i in str(row[0]).split("\n")])
            if side_header:
                row[0] = colorize(row[0], "column_header")
            table_object.add_row(row)

        for column_data in self.columns:
            table_object.align[column_data["name"]] = column_data["align"][0:1].lower()

        table_str = table_object.get_string()
        if super_header:
            table_str = self.combine_table_headers(table_str)
        if self.title:
            table_str = f"{Colors.apply(self.title, 'table_title')}\n{table_str}"

        return table_str + "\n"

    def combine_table_headers(self, report_str):
        report = report_str.split("\n")
        col_sep = report[1][0]
        old_header1 = report[1].replace(Colors.COLUMN_HEADER, "").replace(Colors.RESET, "")
        colorize_characters_width = len(Colors.apply("", "column_header"))
        headers1 = old_header1.split(col_sep)
        prior_header_len = 0
        new_header1 = col_sep
        new_header1_colored = col_sep
        for i in range(len(headers1)):
            if i > 0 and i < len(headers1) - 1:
                if (
                    i == len(headers1) - 2
                    or headers1[i].strip() != headers1[i - 1].strip()
                    or len(headers1[i - 1].strip()) == 0
                ):
                    if i == len(headers1) - 2:
                        prior_header_len += len(headers1[i]) + 1
                    if prior_header_len > 0:
                        new_header1 += f"{headers1[i-1]:^{prior_header_len-1}}{col_sep}"
                        padding = prior_header_len - 1 + colorize_characters_width
                        new_header1_colored += f"{Colors.apply(headers1[i-1], 'column_header'):^{padding}}{col_sep}"
                        prior_header_len = 0
                prior_header_len += len(headers1[i]) + 1
        new_header0 = report[0]
        for i in range(len(old_header1)):
            if old_header1[i] == col_sep and new_header1[i] != col_sep:
                new_header0 = new_header0[0:i] + new_header0[i - 1] + new_header0[i + 1 :]
        new_report = [new_header0, new_header1_colored]
        new_report.extend(report[2:])
        return "\n".join(new_report)


class EdaReports:

    def __init__(self, **kwargs):
        self.match_level_tags = {
            "MATCH": "Matches",
            "AMBIGUOUS_MATCH": "Ambiguous matches",
            "POSSIBLE_MATCH": "Possible matches",
            "POSSIBLE_RELATION": "Possibly related",
            "DISCLOSED_RELATION": "Disclosed relation",
        }
        self.audit_colors = {"MERGE": "good", "SPLIT": "bad", "SPLIT+MERGE": "fg_red,bg_green"}
        self.snapshot_data = None
        self.audit_data = None
        self.default_how_view = kwargs.get("default_how_view", "columnar")

    def fmt_statistic(self, amt):
        amt = int(amt)
        if amt > 1000000:
            return "{:,.2f}m".format(round(amt / 1000000, 2))
        return "{:,}".format(amt)

    def load_file(self, file_name):
        if not os.path.exists(file_name):
            raise Exception(f"{file_name} not found!")
        try:
            json_data = json.load(open(file_name))
        except Exception as ex:
            raise Exception(f"{file_name}: {ex}")
        if json_data.get("SOURCE") == "sz_snapshot":
            self.snapshot_file = file_name
            self.snapshot_data = json_data

        elif json_data.get("SOURCE") == "sz_audit":
            self.audit_file = file_name
            self.audit_data = json_data
        else:
            raise Exception(f"{file_name} not created by sz_snapshot or sz_audit", "error")

    def check_for_snapshot(self):
        if not self.snapshot_data:
            raise Exception("Please load a json file created with sz_snapshot to access this report")

    def review_features(self, entity_size, entity_data):
        if entity_size <= 5:  # super small
            review_max = 2
        elif entity_size <= 10:  # small
            review_max = 3
        elif entity_size <= 50:  # medium
            review_max = 10
        else:  # large
            review_max = 25
        review_features = []
        feature_counts = list(entity_data.values())[0]
        # (feature_counts)
        for ftype_code in feature_counts:
            ftype_excl = sdk_wrapper.ftype_code_lookup[ftype_code]["FTYPE_EXCL"]
            ftype_freq = sdk_wrapper.ftype_code_lookup[ftype_code]["FTYPE_FREQ"]
            ftype_count = feature_counts[ftype_code]
            if ftype_count > entity_size:  # a single record has reported multiple
                continue
            if ftype_excl == "Yes" and ftype_count > 1:
                review_features.append(ftype_code)
            elif ftype_freq in ("F1", "FF") and ftype_count > review_max:
                review_features.append(ftype_code)
        return review_features

    def show_audit_sample(self, audit_records, use_color=True):
        get_flag_list = ["SZ_ENTITY_INCLUDE_ALL_FEATURES", "SZ_ENTITY_INCLUDE_RECORD_FEATURES"]
        features_by_record = {}
        entity_list = set([x["NEWER_ID"] for x in audit_records])
        for entity_id in entity_list:
            if entity_id == "unknown":  # bypass missing
                continue
            try:
                json_data = sdk_wrapper.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                print_message(err, "error")
                continue
            entity_features = sdk_wrapper.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            for record in json_data["RESOLVED_ENTITY"]["RECORDS"]:
                record_key = record["RECORD_ID"] + "||" + record["DATA_SOURCE"]
                features = sdk_wrapper.get_record_features(entity_features, record["FEATURES"])["BY_TYPE"]
                features_by_record[record_key] = features

        ftypes_used = []
        for i in range(len(audit_records)):
            record_key = audit_records[i]["RECORD_ID"] + "||" + audit_records[i].get("DATA_SOURCE", "")
            if record_key in features_by_record:
                features = features_by_record[record_key]
            else:  # try to find by record_id alone (truthset key does not require data source)
                features = {}
                for record_key in features_by_record:
                    if record_key.startswith(audit_records[i]["RECORD_ID"] + "||"):
                        features = features_by_record[record_key]
                        break
            audit_records[i]["FEATURES"] = features
            ftypes_used.extend(list(features.keys()))
        ftypes_used = sorted(set(ftypes_used), key=lambda k: sdk_wrapper.ftype_code_order[k])

        tbl = eda_table()
        tbl.title = f'Audit Result ID {audit_records[0]["AUDIT_ID"]} {audit_records[0]["AUDIT_CATEGORY"]}'
        tbl.columns = [
            {"name": "DataSource", "width": 30, "align": "left"},
            {"name": "Record ID", "width": 30, "align": "left"},
            {"name": "Prior ID", "width": 20, "align": "left"},
            {"name": "Prior Score", "width": 75, "align": "left"},
            {"name": "Newer ID", "width": 20, "align": "left"},
            {"name": "Newer Score", "width": 75, "align": "left"},
            {"name": "Audit result", "width": 10, "align": "left"},
        ]
        for ftype_code in ftypes_used:
            tbl.columns.append({"name": ftype_code, "width": 50, "align": "left"})

        sort_order = {"same": 1, "new negative": 3, "new positive": 2, "missing": 4}
        local_colors = {
            "DSRC_COLOR": "dsrc_color" if use_color else None,
            "ENTITY_COLOR": "entity_color" if use_color else None,
            "NEW POSITIVE": self.audit_colors["MERGE"] if use_color else None,
            "NEW NEGATIVE": self.audit_colors["SPLIT"] if use_color else None,
            "MISSING": "CAUTION" if use_color else None,
        }

        tbl.rows = []
        for audit_record in sorted(
            audit_records,
            key=lambda k: [sort_order[k["AUDIT_RESULT"]], str(k["PRIOR_ID"]), k["NEWER_ID"]],
        ):
            result_color = local_colors.get(audit_record["AUDIT_RESULT"].upper(), "bold") if use_color else None
            row = [
                colorize(audit_record.get("DATA_SOURCE", ""), local_colors["DSRC_COLOR"]),
                audit_record["RECORD_ID"],
                audit_record["PRIOR_ID"],
                audit_record["PRIOR_SCORE"],
                colorize(audit_record["NEWER_ID"], local_colors["ENTITY_COLOR"]),
                audit_record["NEWER_SCORE"],
                colorize(audit_record["AUDIT_RESULT"], result_color),
            ]
            for ftype_code in ftypes_used:
                row.append("\n".join([x["FEAT_DESC"] for x in audit_record["FEATURES"].get(ftype_code, [])]))
            tbl.rows.append(row)

        if not use_color:  # if exporting report
            return tbl.columns, tbl.rows
        return tbl.render_table()

    def audit_summary(self):
        if not self.audit_data:
            print_message("Please load a json file created with sz_audit to view this report", "warning")
            return

        tbl = eda_table()
        tbl.title = f"Audit Summary from {self.audit_file}"
        tbl.columns = [
            {"name": tbl.hide_last_char("Statistic1"), "width": 25, "align": "left"},
            {"name": "Entities", "width": 25, "align": "right"},
            {"name": tbl.hide_last_char("Pairs1"), "width": 25, "align": "right"},
            {"name": tbl.hide_last_char("Statistic2"), "width": 25, "align": "left"},
            {"name": tbl.hide_last_char("Pairs2"), "width": 25, "align": "right"},
            {"name": tbl.hide_last_char("Statistic3"), "width": 25, "align": "left"},
            {"name": "Accuracy", "width": 25, "align": "right"},
        ]
        tbl.rows = []
        tbl.rows.append(
            [
                colorize("Prior Count", "highlight2"),
                self.fmt_statistic(self.audit_data["ENTITY"].get("PRIOR_COUNT", -1)),
                self.fmt_statistic(self.audit_data["PAIRS"].get("PRIOR_COUNT", -1)),
                colorize("Same Positives", "highlight2"),
                colorize(self.fmt_statistic(self.audit_data["PAIRS"]["SAME_POSITIVE"]), None),
                colorize("Precision", "highlight2"),
                colorize(self.audit_data["PAIRS"]["PRECISION"], None),
            ]
        )
        tbl.rows.append(
            [
                colorize("Newer Count", "highlight2"),
                self.fmt_statistic(self.audit_data["ENTITY"].get("NEWER_COUNT", -1)),
                self.fmt_statistic(self.audit_data["PAIRS"].get("NEWER_COUNT", -1)),
                colorize("New Positives", self.audit_colors["MERGE"]),
                colorize(self.fmt_statistic(self.audit_data["PAIRS"]["NEW_POSITIVE"]), None),
                colorize("Recall", "highlight2"),
                colorize(self.audit_data["PAIRS"]["RECALL"], None),
            ]
        )
        tbl.rows.append(
            [
                colorize("Common Count", "highlight2"),
                self.fmt_statistic(self.audit_data["ENTITY"].get("COMMON_COUNT", -1)),
                self.fmt_statistic(self.audit_data["PAIRS"].get("COMMON_COUNT", -1)),
                colorize("New Negatives", self.audit_colors["SPLIT"]),
                colorize(self.fmt_statistic(self.audit_data["PAIRS"]["NEW_NEGATIVE"]), None),
                colorize("F1 Score", "highlight2"),
                colorize(self.audit_data["PAIRS"]["F1-SCORE"], None),
            ]
        )
        report_table = tbl.render_table()

        report_data = {}
        for category in self.audit_data["AUDIT"]:
            report_data[category] = {
                "COUNT": self.audit_data["AUDIT"][category]["COUNT"],
                "MATCH_KEY": self.audit_data["AUDIT"][category]["SUB_CATEGORY"],
            }

        tbl = eda_table()
        tbl.title = "Review categories..."
        tbl.columns = [
            {"name": "Row", "width": 5, "align": "center"},
            {"name": "Category", "width": 25, "align": "left"},
            {"name": "Count", "width": 25, "align": "right"},
        ]
        tbl.rows = []
        row_num = 0
        for category in report_data:
            row_num += 1
            count = report_data[category]["COUNT"]
            tbl.rows.append(
                [
                    colorize(row_num, "bold"),
                    colorize(category, self.audit_colors.get(category, "caution")),
                    self.fmt_statistic(count),
                ]
            )
        report_table += "\n" + tbl.render_table()

        select_levels = ["CATEGORY", "MATCH_KEY"]
        self.drill_into(report_table, report_data, select_levels)

    def entity_size_breakdown(self):
        self.check_for_snapshot()
        report_data = {}
        for str_entity_size in sorted(self.snapshot_data["ENTITY_SIZES"].keys(), key=lambda k: int(k)):
            entity_size_data = self.snapshot_data["ENTITY_SIZES"][str_entity_size]
            entity_size = int(str_entity_size)
            entity_size_count = entity_size_data["COUNT"]
            if entity_size < 10:
                size_group = entity_size
            elif entity_size < 100:
                size_group = int(entity_size / 10) * 10
            else:
                size_group = int(entity_size / 100) * 100
            if size_group not in report_data:
                report_data[size_group] = {
                    "COUNT": entity_size_count,
                    "SAMPLE": [],
                    "REVIEW_COUNT": 0,
                    "REVIEW_FEATURES": [],
                }
            else:
                report_data[size_group]["COUNT"] += entity_size_count
            for entity_data in entity_size_data["SAMPLE"]:
                entity_id = list(entity_data.keys())[0]
                review_list = []
                if entity_size > 1:
                    review_list = self.review_features(entity_size, entity_data)
                    if review_list:
                        report_data[size_group]["REVIEW_COUNT"] += 1
                        for feature in review_list:
                            if feature not in report_data[size_group]["REVIEW_FEATURES"]:
                                report_data[size_group]["REVIEW_FEATURES"].append(feature)
                report_data[size_group]["SAMPLE"].append({entity_id: review_list})
        tbl = eda_table()
        tbl.title = f"Entity size breakdown from {self.snapshot_file}"
        tbl.columns = [
            {"name": "Row", "width": 5, "align": "center"},
            {"name": "Size Group", "width": 10, "align": "center"},
            {"name": "Entity Count", "width": 10, "align": "right"},
            {"name": "Review Count", "width": 10, "align": "right"},
            {"name": "Review Features", "width": 75, "align": "left"},
        ]
        tbl.rows = []
        row_num = 0
        for size_group in report_data:
            row_num += 1
            report_segment = report_data[size_group]
            row = [
                colorize(row_num, "bold"),
                size_group,
                report_segment["COUNT"],
                colorize(report_segment["REVIEW_COUNT"], "caution") if report_segment["REVIEW_COUNT"] else "",
                ", ".join(colorize(x, "caution") for x in report_segment["REVIEW_FEATURES"]),
            ]
            tbl.rows.append(row)
            report_data[size_group] = report_segment
        report_table = tbl.render_table()
        select_levels = ["ENTITY_SIZE_GROUP"]
        self.drill_into(report_table, report_data, select_levels)

    def data_source_summary(self, data_source_filter):
        self.check_for_snapshot()
        report_data = {}
        tbl = eda_table()
        tbl.title = f"Data Source Summary from {self.snapshot_file}"
        tbl.columns = [
            {"name": "\nRow", "width": 5, "align": "center"},
            {"name": "\nData Source", "width": 25, "align": "left"},
            {"name": "\nRecords", "width": 15, "align": "right"},
            {"name": "\nEntities", "width": 15, "align": "right"},
            {"name": "\nCompression", "width": 15, "align": "right"},
            {"name": "Matched\nRecords", "width": 15, "align": "right"},
            {"name": "Matched\nEntities", "width": 15, "align": "right"},
            {"name": "Related Entities\nAmbiguous Matches", "width": 15, "align": "right"},
            {"name": "Related Entities\nPossible Matches", "width": 15, "align": "right"},
            {"name": "Related Entities\nPossible Relationships", "width": 15, "align": "right"},
        ]
        tbl.rows = []
        row_num = 0
        for data_source in sorted(self.snapshot_data["DATA_SOURCES"]):
            if data_source_filter and data_source != data_source_filter.upper():
                continue
            row_num += 1
            report_segment = self.snapshot_data["DATA_SOURCES"][data_source]
            compression = 100 - (report_segment["ENTITY_COUNT"] / float(report_segment["RECORD_COUNT"]) * 100)
            row = [
                colorize(row_num, "bold"),
                colorize_dsrc(data_source),
                self.fmt_statistic(report_segment["RECORD_COUNT"]),
                self.fmt_statistic(report_segment["ENTITY_COUNT"]),
                f"{round(compression,2)}%",
                self.fmt_statistic(report_segment["MATCH"]["RECORD_COUNT"]),
                self.fmt_statistic(report_segment["MATCH"]["ENTITY_COUNT"]),
                self.fmt_statistic(report_segment["AMBIGUOUS_MATCH"]["RELATION_COUNT"]),
                self.fmt_statistic(report_segment["POSSIBLE_MATCH"]["RELATION_COUNT"]),
                self.fmt_statistic(report_segment["POSSIBLE_RELATION"]["RELATION_COUNT"]),
            ]
            tbl.rows.append(row)
            report_data[data_source] = {"COUNT": 0, "MATCH_LEVEL": {}}
            for match_level_tag in self.match_level_tags:
                match_level_desc = self.match_level_tags[match_level_tag]
                if match_level_tag == "MATCH":
                    match_level_count = report_segment[match_level_tag]["ENTITY_COUNT"]
                else:
                    match_level_count = report_segment[match_level_tag]["RELATION_COUNT"]
                if match_level_count:
                    report_data[data_source]["MATCH_LEVEL"][match_level_desc] = {
                        "COUNT": match_level_count,
                        "MATCH_KEY": report_segment[match_level_tag]["PRINCIPLES"],
                    }
        report_table = tbl.render_table(super_header=True)
        select_levels = ["DATA_SOURCE", "MATCH_LEVEL", "MATCH_KEY"]
        self.drill_into(report_table, report_data, select_levels)

    def cross_source_summary(self, data_source_filter):
        self.check_for_snapshot()
        report_data = {}
        tbl = eda_table()
        tbl.title = f"Cross Source Summary from {self.snapshot_file}"
        tbl.columns = [
            {"name": "\nRow", "width": 5, "align": "center"},
            {"name": "From\nData Source", "width": 25, "align": "center"},
            {"name": "To\nData Source", "width": 25, "align": "center"},
            {"name": "Matched\nRecords", "width": 15, "align": "right"},
            {"name": "Matched\nEntities", "width": 15, "align": "right"},
            {"name": "Related Entities\nAmbiguous Matches", "width": 15, "align": "right"},
            {"name": "Related Entities\nPossible Matches", "width": 15, "align": "right"},
            {"name": "Related Entities\nPossible Relationships", "width": 15, "align": "right"},
        ]
        tbl.rows = []
        row_num = 0
        for data_source_pair in sorted(self.snapshot_data["CROSS_SOURCES"]):
            data_source1, data_source2 = data_source_pair.split("||")
            if data_source_filter and data_source1 != data_source_filter.upper():
                continue
            row_num += 1
            report_segment = self.snapshot_data["CROSS_SOURCES"][data_source_pair]
            row = [
                colorize(row_num, "bold"),
                colorize_dsrc(data_source1),
                colorize_dsrc(data_source2),
                self.fmt_statistic(report_segment["MATCH"]["RECORD_COUNT"]),
                self.fmt_statistic(report_segment["MATCH"]["ENTITY_COUNT"]),
                self.fmt_statistic(report_segment["AMBIGUOUS_MATCH"]["RELATION_COUNT"]),
                self.fmt_statistic(report_segment["POSSIBLE_MATCH"]["RELATION_COUNT"]),
                self.fmt_statistic(report_segment["POSSIBLE_RELATION"]["RELATION_COUNT"]),
            ]
            tbl.rows.append(row)

            report_data[data_source_pair] = {"COUNT": 0, "MATCH_LEVEL": {}}
            for match_level_tag in self.match_level_tags:
                match_level_desc = self.match_level_tags[match_level_tag]
                if match_level_tag == "MATCH":
                    match_level_count = report_segment[match_level_tag]["ENTITY_COUNT"]
                else:
                    match_level_count = report_segment[match_level_tag]["RELATION_COUNT"]
                if match_level_count:
                    report_data[data_source_pair]["MATCH_LEVEL"][match_level_desc] = {
                        "COUNT": match_level_count,
                        "MATCH_KEY": report_segment[match_level_tag]["PRINCIPLES"],
                    }
        report_table = tbl.render_table(super_header=True)
        select_levels = ["DATA_SOURCES", "MATCH_LEVEL", "MATCH_KEY"]
        self.drill_into(report_table, report_data, select_levels)

    def entity_source_summary(self, data_source_filter):
        self.check_for_snapshot()
        report_data = {}
        tbl = eda_table()
        tbl.title = f"Entity Source Summary from {self.snapshot_file}"
        tbl.columns = [
            {"name": "Row", "width": 5, "align": "center"},
            {"name": "Data Sources", "width": 100, "align": "left"},
            {"name": "Entities", "width": 15, "align": "right"},
        ]
        tbl.rows = []
        row_num = 0
        _data = self.snapshot_data["ENTITY_SOURCES"]
        sorted_data = sorted(_data, key=lambda k: _data[k]["ENTITY_COUNT"], reverse=True)
        for data_sources in sorted_data:
            if data_source_filter and data_source_filter.upper() not in data_sources:
                continue
            row_num += 1
            report_segment = self.snapshot_data["ENTITY_SOURCES"][data_sources]
            row = [
                colorize(row_num, "bold"),
                colorize(" | ", "dim").join(colorize_dsrc(x) for x in data_sources.split("||")),
                self.fmt_statistic(report_segment.get("ENTITY_COUNT", 0)),
            ]
            tbl.rows.append(row)
            report_data[data_sources] = report_segment

        report_table = tbl.render_table()
        select_levels = ["DATA_SOURCES"]
        self.drill_into(report_table, report_data, select_levels)

    def principles_used_report(self):
        self.check_for_snapshot()
        report_data = {}
        report_segment = self.snapshot_data["TOTALS"]
        for match_level_tag in self.match_level_tags:
            match_level_desc = self.match_level_tags[match_level_tag]
            if match_level_tag == "MATCH":
                match_level_count = report_segment[match_level_tag]["ENTITY_COUNT"]
            else:
                match_level_count = report_segment[match_level_tag]["RELATION_COUNT"]
            if not match_level_count:
                continue
            if match_level_desc not in report_data:
                report_data[match_level_desc] = {"COUNT": match_level_count, "PRINCIPLE": {}}
            for principle_match_key in report_segment[match_level_tag]["PRINCIPLES"]:
                pmk_data = report_segment[match_level_tag]["PRINCIPLES"][principle_match_key]
                pmk_count = pmk_data["COUNT"]
                principle, match_key = principle_match_key.split("||")
                if principle not in report_data[match_level_desc]["PRINCIPLE"]:
                    report_data[match_level_desc]["PRINCIPLE"][principle] = {"COUNT": pmk_count, "MATCH_KEY": {}}
                else:
                    report_data[match_level_desc]["PRINCIPLE"][principle]["COUNT"] += pmk_count
                report_data[match_level_desc]["PRINCIPLE"][principle]["MATCH_KEY"][principle_match_key] = pmk_data

        tbl = eda_table()
        tbl.title = f"Principles Used Report from {self.snapshot_file}"
        tbl.columns = [
            {"name": "Row", "width": 5, "align": "center"},
            {"name": "Match level", "width": 25, "align": "left"},
            {"name": "Count", "width": 15, "align": "right"},
        ]
        tbl.rows = []
        row_num = 0
        for match_level in report_data.keys():
            row_num += 1
            row = [colorize(row_num, "bold"), match_level, self.fmt_statistic(report_data[match_level]["COUNT"])]
            tbl.rows.append(row)

        report_table = tbl.render_table()
        select_levels = ["MATCH_LEVEL", "PRINCIPLE", "MATCH_KEY"]
        self.drill_into(report_table, report_data, select_levels)

    def fmt_match_key_category(self, key, **kwargs):
        sep = kwargs.get("sep", "\n ")
        if "||" in key:
            errule_code, match_key = key.split("||")
        else:
            errule_code = ""
            match_key = key
        if not errule_code:
            return colorize_match_key(match_key) if "+" in match_key else match_key
        return f"{colorize_match_key(match_key)}{sep}{colorize(errule_code, 'dim')}"

    def drill_into(self, report_table, report_data, select_levels):
        report_levels = [[report_table, report_data, select_levels[0], ""]]
        summarized_match_key = 0
        while True:
            select_table, select_data, select_level, prior_keys = report_levels[-1]
            if select_table == "build":
                tbl = eda_table()
                tbl.title = f"Selected {prior_keys}"
                tbl.columns = [
                    {"name": "Row", "width": 5, "align": "center"},
                    {"name": select_level.lower(), "width": 100, "align": "left"},
                    {"name": "count", "width": 10, "align": "right"},
                ]
                row_num = 0
                if select_level in ("MATCH_KEY"):
                    keys = sorted(select_data.keys(), key=lambda k: select_data[k]["COUNT"], reverse=True)
                    summarized_data = {}
                    key_count = 0
                    for key in keys:
                        key_count += 1
                        if key_count < 10 or summarized_match_key == 2:
                            summarized_data[key] = select_data[key]
                        else:
                            summarized_match_key = 1
                            summarized_key = f"||{len(keys)-9} more match_keys"
                            if summarized_key not in summarized_data:
                                summarized_data[summarized_key] = select_data[key]
                            else:
                                summarized_data[summarized_key]["COUNT"] += select_data[key]["COUNT"]
                                summarized_data[summarized_key]["SAMPLE"] += select_data[key]["SAMPLE"]
                    select_data = summarized_data
                elif select_level == "PRINCIPLE":
                    select_data = dict(sorted(select_data.items()))

                for key in select_data.keys():
                    row_num += 1
                    if select_level == "MATCH_KEY":
                        formatted_key = self.fmt_match_key_category(key)
                    else:
                        formatted_key = key
                    item_count = select_data[key]["COUNT"]
                    tbl.rows.append([colorize(row_num, "bold"), formatted_key, item_count])
                select_table = tbl.render_table()

            view_report(select_table, no_scroll=True)
            # debug_print(f"{select_level} {summarized_match_key}")
            valid_responses = [str(n + 1) for n in range(len(select_data.keys()))] + ["Q"]
            if select_level == "ENTITY_SIZE_GROUP":
                valid_responses.extend(["R" + str(n + 1) for n in range(len(select_data.keys()))])
                selection = get_char_with_prompt(
                    'Select row number to review, "R" + row number for review items only, or <enter> if done... ',
                    valid_responses,
                )

            elif select_level == "MATCH_KEY" and summarized_match_key == 1:
                valid_responses.append("A")
                selection = get_char_with_prompt(
                    "Select row number to review, (A) for all match_keys, or <enter> if done... ",
                    valid_responses,
                )
            else:
                selection = get_char_with_prompt("Select row number to review or <enter> if done... ", valid_responses)
            if not selection:
                selection = "Q"

            review_filter = selection.upper().startswith("R")
            if review_filter:
                selection = selection[1:]

            if selection.upper().startswith("Q"):
                summarized_match_key = 0
                del report_levels[-1]
                if len(report_levels) == 0:
                    break
            elif selection.upper().startswith("A"):
                summarized_match_key = 2  # turns off summarization
            elif selection.isdigit() and 1 <= int(selection) <= len(select_data.keys()):
                selected_key = list(select_data.keys())[int(selection) - 1]
                if review_filter and "REVIEW_COUNT" in select_data[selected_key]:
                    sample = []
                    for entity_data in select_data[selected_key]["SAMPLE"]:
                        review_list = list(entity_data.items())[0][1]
                        if review_list:
                            sample.append(entity_data)
                    select_data[selected_key]["REVIEW"] = sample
                    select_data = select_data[selected_key]
                elif "SAMPLE" in select_data[selected_key]:
                    select_data = select_data[selected_key]
                else:
                    next_level = select_levels[len(report_levels)].upper()
                    select_data = select_data[selected_key][next_level]

                if select_level.startswith("DATA_SOURCE"):
                    prior_key = colorize_dsrc(selected_key)
                elif select_level == "MATCH_KEY":
                    prior_key = self.fmt_match_key_category(selected_key, sep=" ")
                elif isinstance(selected_key, int):
                    prior_key = f"{select_level} {selected_key}"
                else:
                    prior_key = selected_key
                prior_keys += " " + prior_key if prior_keys else prior_key

                if "SAMPLE" in select_data:
                    sample_records = select_data["REVIEW"] if review_filter else select_data["SAMPLE"]
                    if len(sample_records) == 0:
                        get_char_with_prompt("\nNo samples found, press any key to continue...")
                        continue
                    if isinstance(sample_records[0], dict):  # from entity_size_breakdown
                        sample_records = sorted(sample_records, key=lambda d: list(d.keys())[0])
                    elif not isinstance(sample_records[0], list):  # not from audit_summary as it can't be sorted
                        sample_records = sorted(select_data["SAMPLE"])
                    self.browse_list(prior_keys, sample_records)
                else:
                    select_level = select_levels[len(report_levels)]
                    report_levels.append(["build", select_data, select_level, prior_keys])
                    if select_level == "match_key":
                        summarized_match_key = 0

    def get_ambiguous_entity_set(self, entity_id):
        # get other ambiguous relationships if this is the ambiguous entity
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data_2 = sdk_wrapper.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            print_message(err, "error")
            return None

        ambiguous_entity = "AMBIGUOUS_ENTITY" in json_data_2["RESOLVED_ENTITY"]["FEATURES"]
        if ambiguous_entity and "RELATED_ENTITIES" in json_data_2:
            entity_set = []
            for related_entity in json_data_2["RELATED_ENTITIES"]:
                if related_entity["IS_AMBIGUOUS"] != 0:
                    entity_set.append(str(related_entity["ENTITY_ID"]))
            if len(entity_set) > 1:
                return [entity_id] + entity_set
        return None

    def browse_list(self, list_header, list_records):
        list_count = len(list_records)
        current_index = 0
        while True:
            item_header = colorize(f"Sample {current_index + 1} of {list_count} in {list_header}", "bold")
            if isinstance(list_records[current_index], list):  # from audit_summary
                entity_list = list(set([x["NEWER_ID"] for x in list_records[current_index]]))
                entity_list = [x for x in entity_list if x.isdigit()]  # must remove "unknown" from audit
                report = self.show_audit_sample(list_records[current_index])
            else:
                if isinstance(list_records[current_index], dict):  # from entity_size breakdown
                    entity_id, review_list = list(list_records[current_index].items())[0]
                    entity_list = [entity_id]
                    if review_list:
                        item_header += colorize(f", review for {','.join(review_list)}", "bold")
                else:  # from source_summaries
                    entity_list = str(list_records[current_index]).split()

                if len(entity_list) == 1:
                    report = sdk_wrapper.get_entity(entity_list, show_detail=True)
                else:
                    if "Ambiguous" in list_header:
                        for this_entity_id in entity_list:
                            ambiguous_list = self.get_ambiguous_entity_set(this_entity_id)
                            if ambiguous_list:
                                entity_list = ambiguous_list
                                break
                    report = sdk_wrapper.compare_entities(entity_list)
            view_report(report, no_scroll=True, extra_header=item_header)

            valid_responses = ["P", "N", "G", "S", "Q", "E", "C"]
            if len(entity_list) == 1:
                prompt = "Select (P)revious, (N)ext, (G)oto, (H)ow, (E)xport, (S)croll, (Q)uit..."
                valid_responses += ["D", "H"]
            else:
                prompt = "Select (P)revious, (N)ext, (G)oto, (W)hy, (E)xport, (S)croll, (Q)uit..."
                valid_responses += ["W"]
            for char in valid_responses:
                prompt = prompt.replace(f"({char})", f"({Colors.apply(char, 'bold')})")
            reply = get_char_with_prompt(prompt, valid_responses)
            if reply:
                if reply.isdigit():
                    reply = "G" + reply
            else:
                reply = "N"

            if reply.upper().startswith("Q"):
                break
            elif reply.upper() == "S":
                scroll(report)
            elif reply.upper().startswith("P"):
                if current_index == 0:
                    get_char_with_prompt("\nNo prior records, press any key to continue...")
                else:
                    current_index = current_index - 1
            elif reply.upper().startswith("N"):
                if current_index == list_count - 1:
                    get_char_with_prompt("\nNo more records, press any key to continue...")
                else:
                    current_index = current_index + 1
            elif reply.upper().startswith("G"):
                reply = reply[1:]
                if not reply:
                    reply = input("\nSample item number to go to? ")
                    if reply:
                        remove_from_history()
                if reply:
                    if reply.isnumeric() and int(reply) > 0 and int(reply) <= list_count:
                        current_index = int(reply) - 1
                    else:
                        get_char_with_prompt("\nInvalid item number, press any key to continue...")
            elif reply.upper().startswith("W"):
                if len(entity_list) == 2:
                    report = sdk_wrapper.why_not(entity_list)
                else:
                    report = sdk_wrapper.why_not_many(entity_list)
                view_report(report, force_scroll=True)
            elif reply.upper().startswith("H"):
                sdk_wrapper.how_viewer(int(entity_list[0]), how_view=self.default_how_view, force_scroll=True)
            elif reply.upper().startswith("E"):
                additive = False
                file_name = f"{'-'.join(entity_list)}.jsonl"
                token_list = reply.split()
                for i, token in enumerate(token_list):
                    next_token = token_list[i + 1] if i + 1 < len(token_list) else None
                    if token.lower() == "additive":
                        additive = True
                    elif token.lower() == "to" and next_token:
                        file_name = next_token
                json_lines = sdk_wrapper.export_records(entity_list, degree=0)
                if json_lines:
                    with open(file_name, "a" if additive else "w", encoding="utf-8") as f:
                        f.write("\n".join(json_lines) + "\n")
                    get_char_with_prompt(
                        f"\n{len(json_lines)} records written to {file_name}, press any key to continue ..."
                    )


class EdaSdkWrapper:

    def __init__(self, engine_config, **kwargs):
        self.webapp_url = kwargs.get("webapp_url")
        self.debug_trace = kwargs.get("debug_trace")
        try:
            self.sz_factory = SzAbstractFactoryCore(MODULE_NAME, engine_config, verbose_logging=self.debug_trace)
            self.sz_engine = self.sz_factory.create_engine()
            self.sz_diagnostic = self.sz_factory.create_diagnostic()
            sz_product = self.sz_factory.create_product()
            self.sdk_version = json.loads(sz_product.get_version())
            sz_configmgr = self.sz_factory.create_configmanager()
            sz_config = sz_configmgr.create_config_from_config_id(sz_configmgr.get_default_config_id())
            sz_config_data = json.loads(sz_config.export())

        except SzError as err:
            raise Exception(err)

        self.dsrc_lookup = {item["DSRC_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_DSRC"]}
        self.dsrc_code_lookup = {item["DSRC_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_DSRC"]}
        self.errule_lookup = {item["ERRULE_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_ERRULE"]}
        self.errule_code_lookup = {item["ERRULE_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_ERRULE"]}
        self.ftype_lookup = {item["FTYPE_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_FTYPE"]}
        self.ftype_code_lookup = {item["FTYPE_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_FTYPE"]}
        self.felem_code_lookup = {item["FELEM_CODE"]: item for item in sz_config_data["G2_CONFIG"]["CFG_FELEM"]}
        self.cfunc_lookup = {item["CFUNC_ID"]: item for item in sz_config_data["G2_CONFIG"]["CFG_CFUNC"]}
        self.errule_code_lookup["DISCLOSED"] = {"ERRULE_ID": 0}

        # supplement feature code lookup with attribute details
        for item in sz_config_data["G2_CONFIG"]["CFG_ATTR"]:
            if item.get("FTYPE_CODE"):
                # self.ftype_code_lookup[item["FTYPE_CODE"]]["ATTR_CLASS"] = item["ATTR_CLASS"]
                if "ATTRIBUTES" not in self.ftype_code_lookup[item["FTYPE_CODE"]]:
                    self.ftype_code_lookup[item["FTYPE_CODE"]]["ATTRIBUTES"] = {}
                self.ftype_code_lookup[item["FTYPE_CODE"]]["ATTRIBUTES"][item["FELEM_CODE"]] = item

        # supplement feature code lookup with scoring code
        for item in sorted(sz_config_data["G2_CONFIG"]["CFG_CFCALL"], key=lambda k: k["FTYPE_ID"]):
            ftype_code = self.ftype_lookup[item["FTYPE_ID"]]["FTYPE_CODE"]
            cfunc_code = self.cfunc_lookup[item["CFUNC_ID"]]["CFUNC_CODE"]
            self.ftype_code_lookup[ftype_code]["CFUNC_CODE"] = cfunc_code

        self.senzing_features = ["CONFUSED_ENTITY", "AMBIGUOUS_ENTITY"]
        # supplement feature code lookup with sort order (scored features first)
        for ftype_code in self.ftype_code_lookup:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            if ftype_code in self.senzing_features:
                self.ftype_code_lookup[ftype_code]["SORT_ORDER"] = 10000 + ftype_id
            elif self.ftype_code_lookup[ftype_code].get("CFUNC_CODE"):
                self.ftype_code_lookup[ftype_code]["SORT_ORDER"] = 20000 + ftype_id
            else:
                self.ftype_code_lookup[ftype_code]["SORT_ORDER"] = 30000 + ftype_id

        self.ambiguous_ftype_id = self.ftype_code_lookup["AMBIGUOUS_ENTITY"]["FTYPE_ID"]
        # self.ftype_code_lookup["AMBIGUOUS_ENTITY"]["SORT_ORDER"] = 1

        self.ftype_id_order = {}
        self.ftype_code_order = {}
        for ftype_code in self.ftype_code_lookup:
            ftype_id = self.ftype_code_lookup[ftype_code]["FTYPE_ID"]
            sort_order = self.ftype_code_lookup[ftype_code]["SORT_ORDER"]
            self.ftype_id_order[ftype_id] = sort_order
            self.ftype_code_order[ftype_code] = sort_order

        self.match_category_sort = {
            "MATCH": 1,
            "AMBIGUOUS_MATCH": 2,
            "POSSIBLE_MATCH": 3,
            "POSSIBLY_RELATED": 4,
            "DISCLOSED_RELATION": 5,
        }
        self.match_category_desc = {
            "MATCH": "Resolved match",
            "AMBIGUOUS_MATCH": "Ambiguous match",
            "POSSIBLE_MATCH": "Possible match",
            "POSSIBLY_RELATED": "Possibly related",
            "DISCLOSED_RELATION": "Disclosed relation",
        }
        self.last_command = None
        self.last_call_cache = []

        self.how_views = {"T": "tree", "S": "summary", "C": "columnar"}

    def begin_call_cache(self, cmd):
        self.last_command = cmd
        self.last_call_cache = []

    def export_call_cache(self):
        cntr = 0
        report = f"\nCOMMAND RUN: {self.last_command}, {len(self.last_call_cache)} call(s) made\n"
        for caller, api_name, flags, parms, response_data in self.last_call_cache:
            cntr += 1
            parm_list = []
            for parm in parms:
                if str(parm).startswith("{"):
                    parm_list.append(f"\n{json.dumps(json.loads(parm), indent=4)}")
                else:
                    parm_list.append(str(parm))
            report += f"\ncall {cntr}: {api_name}({', '.join(parm_list)})\n"
            if flags:
                report += "flags:\n"
                for flag in flags:
                    report += f"\t{flag}\n"
            report += "response:\n"
            report += json.dumps(response_data, indent=4) + "\n"

        return report

    def call_sdk(
        self, api_name: str, flags: List[str], parms: Union[List[Union[str, int]], int, str]
    ) -> Dict[str, Any]:
        parms = parms if isinstance(parms, list) else [parms]
        caller = inspect.stack()[1].function
        try:
            flags_int = combine_engine_flags(flags)
            parms.append(flags_int)
            api_call = getattr(self.sz_engine, api_name)
            response = api_call(*parms)
            response_data: Dict[str, Any] = json.loads(response)
        except SzError as err:
            raise SzError(f"{api_name}: {err}") from None

        self.last_call_cache.append([caller, api_name, flags, parms, response_data])

        return response_data

    # sdk reformatters

    def get_entity_features(self, feature_data):
        features_by_id = {}
        features_by_type = {}
        for ftype_code in feature_data:
            features_by_type[ftype_code] = []
            for distinct_feat_record in feature_data[ftype_code]:
                distinct_usage_type = distinct_feat_record.get("USAGE_TYPE", "")
                # search request does contain feat_desc_values
                if not distinct_feat_record.get("FEAT_DESC_VALUES"):
                    distinct_feat_record["FEAT_DESC_VALUES"] = [distinct_feat_record]
                for feat_record in distinct_feat_record["FEAT_DESC_VALUES"]:
                    feat_record = feat_record.copy()
                    feat_record["FTYPE_CODE"] = ftype_code
                    feat_record["USAGE_TYPE"] = feat_record.get("USAGE_TYPE", distinct_usage_type)
                    if feat_record["USAGE_TYPE"] == "PRIMARY":
                        feat_record["USAGE_TYPE_SORT"] = "1-PRIMARY"
                    elif feat_record["USAGE_TYPE"]:
                        feat_record["USAGE_TYPE_SORT"] = f"2-{feat_record['USAGE_TYPE']}"
                    else:
                        feat_record["USAGE_TYPE_SORT"] = "3-UNSPECIFIED"
                    lib_feat_id = feat_record["LIB_FEAT_ID"]
                    if lib_feat_id in features_by_id:  # may be a different usage type
                        usage_type1 = features_by_id[lib_feat_id].get("USAGE_TYPE", "")
                        usage_type2 = feat_record.get("USAGE_TYPE", "")
                        if usage_type1 and usage_type2 and usage_type2 != usage_type1:
                            features_by_id[lib_feat_id]["USAGE_TYPE"] += ", " + usage_type2
                    else:
                        features_by_id[lib_feat_id] = feat_record

        # features_by_type is updated after in case duplicate lib_feat_ids
        for feat_record in features_by_id.values():
            features_by_type[feat_record["FTYPE_CODE"]].append(feat_record)

        return {"BY_ID": features_by_id, "BY_TYPE": features_by_type}

    def get_record_features(self, entity_features, feature_list):
        features_by_id = {}
        for feat_record in feature_list:
            lib_feat_id = feat_record["LIB_FEAT_ID"]
            if lib_feat_id in entity_features:
                feature_data = entity_features[lib_feat_id].copy()
                feature_data["USAGE_TYPE"] = feat_record.get("USAGE_TYPE", "")
                if feature_data["USAGE_TYPE"] == "PRIMARY":
                    feature_data["USAGE_TYPE_SORT"] = "1-PRIMARY"
                elif feature_data["USAGE_TYPE"]:
                    feature_data["USAGE_TYPE_SORT"] = f"2-{feature_data['USAGE_TYPE']}"
                else:
                    feature_data["USAGE_TYPE_SORT"] = "3-UNSPECIFIED"
                ftype_code = feature_data["FTYPE_CODE"]
                if lib_feat_id in features_by_id:  # may be a different usage type
                    usage_type1 = features_by_id[lib_feat_id].get("USAGE_TYPE", "")
                    usage_type2 = feat_record.get("USAGE_TYPE", "")
                    if usage_type1 and usage_type2 and usage_type2 != usage_type1:
                        features_by_id[lib_feat_id]["USAGE_TYPE"] += ", " + usage_type2
                else:
                    features_by_id[lib_feat_id] = feature_data
        # features_by_type is updated after in case duplicate lib_feat_ids
        features_by_type = {}
        for feat_record in features_by_id.values():
            if feat_record["FTYPE_CODE"] not in features_by_type:
                features_by_type[feat_record["FTYPE_CODE"]] = [feat_record]
            else:
                features_by_type[feat_record["FTYPE_CODE"]].append(feat_record)

        return {"BY_ID": features_by_id, "BY_TYPE": features_by_type}

    def regroup_by_type(self, features_by_id):
        features_by_type = {}
        for lib_feat_id in features_by_id:
            ftype_code = features_by_id[lib_feat_id]["FTYPE_CODE"]
            if ftype_code not in features_by_type:
                features_by_type[ftype_code] = [features_by_id[lib_feat_id]]
            else:
                features_by_type[ftype_code].append(features_by_id[lib_feat_id])
        return features_by_type

    def get_unmapped_list(self, unmapped_data):
        if not unmapped_data:
            return []
        else:
            return [{k: v} for k, v in unmapped_data.items()]

    def get_related_entities(self, related_entities):
        relation_list = []
        relations_by_id = {}
        for related_entity in related_entities:
            if related_entity["IS_DISCLOSED"] != 0:
                match_category = "DISCLOSED_RELATION"
            elif related_entity["IS_AMBIGUOUS"] != 0:
                match_category = "AMBIGUOUS_MATCH"
            elif related_entity["MATCH_LEVEL_CODE"] == "POSSIBLY_SAME":
                match_category = "POSSIBLE_MATCH"
            else:
                match_category = "POSSIBLY_RELATED"
            related_id = related_entity["ENTITY_ID"]
            relation = {
                "ENTITY_ID": related_id,
                "ENTITY_NAME": related_entity.get("ENTITY_NAME", "unknown"),
                "MATCH_LEVEL_CODE": related_entity["MATCH_LEVEL_CODE"],
                "MATCH_CATEGORY": match_category,
                "MATCH_CATEGORY_SORT": self.match_category_sort[match_category],
                "MATCH_KEY": related_entity["MATCH_KEY"],
                "ERRULE_CODE": related_entity["ERRULE_CODE"],
                "ERRULE_ID": self.errule_code_lookup[related_entity["ERRULE_CODE"]]["ERRULE_ID"],
                "RECORD_SUMMARY": related_entity.get("RECORD_SUMMARY", []),  # wont have on getNetwork
            }
            relation_list.append(relation)
            relations_by_id[related_id] = relation
        relation_list = sorted(relation_list, key=lambda k: k["MATCH_CATEGORY_SORT"])

        return {"LIST": relation_list, "BY_ID": relations_by_id}

    def get_resolved_entities(self, entity_list):
        entities = {}
        for entity in entity_list:
            entity_id = entity["RESOLVED_ENTITY"]["ENTITY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity["RESOLVED_ENTITY"]["ENTITY_NAME"],
                "RECORD_SUMMARY": entity["RESOLVED_ENTITY"]["RECORD_SUMMARY"],
                "RELATIONSHIPS": self.get_related_entities(entity["RELATED_ENTITIES"])["LIST"],
            }
        return entities

    def get_why_key(self, match_info):
        if "MATCH_KEY" in match_info:
            return match_info
        why_key = {
            "MATCH_KEY": match_info.get("WHY_KEY", ""),
            "ERRULE_CODE": match_info.get("WHY_ERRULE_CODE", ""),
            "ANY_CANDIDATES": len(match_info.get("CANDIDATE_KEYS", [])),
        }
        return why_key

    def get_why_scores(self, match_info):
        scores_by_id = {}
        for ftype_code in match_info.get("CANDIDATE_KEYS", {}):
            for score_record in match_info["CANDIDATE_KEYS"][ftype_code]:
                lib_feat_id = score_record["FEAT_ID"]
                scores_by_id[lib_feat_id] = {"WAS_CANDIDATE": True, "MATCH_SCORE": 100}

        score_records = {}
        if match_info.get("WHY_KEY_DETAILS"):
            for best_score in match_info["WHY_KEY_DETAILS"].get("CONFIRMATIONS", []):
                key = f"{best_score['INBOUND_FEAT_ID']}-{best_score['CANDIDATE_FEAT_ID']}"
                score_records[key] = best_score
            for best_score in match_info["WHY_KEY_DETAILS"].get("DENIALS", []):
                key = f"{best_score['INBOUND_FEAT_ID']}-{best_score['CANDIDATE_FEAT_ID']}"
                score_records[key] = best_score
        for ftype_code in match_info.get("FEATURE_SCORES", {}):
            all_scores = match_info["FEATURE_SCORES"][ftype_code]
            best_score = sorted(all_scores, key=lambda x: x["SCORE"])[-1]
            key = f"{best_score['INBOUND_FEAT_ID']}-{best_score['CANDIDATE_FEAT_ID']}"
            if key not in score_records:
                score_records[key] = best_score

        for key, best_score in score_records.items():
            scores_by_id[best_score["INBOUND_FEAT_ID"]] = {
                "MATCHED_FEAT_ID": best_score["CANDIDATE_FEAT_ID"],
                "MATCHED_FEAT_DESC": best_score["CANDIDATE_FEAT_DESC"],
                "MATCH_SCORE": best_score["SCORE"],
                "ALL_SCORES": best_score["ADDITIONAL_SCORES"],
                "MATCH_KEY_TOKEN": best_score.get("TOKEN"),
                "SCORE_BUCKET": best_score["SCORE_BUCKET"],
                "SCORE_BEHAVIOR": best_score["SCORE_BEHAVIOR"],
            }
            scores_by_id[best_score["CANDIDATE_FEAT_ID"]] = {
                "MATCHED_FEAT_ID": best_score["INBOUND_FEAT_ID"],
                "MATCHED_FEAT_DESC": best_score["INBOUND_FEAT_DESC"],
                "MATCH_SCORE": best_score["SCORE"],
                "ALL_SCORES": best_score["ADDITIONAL_SCORES"],
                "MATCH_KEY_TOKEN": best_score.get("TOKEN"),
                "SCORE_BUCKET": best_score["SCORE_BUCKET"],
                "SCORE_BEHAVIOR": best_score["SCORE_BEHAVIOR"],
            }
        return scores_by_id

    def combine_json(self, records):
        search_json = {}
        for record in records:
            if not search_json:
                search_json = record["JSON_DATA"]
            else:
                root_attributes = {}
                for root_attribute in record["JSON_DATA"]:
                    if not isinstance(record["JSON_DATA"][root_attribute], list):
                        root_attributes[root_attribute] = record["JSON_DATA"][root_attribute]
                    else:
                        if root_attribute not in search_json:
                            search_json[root_attribute] = []
                        for sub_record in record["JSON_DATA"][root_attribute]:
                            search_json[root_attribute].append(sub_record)
                if root_attributes:
                    if "ROOT_ATTRIBUTES" not in search_json:
                        search_json["ROOT_ATTRIBUTES"] = []
                    search_json["ROOT_ATTRIBUTES"].append(root_attributes)

        return search_json

    def get_how_data(self, entity_id):
        entity_id = int(entity_id)
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURES",
            "SZ_INCLUDE_MATCH_KEY_DETAILS",
        ]
        try:
            entity_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, entity_id)
        except SzError as err:
            raise err from err

        entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
        entity_records = entity_data["RESOLVED_ENTITY"]["RECORDS"]
        summary = {
            "RECORD_COUNT": len(entity_records),
            "SOURCE_FEATURE_COUNT": 0,
            "DERIVED_FEATURE_COUNT": 0,
            "STEP_TYPE": {},
            "PRINCIPLE": {},
            "INTERESTING_STEP": {},
        }
        for lib_feat_id in entity_features:
            ftype_code = entity_features[lib_feat_id]["FTYPE_CODE"]
            derived = self.ftype_code_lookup[ftype_code]["DERIVED"]
            if derived == "No":
                summary["SOURCE_FEATURE_COUNT"] += 1
            else:
                summary["DERIVED_FEATURE_COUNT"] += 1
            entity_features[lib_feat_id]["DERIVED"] = derived
            entity_features[lib_feat_id]["RECORD_COUNT"] = 0

        for record in entity_records:
            for feature in record["FEATURES"]:
                lib_feat_id = feature["LIB_FEAT_ID"]
                entity_features[lib_feat_id]["RECORD_COUNT"] += 1

        how_flag_list = ["SZ_HOW_ENTITY_DEFAULT_FLAGS"]
        try:
            how_data = self.call_sdk("how_entity_by_entity_id", how_flag_list, entity_id)
        except SzError as err:
            raise err from err

        how_steps = how_data["HOW_RESULTS"]["RESOLUTION_STEPS"]
        steps = {}
        for step in how_steps:
            step_num = step["STEP"]
            result_id = step["RESULT_VIRTUAL_ENTITY_ID"]
            entity_list = []
            for ve_num in ["VIRTUAL_ENTITY_1", "VIRTUAL_ENTITY_2"]:
                record_list = []
                features = {}
                for member_record in step[ve_num]["MEMBER_RECORDS"]:
                    for record in member_record["RECORDS"]:
                        record_list.append(record)
                        data_source = record["DATA_SOURCE"]
                        record_id = record["RECORD_ID"]
                        entity_record = next(
                            x for x in entity_records if x["DATA_SOURCE"] == data_source and x["RECORD_ID"] == record_id
                        )
                        features.update(self.get_record_features(entity_features, entity_record["FEATURES"])["BY_ID"])
                entity_list.append(
                    {
                        "VIRTUAL_ID": step[ve_num]["VIRTUAL_ENTITY_ID"],
                        "MEMBER_COUNT": len(step[ve_num]["MEMBER_RECORDS"]),
                        "RECORDS": record_list,
                        "FEATURES": features,
                    }
                )
            entity_list = sorted(entity_list, key=lambda k: k["MEMBER_COUNT"])
            if entity_list[0]["MEMBER_COUNT"] + entity_list[1]["MEMBER_COUNT"] == 2:
                step_type = "Create virtual entity"
            elif entity_list[0]["MEMBER_COUNT"] > 1:
                step_type = "Combine virtual entities"
                # all combine steps are interesting
                member_count1 = entity_list[0]["MEMBER_COUNT"]
                member_count2 = entity_list[1]["MEMBER_COUNT"]
                reason = f"Combines a group of {member_count1} with a group of {member_count2}"
                summary["INTERESTING_STEP"][step_num] = reason
            else:
                step_type = "Add record to virtual entity"

            steps[step_num] = {
                "STEP_TYPE": step_type,
                "ENTITY_LIST": entity_list,
                "MATCH_INFO": step["MATCH_INFO"],
                "RESULT_ID": result_id,
            }
            if step_type not in summary["STEP_TYPE"]:
                summary["STEP_TYPE"][step_type] = 1
            else:
                summary["STEP_TYPE"][step_type] += 1

            errule_code = step["MATCH_INFO"].get("ERRULE_CODE", "None")
            match_key = step["MATCH_INFO"].get("MATCH_KEY", "None")
            if not match_key.startswith("+NAME"):
                # eventually get match_key details and check name score
                reason = "Match_key has no or partial name match"
                summary["INTERESTING_STEP"][step_num] = reason

            if errule_code not in summary["PRINCIPLE"]:
                summary["PRINCIPLE"][errule_code] = {"COUNT": 1, "MATCH_KEY": {}}
            else:
                summary["PRINCIPLE"][errule_code]["COUNT"] += 1
            if match_key not in summary["PRINCIPLE"][errule_code]["MATCH_KEY"]:
                summary["PRINCIPLE"][errule_code]["MATCH_KEY"][match_key] = 1
            else:
                summary["PRINCIPLE"][errule_code]["MATCH_KEY"][match_key] += 1

        final_entities = how_data["HOW_RESULTS"]["FINAL_STATE"]["VIRTUAL_ENTITIES"]
        if how_data["HOW_RESULTS"]["FINAL_STATE"]["NEED_REEVALUATION"]:
            reevaluation_msg = f"Needs reevaluation: resulted in {len(final_entities)} entities!"
        else:
            reevaluation_msg = ""
        summary["REEVALUATION_MSG"] = reevaluation_msg
        summary["FINAL_COUNT"] = len(final_entities)

        how_data = {
            "ENTITY_ID": entity_id,
            "ENTITY_NAME": entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"],
            "FEATURES": entity_features,
            "RECORDS": entity_records,
            "SUMMARY": summary,
            "STEPS": steps,
            "FINAL_ENTITIES": final_entities,
        }
        return how_data

    def reorder_search_results(self, resolved_entities):
        matched_list = []
        for matched_entity in resolved_entities:
            match_score = 0
            feature_scores = matched_entity["MATCH_INFO"]["FEATURE_SCORES"]
            for feature_code in feature_scores:
                score_weight = 1 if feature_code == "NAME" else 0.5
                best_score_record = sorted(feature_scores[feature_code], key=lambda x: x["SCORE"])[-1]
                if best_score_record["SCORE"] >= 50:
                    match_score += best_score_record["SCORE"] * score_weight
            matched_entity["MATCH_SCORE"] = match_score
            matched_list.append(matched_entity)
        return sorted(matched_list, key=lambda k: k["MATCH_SCORE"], reverse=True)

    # display formatters

    def fmt_record_summary(self, record_summary, **kwargs):
        sep = kwargs.get("sep", "\n")
        dsrc_counts = {}
        for record in record_summary:
            count = record.get("RECORD_COUNT", 1)
            if record["DATA_SOURCE"] not in dsrc_counts:
                dsrc_counts[record["DATA_SOURCE"]] = count
            else:
                dsrc_counts[record["DATA_SOURCE"]] += count
        return sep.join([f"{colorize_dsrc(k)} ({v})" for k, v in dsrc_counts.items()])

    def fmt_record_list(self, record_list, **kwargs):
        record_limit = kwargs.get("record_limit", 1)
        source_data = {}
        for record in record_list:
            if record["DATA_SOURCE"] not in source_data:
                source_data[record["DATA_SOURCE"]] = [record["RECORD_ID"]]
            else:
                source_data[record["DATA_SOURCE"]].append(record["RECORD_ID"])
        display_list = []
        for data_source in sorted(source_data.keys()):
            colored_source = colorize_dsrc(data_source)
            if record_limit == 1:
                if len(source_data[data_source]) == 1:
                    display_list.append(f"{colored_source}: {source_data[data_source][0]}")
                else:
                    display_list.append(f"{colored_source}: {len(source_data[data_source])} records")
            else:
                line_cnt = 0
                display_list.append(colored_source)
                for record_id in sorted(source_data[data_source]):
                    display_list.append(record_id)
                    line_cnt += 1
                    if line_cnt >= record_limit:
                        break
                if record_limit and len(source_data[data_source]) > record_limit:
                    display_list.append(f"+{len(source_data[data_source])-record_limit} more")
        return "\n".join(display_list)

    def fmt_features(self, feature_data, **kwargs):
        attr_limit = kwargs.get("attr_limit", 0)
        attr_width = kwargs.get("attr_width", 80)
        display_list = []
        include_feature_code = True  # kwargs.get("include_feature_code")  # len(feature_data.keys()) > 1
        for ftype_code in sorted(feature_data.keys(), key=lambda k: self.ftype_code_order[k]):
            line_cnt = 0
            if include_feature_code:
                if ftype_code in self.senzing_features:
                    colored_ftype = colorize(ftype_code, "bad") + ": "
                else:
                    colored_ftype = colorize_attr(ftype_code) + ": "
            else:
                colored_ftype = ""
            for feature in sorted(feature_data[ftype_code], key=lambda k: (k["USAGE_TYPE_SORT"], -len(k["FEAT_DESC"]))):
                usage_type = f' ({feature.get("USAGE_TYPE")})' if feature.get("USAGE_TYPE") else ""
                feat_desc = feature["FEAT_DESC"]
                line_cnt += 1
                if attr_limit and line_cnt >= attr_limit:
                    continue
                colored_utype = colorize(usage_type, "dim, italics")
                if len(ftype_code + feat_desc + usage_type) + 2 < attr_width or not attr_width:
                    display_list.append(f"{colored_ftype}{feat_desc}{colored_utype}")
                elif len(feat_desc + usage_type) + 1 < attr_width - 1:
                    display_list.append(colored_ftype)
                    display_list.append(f" {feat_desc}{colored_utype}")
                else:
                    display_list.append(colored_ftype)
                    wrapper = textwrap.TextWrapper(width=attr_width - 1)
                    for line in wrapper.wrap(text=feat_desc):
                        display_list.append(" " + line)
                    if usage_type:
                        if len(display_list[-1] + usage_type) < attr_width - 1:
                            display_list[-1] += colored_utype
                        else:
                            display_list.append(colored_utype)

            if attr_limit > 0 and line_cnt > attr_limit:
                display_list.append(f"{colored_ftype}: +{line_cnt - attr_limit} more")

        return "\n".join(display_list)

    def fmt_feature_stats(self, feature):
        stats = "["
        if feature["CANDIDATE_CAP_REACHED"] == "Y":
            stats += "~"
        if feature["SCORING_CAP_REACHED"] == "Y":
            stats += "!"
        if feature.get("SUPPRESSED") == "Y":
            stats += "#"
        stats += str(feature["ENTITY_COUNT"]) + "]"
        return stats

    def fmt_why_features(self, why_key, feat_list, **kwargs):
        attr_limit = kwargs.get("attr_limit", 0)
        attr_width = kwargs.get("attr_width", 80)  # this attr_width cannot be 0 due to use of wrap_text
        display_list = []
        line_cnt = 0
        for feature in sorted(feat_list, key=lambda k: (-k.get("MATCH_SCORE", 0), k["FEAT_DESC"])):
            line_cnt += 1
            if attr_limit and line_cnt >= attr_limit:
                continue
            feat_desc = feature["FEAT_DESC"]
            stats = self.fmt_feature_stats(feature)
            feat_color = ""
            if feature.get("MATCH_SCORE", -1) >= 0:
                if feature.get("WAS_CANDIDATE"):  # always 100
                    feat_color = "highlight2"
                elif feature.get("SCORE_BUCKET") in ("SAME", "CLOSE"):
                    feat_color = "good"
                elif f"-{feature['FTYPE_CODE']}" in why_key:
                    feat_color = "bad"
                else:
                    feat_color = "caution"
            elif feature["FTYPE_CODE"] in self.senzing_features:
                feat_color = "bad"

            if any(x in stats for x in ("~", "!", "#")):
                feat_color += ",dim" if feat_color else "dim"

            display_list.extend(wrap_text(f"{feat_desc} {stats}", attr_width, feat_color))

            if feature.get("MATCHED_FEAT_DESC"):
                if feature["FTYPE_CODE"] != "NAME":
                    score = feature.get("MATCH_SCORE", 0)
                elif feature["ALL_SCORES"].get("GNR_ON", -1) != -1:
                    score = f"ORG:{feature['ALL_SCORES'].get('GNR_ON', 0)}"
                else:
                    score_list = []
                    if feature["ALL_SCORES"].get("GNR_FN", -1) != -1:
                        score_list.append(f"FULL:{feature['ALL_SCORES'].get('GNR_FN')}")
                    if feature["ALL_SCORES"].get("GNR_SN", -1) != -1:
                        score_list.append(f"SUR:{feature['ALL_SCORES'].get('GNR_SN')}")
                    if feature["ALL_SCORES"].get("GNR_GN", -1) != -1:
                        score_list.append(f"GIV:{feature['ALL_SCORES'].get('GNR_GN')}")
                    score = "|".join(score_list)
                matched_desc = f"\u2514\u2500\u2500 {feature['MATCHED_FEAT_DESC']} ({score})"
                display_list.extend(wrap_text(matched_desc, attr_width, feat_color))
        if attr_limit > 0 and line_cnt > attr_limit:
            display_list.append(f"+{line_cnt - attr_limit} more")

        return "\n".join(display_list)

    def fmt_unmapped(self, unmapped_list, **kwargs):
        attr_limit = kwargs.get("attr_limit", 0)
        attr_width = kwargs.get("attr_width", 0)
        attr_data = {}
        for record in unmapped_list:
            attr, value = list(record.items())[0]
            if attr not in attr_data:
                attr_data[attr] = [str(value)]
            else:
                attr_data[attr].append(str(value))
        display_list = []
        for attr in sorted(attr_data.keys()):
            colored_attr = colorize_attr(attr) + ":"
            attr_value_list = sorted(set(attr_data[attr]))

            line_cnt = 0
            for value in attr_value_list:
                if len(attr + value) + 1 < attr_width:
                    display_list.append(f"{colored_attr} {value}")
                else:
                    display_list.append(colored_attr)
                    wrapper = textwrap.TextWrapper(width=attr_width - 1)
                    for line in wrapper.wrap(text=value):
                        display_list.append(" " + line)
                line_cnt += 1
                if attr_limit and line_cnt >= attr_limit:
                    continue
            if attr_limit > 0 and line_cnt > attr_limit:
                display_list.append(f"{colored_attr}: +{line_cnt - attr_limit} more")

        return "\n".join(display_list)

    def fmt_match_key(self, match_data, **kwargs):
        sep = kwargs.get("sep", "\n")
        colored_key = ""
        if match_data.get("MATCH_KEY"):
            if match_data["MATCH_KEY"] == "n/a":
                return ""
            colored_key = colorize_match_key(match_data["MATCH_KEY"])
        if match_data.get("ERRULE_CODE"):
            if ":" in match_data["ERRULE_CODE"]:
                colored_rule = colorize(f'Principle {match_data["ERRULE_CODE"]}', "dim")
            elif self.errule_code_lookup.get(match_data["ERRULE_CODE"]):
                rule_id = match_data.get("ERRULE_ID", self.errule_code_lookup[match_data["ERRULE_CODE"]]["ERRULE_ID"])
                colored_rule = colorize(f'Principle {rule_id}: {match_data["ERRULE_CODE"]}', "dim")
            else:
                colored_rule = colorize(match_data["ERRULE_CODE"], "dim")
            if not colored_key:
                colored_key = colored_rule
            else:
                colored_key += f"{sep} {colored_rule}"
        if not colored_key and "ANY_CANDIDATES" in match_data:
            if match_data.get("ANY_CANDIDATES", 0) == 0:
                colored_key = colorize("No candidates", "bad")
            else:
                colored_key = colorize("No principles satisfied", "bad")

        return colored_key

    def fmt_match_group(self, match_category, match_key, **kwargs):
        match_key = match_key.replace(" (Ambiguous)", "")
        rel_keys = []
        plus_keys = []
        minus_keys = []
        key_list = re.split(r"(\+|\-)", match_key)
        i = 1
        while i < len(key_list):
            if key_list[i] in ("-"):
                i += 1
                this_key = key_list[i]
                minus_keys.append(this_key)

            elif key_list[i] in ("+"):
                i += 1
                this_key = key_list[i]
                if "(" not in this_key:
                    plus_keys.append(this_key)
                elif this_key.startswith("REL_POINTER(DOMAIN:"):  # kwargs.get("from_database"):
                    # format: REL_POINTER(DOMAIN:|MIN:|MAX:PRINCIPAL)
                    try:
                        l1 = this_key.find("DOMAIN:")
                        l2 = this_key.find("MIN:")
                        l3 = this_key.find("MAX:")
                        domain = this_key[l1 + 7 : l2 - 1]
                        role1 = this_key[l2 + 4 : l3 - 1]
                        role2 = this_key[l3 + 4 : -1]
                        rel_keys.append(f"{domain}({role1}:{role2})")
                    except:
                        print(f"Could not parse: {this_key}")
                else:
                    # format: DOMAIN(ROLE:ROLE) left role is from this entity's point of view
                    roles = this_key[this_key.find("(") + 1 : this_key.find(")")].split(":")
                    if roles[0]:
                        role = "--> " + roles[0]
                    else:
                        role = "<-- " + roles[1]
                    rel_keys.append(role)
            i += 1

        if rel_keys:
            match_group = colorize("+".join(sorted(rel_keys)), "highlight2")
        else:
            match_group = colorize("+".join(plus_keys), "good") if plus_keys else ""
            if match_category == "POSSIBLE_MATCH":
                match_group += colorize("-" + "-".join(minus_keys), "bad") if minus_keys else ""

        return match_group

    def fmt_relation(self, relation):
        colored_key = self.fmt_match_key(relation)
        colored_key += f'\n to {colorize_entity(relation.get("ENTITY_ID"))} {relation.get("ENTITY_NAME")}'
        return colored_key

    def fmt_entity_desc(self, entity):
        entity_desc = f'{colorize_entity(entity["ENTITY_ID"])}: {entity["ENTITY_NAME"]}'
        if entity.get("RECORD_SUMMARY"):
            entity_desc += " " + self.fmt_record_summary(entity["RECORD_SUMMARY"], sep=" | ")
        return entity_desc

    def fmt_how_statistic_hdr(self, header):
        return colorize(header, "highlight2")

    def fmt_how_statistic(self, stat, cnt):
        return stat + " " + colorize("(" + str(cnt) + ")", "highlight2")

    # formatted tables

    def get_features(self, arg_tokens, **kwargs):
        """display an entity's features and internal parsing"""
        feature_filter = kwargs.get("feature_list")
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
        ]
        try:
            if len(arg_tokens) == 1:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(arg_tokens[0]))
            else:
                json_data = self.call_sdk("get_entity_by_record_id", get_flag_list, arg_tokens)
        except SzError as err:
            raise err from err

        entity_id = json_data["RESOLVED_ENTITY"]["ENTITY_ID"]
        entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
        entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]

        tbl = eda_table()
        tbl.title = f"Features of entity {colorize_entity(entity_id)}: {entity_name}"
        tbl.columns = [
            {"name": "Feature", "width": 30, "align": "left"},
            {"name": "Description", "width": 100, "align": "left"},
            {"name": "Elements", "width": 100, "align": "left"},
        ]
        tbl.rows = []
        for lib_feat_id in sorted(
            set(entity_features.keys()), key=lambda k: self.ftype_code_order[entity_features[k]["FTYPE_CODE"]]
        ):
            try:
                response = self.sz_diagnostic.get_feature(lib_feat_id)
            except SzError as err:
                raise err from err
            feature_data = json.loads(response)

            if feature_filter and feature_data["FTYPE_CODE"] not in feature_filter:
                continue

            felem_values = []
            for felem_data in sorted(
                feature_data["ELEMENTS"], key=lambda k: self.felem_code_lookup[k["FELEM_CODE"]]["FELEM_ID"]
            ):
                felem_code = f'{colorize_attr(felem_data["FELEM_CODE"])}'
                felem_value = felem_data["FELEM_VALUE"]
                if felem_data["FELEM_CODE"] == "LIBPOSTAL_PARSE":
                    # with suppress(Exception):
                    # print(felem_value)
                    value_data = json.loads(felem_value)
                    value_list = []
                    for key in sorted(value_data.keys()):
                        value_list.append(f"  {colorize(key, 'highlight2,dim')}: {json.dumps(value_data[key])}")
                    felem_value = "\n" + "\n".join(value_list)
                felem_values.append(f"{felem_code}: {felem_value}")

            tbl.rows.append(
                [
                    f'{colorize_attr(feature_data["FTYPE_CODE"])}\n  {colorize("id: " + str(lib_feat_id), "dim")}',
                    entity_features[lib_feat_id]["FEAT_DESC"],
                    "\n".join(felem_values),
                ]
            )

        return tbl.render_table()

    def get_entity(self, arg_tokens, **kwargs):
        kwargs["record_limit"] = kwargs.get("record_limit", 20)
        kwargs["attr_limit"] = kwargs.get("attr_limit", 20)
        kwargs["attr_width"] = kwargs.get("attr_width", 80)
        show_detail = kwargs.get("show_detail")
        show_relations_on_get = kwargs.get("show_relations_on_get", "none")
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURES",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
        ]
        try:
            if len(arg_tokens) == 1:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(arg_tokens[0]))
            else:
                json_data = self.call_sdk("get_entity_by_record_id", get_flag_list, arg_tokens)
        except SzError as err:
            raise err from err

        related_entity_count = len(json_data.get("RELATED_ENTITIES", []))
        entity_id = json_data["RESOLVED_ENTITY"]["ENTITY_ID"]
        entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
        entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
        self.last_entity_id = entity_id

        report_type = "detail" if show_detail else "summary"
        tbl = eda_table()
        tbl.title = f"Entity {report_type} for entity {colorize_entity(entity_id)}: {entity_name}"
        if self.webapp_url:
            tbl.title += f"  {colorize('WebApp:', 'dim')} " + colorize(
                f"{self.webapp_url}/graph/{entity_id}", "highlight1,underline"
            )
        tbl.columns = [
            {"name": "Sources", "width": 50, "align": "left"},
            {"name": "Features", "width": kwargs["attr_width"], "align": "left"},
            {"name": "Additional Data", "width": kwargs["attr_width"], "align": "left"},
        ]

        table_data = {}
        for record in sorted(json_data["RESOLVED_ENTITY"]["RECORDS"], key=lambda k: (k["DATA_SOURCE"], k["RECORD_ID"])):
            data_source = record["DATA_SOURCE"]
            record_id = record["RECORD_ID"]
            record_source = {"DATA_SOURCE": data_source, "RECORD_ID": record_id}
            record_features = self.get_record_features(entity_features, record["FEATURES"])["BY_ID"]
            unmapped_items = self.get_unmapped_list(record.get("UNMAPPED_DATA"))
            if report_type == "summary":
                table_key = data_source
            else:
                table_key = data_source + record_id
                record_source["MATCH_KEY"] = record.get("MATCH_KEY")
                record_source["ERRULE_CODE"] = record.get("ERRULE_CODE")
            if table_key not in table_data:
                table_data[table_key] = {
                    "RECORDS": [record_source],
                    "FEATURES": record_features,
                    "UNMAPPED": unmapped_items,
                }
            else:
                table_data[table_key]["RECORDS"].append(record_source)
                table_data[table_key]["FEATURES"].update(record_features)
                table_data[table_key]["UNMAPPED"].extend(unmapped_items)

        for table_key in table_data:
            source_display = self.fmt_record_list(table_data[table_key]["RECORDS"], **kwargs)
            if report_type != "summary":
                source_display += "\n" + self.fmt_match_key(table_data[table_key]["RECORDS"][0])
            features_by_type = self.regroup_by_type(table_data[table_key]["FEATURES"])
            feature_display = self.fmt_features(features_by_type, **kwargs)
            unmapped_display = self.fmt_unmapped(table_data[table_key]["UNMAPPED"], **kwargs)
            tbl.rows.append([source_display, feature_display, unmapped_display])

        entity_only_features = []
        for feat_data in entity_features.values():
            if feat_data["FTYPE_CODE"] in self.senzing_features:
                entity_only_features.append(f"{colorize(feat_data['FTYPE_CODE'], 'bad')}: {feat_data['FEAT_DESC']}")
        if entity_only_features:
            tbl.rows.insert(0, [colorize_dsrc("SENZING"), "\n".join(entity_only_features), ""])

        org_mode = show_relations_on_get == "tree"
        report = tbl.render_table(org_mode=org_mode)

        if related_entity_count == 0 or show_relations_on_get == "none":
            # rel_count_str = f"{'No' if related_entity_count == 0 else related_entity_count}"
            report += f"\u2514\u2500\u2500 {related_entity_count} related entities\n"

        elif related_entity_count and show_relations_on_get == "tree":
            tree_str = self.get_relationship_tree(entity_id)
            report += tree_str[tree_str.find("\n") + 1 :]

        elif related_entity_count:
            related_entities = self.get_related_entities(json_data["RELATED_ENTITIES"])["LIST"]
            tbl = eda_table()
            tbl.title = f"{related_entity_count} related entities"
            tbl.columns = [
                {"name": "Entity ID", "width": 25, "align": "center"},
                {"name": "Entity Name", "width": 100, "align": "left"},
                {"name": "Data Sources", "width": 100, "align": "left"},
                {"name": "Match Level", "width": 15, "align": "left"},
                {"name": "Match Key", "width": 100, "align": "left"},
            ]
            for relationship in sorted(
                related_entities, key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"])
            ):
                row = [
                    colorize_entity(relationship["ENTITY_ID"]),
                    relationship["ENTITY_NAME"],
                    self.fmt_record_summary(relationship["RECORD_SUMMARY"]),
                    self.match_category_desc[relationship["MATCH_CATEGORY"]],
                    self.fmt_match_key(relationship),
                ]
                tbl.rows.append(row)
            report += tbl.render_table()

        return report

    def get_relationship_tree(self, root_entity_id, **kwargs):
        build_out_degree = kwargs.get("build_out_degree", 1)
        max_degree = 0  # really only used for entity paths
        max_entities = 10000  # for safety
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            extra_parms = [[root_entity_id], max_degree, build_out_degree, max_entities]
            json_data = self.call_sdk("find_network_by_entity_id", get_flag_list, extra_parms)
        except SzError as err:
            raise err from err

        entities = self.get_resolved_entities(json_data["ENTITIES"])

        related_entities = sorted(
            entities[root_entity_id]["RELATIONSHIPS"],
            key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"]),
        )
        parents = [
            {
                "entity_id": root_entity_id,
                "relationships": related_entities,
            }
        ]
        tree_nodes = {}
        while parents:
            if len(parents[-1]["relationships"]) == 0:
                parents.pop()
                continue
            entity_id = parents[-1]["entity_id"]
            if entity_id not in tree_nodes:
                tree_nodes[entity_id] = eda_node(entity_id)
                tree_nodes[entity_id].node_desc = self.fmt_entity_desc(entities[entity_id])

            relation = parents[-1]["relationships"][0]
            parents[-1]["relationships"].pop(0)
            related_id = relation["ENTITY_ID"]
            if related_id not in entities or related_id in [x["entity_id"] for x in parents]:
                continue

            category = relation["MATCH_CATEGORY"]
            group = self.fmt_match_group(category, relation["MATCH_KEY"])
            category_node_id = f"{entity_id}-{category}"
            group_node_id = f"{entity_id}-{category}-{group}"

            if category_node_id not in tree_nodes:
                tree_nodes[category_node_id] = eda_node(category_node_id)
                tree_nodes[entity_id].add_child(tree_nodes[category_node_id])
            tree_nodes[category_node_id].counter1 += 1
            tree_nodes[category_node_id].node_desc = (
                f"{self.match_category_desc[category]} ({tree_nodes[category_node_id].counter1 })"
            )

            if group_node_id not in tree_nodes:
                tree_nodes[group_node_id] = eda_node(group_node_id)
                tree_nodes[category_node_id].add_child(tree_nodes[group_node_id])
            tree_nodes[group_node_id].counter1 += 1
            tree_nodes[group_node_id].node_desc = f"{group} ({tree_nodes[group_node_id].counter1})"

            if related_id not in tree_nodes:
                rel_desc = self.fmt_entity_desc(entities[related_id])
                rel_desc += " " + self.fmt_match_key({"MATCH_KEY": relation["MATCH_KEY"]})
                tree_nodes[related_id] = eda_node(related_id)
                tree_nodes[related_id].node_desc = rel_desc
            tree_nodes[group_node_id].add_child(tree_nodes[related_id])

            if len(entities[related_id]["RELATIONSHIPS"]) != 0 and len(parents) < build_out_degree:
                related_entities = sorted(
                    entities[related_id]["RELATIONSHIPS"],
                    key=lambda k: (k["MATCH_CATEGORY_SORT"], k["ERRULE_ID"], k["ENTITY_ID"]),
                )
                parents.append(
                    {
                        "entity_id": related_id,
                        "relationships": related_entities,
                    }
                )
        return tree_nodes[root_entity_id].render_tree()

    def compare_relationships(self, entity_id, **kwargs):
        """compare an entity's relationships side by side"""
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        try:
            json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
        except SzError as err:
            raise err from err

        entity_list = [entity_id]
        related_entities = self.get_related_entities(json_data["RELATED_ENTITIES"])["LIST"]
        entity_list.extend([str(x["ENTITY_ID"]) for x in related_entities])
        kwargs["compare_to_1"] = True
        return self.compare_entities(entity_list, **kwargs)

    def compare_entities(self, entity_list, **kwargs):
        """compare a list of entities side by side"""
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURES",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
        ]
        kwargs["record_limit"] = kwargs.get("record_limit", 1)
        kwargs["attr_limit"] = kwargs.get("attr_limit", 20)
        kwargs["attr_width"] = kwargs.get("attr_width", 80)

        tbl = eda_table()
        if kwargs.get("compare_to_1"):
            tbl.title = "Comparison of relationships"
        else:
            tbl.title = "Comparison of listed entities"
        tbl.columns = [{"name": "ENTITY", "width": 15, "align": "left"}]
        tbl.rows = []
        ftype_codes = []
        entities = {}
        source_row = ["DATA_SOURCES"]
        for entity_id in entity_list:
            try:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                raise err from err

            records = json_data["RESOLVED_ENTITY"]["RECORDS"]
            features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_TYPE"]
            relations = self.get_related_entities(json_data["RELATED_ENTITIES"])["BY_ID"]

            source_row.append(self.fmt_record_list(records, **kwargs))
            entities[entity_id] = {"RECORDS": records, "FEATURES": features, "RELATIONS": relations}
            column_header = f"{colorize_entity(entity_id)}"
            tbl.columns.append({"name": column_header, "width": kwargs["attr_width"], "align": "left"})
            ftype_codes.extend(list(features.keys()))
        tbl.rows.append(source_row)

        if kwargs.get("compare_to_1"):
            cross_row = ["RELATIONSHIP"]
        else:
            cross_row = ["CROSS_RELATIONS"]
        common_row = ["COMMON_RELATIONS"]
        any_cross_rels = False
        any_common_rels = False
        entity_id1 = entity_list[0]
        for entity_id in entity_list:
            common_rels = []
            cross_rels = []
            for related_id in entities[entity_id]["RELATIONS"]:
                relation = entities[entity_id]["RELATIONS"][related_id]
                if kwargs.get("compare_to_1"):
                    if entity_id != entity_id1 and str(related_id) == entity_id1:
                        cross_rels.append(self.fmt_relation(relation))
                        any_cross_rels = True
                else:
                    if str(related_id) in entity_list:
                        cross_rels.append(self.fmt_relation(relation))
                        any_cross_rels = True

                common_count = 0
                for entity_id2 in entity_list:
                    if entity_id2 == entity_id:
                        continue
                    if related_id in entities[entity_id2]["RELATIONS"]:
                        common_count += 1
                if common_count == len(entity_list) - 1:
                    common_rels.append(self.fmt_relation(relation))
                    any_common_rels = True
            cross_row.append("\n".join(cross_rels))
            common_row.append("\n".join(common_rels))

        if any_cross_rels:
            tbl.rows.append(cross_row)
        if any_common_rels:
            tbl.rows.append(common_row)

        for ftype_code in sorted(set(ftype_codes), key=lambda k: self.ftype_code_order[k]):
            # if ftype_code in self.senzing_features:
            #     colorized_ftype = colorize(ftype_code, "caution")
            # else:
            #     colorized_ftype = colorize_attr(ftype_code)
            feat_row = [ftype_code]
            for entity_id in entity_list:
                feat_list = entities[entity_id]["FEATURES"].get(ftype_code)
                if feat_list:
                    feat_row.append(self.fmt_features({ftype_code: feat_list}, **kwargs))
                else:
                    feat_row.append("")
            tbl.rows.append(feat_row)

        any_unmapped = False
        unmapped_row = ["ADDITIONAL_DATA"]
        for entity_id in entity_list:
            unmapped_list = []
            for record in entities[entity_id]["RECORDS"]:
                unmapped_list.extend(self.get_unmapped_list(record.get("UNMAPPED_DATA")))
                any_unmapped = True
            unmapped_row.append(self.fmt_unmapped(unmapped_list, **kwargs))
        if any_unmapped:
            tbl.rows.append(unmapped_row)

        return tbl.render_table(side_header=True)

    def why_display(self, entity_data, **kwargs):
        row1_title = kwargs.get("row1_title", "id").upper()
        report_title = kwargs.get("report_title", "why report")
        kwargs["record_limit"] = kwargs.get("record_limit", 1)
        kwargs["attr_limit"] = kwargs.get("attr_limit", 20)
        kwargs["attr_width"] = kwargs.get("attr_width", 80)
        tbl = eda_table()
        tbl.title = report_title
        tbl.columns = [{"name": row1_title, "width": 15, "align": "left"}]
        tbl.rows = []
        source_row = ["DATA_SOURCES"]
        why_row = ["WHY_RESULT"]
        entity_list = entity_data.keys()

        ftype_codes_used = []
        for _id in entity_list:
            records = entity_data[_id]["RECORDS"]
            source_row.append(self.fmt_record_list(records, **kwargs))

            if "MATCH_INFO_LIST" in entity_data[_id]:  # for why not many
                scores_by_id = {}
                why_list = []
                for match_info in entity_data[_id]["MATCH_INFO_LIST"]:
                    scores_by_id.update(self.get_why_scores(match_info))
                    why_list.append(self.fmt_relation(match_info))
                why_row.append("\n".join(why_list))

            else:
                match_info = entity_data[_id]["MATCH_INFO"]
                why_key = self.get_why_key(match_info)
                scores_by_id = self.get_why_scores(match_info)
                why_row.append(self.fmt_match_key(why_key))

            features_by_id = entity_data[_id]["FEATURES"]
            for lib_feat_id in features_by_id:
                ftype_codes_used.append(features_by_id[lib_feat_id]["FTYPE_CODE"])
                if lib_feat_id in scores_by_id:
                    if "MATCH_SCORE" in scores_by_id[lib_feat_id]:
                        features_by_id[lib_feat_id].update(scores_by_id[lib_feat_id])
            entity_data[_id]["FEATURES"] = self.regroup_by_type(features_by_id)

            column_header = colorize(_id, "dim" if row1_title == "Internal ID" else "entity_color")
            tbl.columns.append({"name": column_header, "width": kwargs["attr_width"], "align": "left"})
        tbl.rows.append(source_row)
        tbl.rows.append(why_row)

        cross_row = ["CROSS_RELATIONS"]
        any_cross_rels = False
        for entity_id in entity_list:
            cross_rels = []
            for related_id in entity_data[entity_id].get("RELATIONS", {}):
                if related_id in entity_list:
                    relation = entity_data[entity_id]["RELATIONS"][related_id]
                    cross_rels.append(self.fmt_relation(relation))
                    any_cross_rels = True
            cross_row.append("\n".join(cross_rels))
        if any_cross_rels:
            tbl.rows.append(cross_row)

        for ftype_code in sorted(set(ftype_codes_used), key=lambda k: self.ftype_code_order[k]):
            feat_row = [ftype_code]
            for _id in entity_list:
                # why not many has multiple match_info_list, must append them altogether to get any minuses
                if entity_data[_id].get("MATCH_INFO_LIST"):
                    why_key = "+".join(x.get("MATCH_KEY", "") for x in entity_data[_id]["MATCH_INFO_LIST"])
                else:
                    why_key = entity_data[_id]["MATCH_INFO"].get("WHY_KEY", "")
                feat_list = entity_data[_id]["FEATURES"].get(ftype_code)
                if feat_list:
                    feat_row.append(self.fmt_why_features(why_key, feat_list, **kwargs))
                else:
                    feat_row.append("")
            tbl.rows.append(feat_row)

        return tbl.render_table(side_header=True)

    def how_tree_display(self, step_data, **kwargs):
        kwargs["record_limit"] = kwargs.get("record_limit", 1)
        kwargs["attr_limit"] = kwargs.get("attr_limit", 20)
        kwargs["attr_width"] = kwargs.get("attr_width", 80)

        virtual_id1 = step_data["ENTITY_LIST"][0]["VIRTUAL_ID"]
        virtual_id2 = step_data["ENTITY_LIST"][1]["VIRTUAL_ID"]

        # debug_print(step_data)
        # source_row.append(self.fmt_record_list(records, 1, attr_width))

        tbl = eda_table()
        tbl.columns = [
            {"name": colorize("VIRTUAL_ID", "dim"), "width": 25, "align": "left"},
            {"name": colorize_entity(virtual_id1), "width": kwargs["attr_width"], "align": "left"},
            {"name": colorize("SCORES", "dim"), "width": 25, "align": "center"},
            {"name": colorize_entity(virtual_id2), "width": kwargs["attr_width"], "align": "left"},
        ]
        tbl.rows = [
            [
                colorize("DATA_SOURCES", "dim"),
                self.fmt_record_list(step_data["ENTITY_LIST"][0]["RECORDS"], **kwargs),
                "",
                self.fmt_record_list(step_data["ENTITY_LIST"][1]["RECORDS"], **kwargs),  # .replace("\n", " | ")[0:80],
            ],
        ]
        if step_data["STEP_TYPE"] == "Create virtual entity":
            left_side_feat = "CANDIDATE_FEAT_DESC"
            right_side_feat = "INBOUND_FEAT_DESC"
        else:
            left_side_feat = "INBOUND_FEAT_DESC"
            right_side_feat = "CANDIDATE_FEAT_DESC"

        match_key = step_data["MATCH_INFO"].get("MATCH_KEY", "")
        feature_scores = step_data["MATCH_INFO"]["FEATURE_SCORES"]
        for ftype_code in sorted(set(feature_scores), key=lambda k: self.ftype_code_order[k]):
            all_scores = step_data["MATCH_INFO"]["FEATURE_SCORES"][ftype_code]
            best_score = sorted(all_scores, key=lambda x: x["SCORE"])[-1]
            if (
                best_score["ADDITIONAL_SCORES"].get("GNR_SN", 0) > 0
                or best_score["ADDITIONAL_SCORES"].get("GNR_GN", 0) > 0
            ):
                score_value = "|".join(
                    [
                        str(best_score["ADDITIONAL_SCORES"]["GNR_GN"]),
                        str(best_score["ADDITIONAL_SCORES"]["GNR_SN"]),
                        str(best_score["ADDITIONAL_SCORES"]["GNR_FN"]),
                    ]
                )
            else:
                score_value = best_score["SCORE"]

            if best_score.get("SCORE_BUCKET") in ("SAME", "CLOSE"):
                feat_color = "good"
            elif f"-{ftype_code}" in match_key:
                feat_color = "bad"
            else:
                feat_color = "caution"

            tbl.rows.append(
                [
                    colorize(ftype_code, "dim"),
                    best_score[left_side_feat],
                    colorize(score_value, feat_color),
                    best_score[right_side_feat],
                ]
            )
        #     tbl.rows[0][0].append(colorize(ftype_code, "dim"))
        #     tbl.rows[0][1].append(best_score["INBOUND_FEAT_DESC"])
        #     tbl.rows[0][2].append(colorize(score_value, feat_color))
        #     tbl.rows[0][3].append(best_score["CANDIDATE_FEAT_DESC"])

        # for i in range(4):
        #     tbl.rows[0][i] = "\n".join(tbl.rows[0][i])

        return tbl.render_table(no_lines=True)

    def why_search(self, search_json, **kwargs):
        search_flag_list = [
            "SZ_SEARCH_INCLUDE_REQUEST_DETAILS",
            "SZ_INCLUDE_FEATURE_SCORES",
            "SZ_INCLUDE_MATCH_KEY_DETAILS",
            "SZ_ENTITY_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURES",
        ]

        if kwargs["search"] == 0:
            search_flag_list.append("SZ_SEARCH_INCLUDE_ALL_CANDIDATES")
            try:
                json_data = self.call_sdk("search_by_attributes", search_flag_list, json.dumps(search_json))
            except SzError as err:
                raise err from err
            matched_list = sdk_wrapper.reorder_search_results(json_data.get("RESOLVED_ENTITIES", []))
        else:
            try:
                json_data = self.call_sdk("why_search", search_flag_list, [json.dumps(search_json), kwargs["search"]])
            except SzError as err:
                raise err from err
            # modify why result to be compatible with a search response
            matched_entity = {
                "MATCH_INFO": json_data["WHY_RESULTS"][0]["MATCH_INFO"],
                "ENTITY": {
                    "RESOLVED_ENTITY": json_data["ENTITIES"][0]["RESOLVED_ENTITY"],
                    "RELATED_ENTITIES": json_data["ENTITIES"][0]["RELATED_ENTITIES"],
                },
            }
            matched_list = [matched_entity]

        entities = {}
        entity_data = json_data["SEARCH_REQUEST"]
        search_records = [
            {"DATA_SOURCE": "SEARCH", "RECORD_ID": json_data["SEARCH_REQUEST"].get("RECORD_ID", "request")}
        ]
        search_features = self.get_entity_features(entity_data["FEATURES"])["BY_ID"]
        entities["n/a"] = {
            "FEATURES": search_features,
            "RECORDS": search_records,
            "RELATIONS": {},
            "MATCH_INFO": {"MATCH_KEY": "n/a"},
        }

        for resolved_entity_data in matched_list:
            match_info = resolved_entity_data["MATCH_INFO"]
            for feature in match_info["CANDIDATE_KEYS"]:
                for feat_data in match_info["CANDIDATE_KEYS"][feature]:
                    if feat_data["FEAT_ID"] in search_features:
                        # print(search_features[feat_data["FEAT_ID"]])
                        search_features[feat_data["FEAT_ID"]]["MATCH_SCORE"] = 100
                        search_features[feat_data["FEAT_ID"]]["WAS_CANDIDATE"] = True
            for feature in match_info["FEATURE_SCORES"]:
                for feat_data in match_info["FEATURE_SCORES"][feature]:
                    # input(json.dumps(feat_data, indent=4))
                    if feat_data["INBOUND_FEAT_ID"] in search_features:
                        match_score = feat_data["SCORE"]
                        score_bucket = feat_data["SCORE_BUCKET"]
                        search_features[feat_data["INBOUND_FEAT_ID"]]["WAS_SEARCH"] = match_score
                        if match_score > search_features[feat_data["INBOUND_FEAT_ID"]].get("MATCH_SCORE", 0):
                            search_features[feat_data["INBOUND_FEAT_ID"]]["MATCH_SCORE"] = match_score
                            search_features[feat_data["INBOUND_FEAT_ID"]]["SCORE_BUCKET"] = score_bucket
            entity_data = resolved_entity_data["ENTITY"]

            entity_id = entity_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = entity_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(entity_data["RELATED_ENTITIES"])["BY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
                "MATCH_INFO": match_info,
            }

        kwargs["report_title"] = "Why search"
        kwargs["row1_title"] = "ENTITY_ID"
        return self.why_display(entities, **kwargs)

    def why_records(self, entity_list, **kwargs):
        why_flag_list = [
            "SZ_ENTITY_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_INCLUDE_FEATURE_SCORES",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURES",
            "SZ_INCLUDE_MATCH_KEY_DETAILS",
        ]
        try:
            parms = [entity_list[0], entity_list[1], entity_list[2], entity_list[3]]
            json_data = self.call_sdk("why_records", why_flag_list, parms)
        except SzError as err:
            raise err from err

        entities = {}
        for entity_data in json_data["ENTITIES"]:
            entity_id = entity_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = entity_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(entity_data["RELATED_ENTITIES"])["BY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
            }

        why_result = json_data["WHY_RESULTS"][0]  # only 1 result for whyRecord
        match_info = why_result["MATCH_INFO"]
        entity_data = {}
        entity_fields = (
            ("INTERNAL_ID", "ENTITY_ID", "FOCUS_RECORDS"),
            ("INTERNAL_ID_2", "ENTITY_ID_2", "FOCUS_RECORDS_2"),
        )
        for internal_field, entity_field, record_field in entity_fields:
            internal_id = why_result[internal_field]
            entity_id = why_result[entity_field]
            entity_features = entities[entity_id]["FEATURES"]
            entity_records = entities[entity_id]["RECORDS"]
            features = {}
            for record in why_result[record_field]:
                data_source = record["DATA_SOURCE"]
                record_id = record["RECORD_ID"]
                record = next(
                    x for x in entity_records if x["DATA_SOURCE"] == data_source and x["RECORD_ID"] == record_id
                )
                features.update(self.get_record_features(entity_features, record["FEATURES"])["BY_ID"])
            entity_data[internal_id] = {
                "RECORDS": why_result[record_field],
                "FEATURES": features,
                "RELATIONS": [],
                "MATCH_INFO": match_info,
            }
        kwargs["report_title"] = "Why for listed records"
        kwargs["row1_title"] = "INTERNAL_ID"
        return self.why_display(entity_data, **kwargs)

    def why_not(self, entity_list, **kwargs):
        entity_list = [int(x) for x in entity_list]

        why_flag_list = [
            "SZ_ENTITY_DEFAULT_FLAGS",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_INCLUDE_FEATURE_SCORES",
            "SZ_INCLUDE_MATCH_KEY_DETAILS",
        ]
        try:
            parms = [entity_list[0], entity_list[1]]
            json_data = self.call_sdk("why_entities", why_flag_list, parms)
        except SzError as err:
            raise err from err

        match_info = json_data["WHY_RESULTS"][0]["MATCH_INFO"]
        entities = {}
        for entity_data in json_data["ENTITIES"]:
            entity_id = entity_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = entity_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(entity_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = entity_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(entity_data["RELATED_ENTITIES"])["BY_ID"]
            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
                "MATCH_INFO": match_info,
            }
        kwargs["report_title"] = "Why not for listed entities"
        kwargs["row1_title"] = "ENTITY_ID"
        return self.why_display(entities, **kwargs)

    def why_not_many(self, entity_list, **kwargs):
        entity_list = [int(x) for x in entity_list]
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_ALL_FEATURES",
            "SZ_ENTITY_INCLUDE_INTERNAL_FEATURES",
            "SZ_ENTITY_INCLUDE_FEATURE_STATS",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_FEATURES",
            "SZ_ENTITY_INCLUDE_RECORD_UNMAPPED_DATA",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
            "SZ_ENTITY_INCLUDE_RELATED_RECORD_SUMMARY",
        ]
        entities = {}
        for entity_id in entity_list:
            try:
                json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
            except SzError as err:
                raise err from err

            entity_id = json_data["RESOLVED_ENTITY"]["ENTITY_ID"]
            entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
            entity_features = self.get_entity_features(json_data["RESOLVED_ENTITY"]["FEATURES"])["BY_ID"]
            records = json_data["RESOLVED_ENTITY"]["RECORDS"]
            relations = self.get_related_entities(json_data["RELATED_ENTITIES"])["BY_ID"]

            search_str = json.dumps(self.combine_json(records))
            search_flag_list = [
                "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
                "SZ_INCLUDE_FEATURE_SCORES",
                "SZ_ENTITY_INCLUDE_FEATURE_STATS",
                "SZ_ENTITY_INCLUDE_ENTITY_NAME",
                "SZ_ENTITY_INCLUDE_RECORD_DATA",
            ]
            try:
                json_data2 = self.call_sdk("search_by_attributes", search_flag_list, search_str)
            except SzError as err:
                raise err from err
            match_info_list = []
            for matched_entity in json_data2["RESOLVED_ENTITIES"]:
                matched_id = matched_entity["ENTITY"]["RESOLVED_ENTITY"]["ENTITY_ID"]
                if matched_id in entity_list and matched_id != entity_id:
                    match_info = matched_entity["MATCH_INFO"]
                    match_info["ENTITY_ID"] = matched_id
                    match_info["ENTITY_NAME"] = matched_entity["ENTITY"]["RESOLVED_ENTITY"]["ENTITY_NAME"]
                    match_info_list.append(match_info)

            entities[entity_id] = {
                "ENTITY_ID": entity_id,
                "ENTITY_NAME": entity_name,
                "FEATURES": entity_features,
                "RECORDS": records,
                "RELATIONS": relations,
                "MATCH_INFO_LIST": match_info_list,
            }

        kwargs["report_title"] = "Why not for listed entities"
        kwargs["row1_title"] = "ENTITY_ID"
        return self.why_display(entities, **kwargs)

    def how_summary(self, how_data):
        summary_node = eda_node("summary")
        summary_node.node_desc = f"How summary for {self.fmt_entity_desc(how_data)}"

        category_node = eda_node("resolution")
        category_node.node_desc = self.fmt_how_statistic_hdr("RESOLUTION SUMMARY")
        summary_node.add_child(category_node)

        group_node = eda_node("steps")
        step_count = 0
        for step_type in how_data["SUMMARY"]["STEP_TYPE"]:
            step_type_count = how_data["SUMMARY"]["STEP_TYPE"][step_type]
            step_count += step_type_count
            step_node = eda_node(step_type)
            step_node.node_desc = self.fmt_how_statistic(step_type, step_type_count)
            group_node.add_child(step_node)
        group_node.node_desc = self.fmt_how_statistic("Resolution steps", step_count)
        category_node.add_child(group_node)

        if how_data["SUMMARY"]["INTERESTING_STEP"]:
            group_node = eda_node("interests")
            interesting_step_count = 0
            for step_num in sorted(list(how_data["SUMMARY"]["INTERESTING_STEP"].keys())):
                interesting_step_count += 1
                interest_node = eda_node(f"interest{step_num}")
                reason = how_data["SUMMARY"]["INTERESTING_STEP"][step_num]
                interest_node.node_desc = colorize(f"Step {step_num} {reason}", "italics")
                group_node.add_child(interest_node)
            group_node.node_desc = self.fmt_how_statistic("Steps of interest", interesting_step_count)
            category_node.add_child(group_node)

        group_node = eda_node("principles")
        principles_used_count = 0
        for principle in how_data["SUMMARY"]["PRINCIPLE"]:
            rule_id = ""
            if principle in self.errule_code_lookup:
                rule_id = f"{self.errule_code_lookup[principle]['ERRULE_ID']}: "
            principle_count = how_data["SUMMARY"]["PRINCIPLE"][principle]["COUNT"]
            principles_used_count += principle_count
            principle_desc = colorize(f"Principle {rule_id}{principle}", "dim")
            principle_node = eda_node(principle)
            for match_key in how_data["SUMMARY"]["PRINCIPLE"][principle]["MATCH_KEY"]:
                match_key_node = eda_node(match_key)
                match_key_desc = colorize_match_key(match_key)
                match_key_count = how_data["SUMMARY"]["PRINCIPLE"][principle]["MATCH_KEY"][match_key]
                match_key_node.node_desc = self.fmt_how_statistic(match_key_desc, match_key_count)
                principle_node.add_child(match_key_node)
            principle_node.node_desc = self.fmt_how_statistic(principle_desc, principle_count)
            group_node.add_child(principle_node)
        group_node.node_desc = self.fmt_how_statistic("Principles used", principles_used_count)
        category_node.add_child(group_node)

        category_node = eda_node("entity")
        category_node.node_desc = self.fmt_how_statistic_hdr("ENTITY SUMMARY")
        summary_node.add_child(category_node)
        for stat_data in [
            ["Total record count", how_data["SUMMARY"]["RECORD_COUNT"]],
            ["Total feature count", how_data["SUMMARY"]["SOURCE_FEATURE_COUNT"]],
        ]:
            item_node = eda_node(stat_data[0])
            item_node.node_desc = self.fmt_how_statistic(stat_data[0], stat_data[1])
            category_node.add_child(item_node)

        features_by_type = self.regroup_by_type(how_data["FEATURES"])
        ftype_codes = features_by_type.keys()
        for ftype_code in sorted(set(ftype_codes), key=lambda k: self.ftype_code_order[k]):
            feature_list = features_by_type[ftype_code]
            derived = feature_list[0]["DERIVED"]
            if derived != "No":
                continue
            ftype_node = eda_node(ftype_code)
            ftype_node.node_desc = self.fmt_how_statistic(ftype_code, len(feature_list))
            category_node.add_child(ftype_node)

            cntr = 0
            for feature in sorted(feature_list, key=lambda k: k["RECORD_COUNT"], reverse=True):
                cntr += 1
                if cntr in (1, 2, len(feature_list), len(feature_list) - 1):
                    lib_feat_id = feature["LIB_FEAT_ID"]
                    feat_desc = feature["FEAT_DESC"]
                    stats = self.fmt_feature_stats(feature)
                    if any(i in stats for i in ["[~", "[!", "[#"]):
                        stats = colorize(stats, "dim")
                    node_desc = f'{colorize(lib_feat_id, "dim")}: {feat_desc} {stats}'
                    feat_node = eda_node(lib_feat_id)
                    feat_node.node_desc = self.fmt_how_statistic(node_desc, feature["RECORD_COUNT"])
                    ftype_node.add_child(feat_node)
                elif cntr == 3 and len(feature_list) > 4:
                    ftype_node.add_child(eda_node("~~~"))

        return summary_node.render_tree()

    def how_tree(self, how_data, **kwargs):
        final_entities = how_data["FINAL_ENTITIES"]
        steps = how_data["STEPS"]
        result_key = {steps[k]["RESULT_ID"]: k for k in steps.keys()}
        root_node = eda_node("root")
        parent_nodes = []
        if len(final_entities) == 1:
            root_node.node_desc = "n/a"
        else:
            root_node.node_desc = colorize("Re-evaluation needed! ", "bad")
        final_node_cnt = 0
        for final_entity in final_entities:
            final_id = final_entity["VIRTUAL_ENTITY_ID"]
            if len(final_entities) == 1:
                final_node_msg = "final entity"
            else:
                final_node_cnt += 1
                final_node_msg = f"final entity {final_node_cnt} of {len(final_entities)}"
            final_node = eda_node(final_id)
            final_node.node_desc = f"{colorize_entity(final_id)} {final_node_msg}"
            final_node.step_created = 0
            root_node.add_child(final_node)
            parent_nodes.append(final_node)

        while parent_nodes:
            current_node = parent_nodes[-1]
            result_id = current_node.node_id
            if result_id not in result_key:
                current_node.node_desc
                parent_nodes.pop()
                continue

            earliest_step = 0
            while True:
                step_num = result_key[result_id]
                if step_num < earliest_step or earliest_step == 0:
                    earliest_step = step_num
                step_data = steps[step_num]
                step_node = eda_node(step_num)
                step_desc = step_data["STEP_TYPE"]
                match_key_desc = self.fmt_match_key(steps[step_num]["MATCH_INFO"], sep=" ")
                result_id_str = colorize_entity(result_id)
                step_node.node_desc = f"Step {step_num}: {step_desc} on {match_key_desc} to create {result_id_str}"
                step_node.node_text = self.how_tree_display(steps[step_num], **kwargs)
                step_node.step_created = step_num
                current_node.add_child(step_node)
                if step_data["STEP_TYPE"] == "Combine virtual entities":
                    # current_node.children = sorted(current_node.children, key=lambda k: k.step_created)
                    parent_nodes.pop()  # done with this parent
                    for virtual_entity in steps[step_num]["ENTITY_LIST"]:
                        interim_id = virtual_entity["VIRTUAL_ID"]
                        interim_node = eda_node(interim_id)
                        interim_node.node_desc = f"{colorize_entity(interim_id)} interim entity"
                        interim_node.step_created = step_num
                        current_node.add_child(interim_node)
                        parent_nodes.append(interim_node)
                    break
                if step_data["STEP_TYPE"] == "Create virtual entity":
                    # current_node.children = sorted(current_node.children, key=lambda k: k.node_desc)
                    parent_nodes.pop()  # end of the line
                    break
                else:  # its an add record to virtual ID
                    result_id = step_data["ENTITY_LIST"][1]["VIRTUAL_ID"]
            current_node.step_created = earliest_step

        if len(final_entities) == 1:
            root_node = root_node.children[0]
        else:
            ordered_nodes = []
            for node in root_node.children:  # sorted(root_node.children, key=lambda k: k.step_created):
                node.node_desc += f" {len(ordered_nodes)+1} of {len(final_entities)}"
                if len(node.children) == 0:
                    node.node_desc += " was orphaned!"
                ordered_nodes.append(node)
            root_node.children = ordered_nodes
        return f"How decision tree for {self.fmt_entity_desc(how_data)}\n\n" + root_node.render_tree()

    def how_columnar(self, how_data, **kwargs):
        entity_id = how_data["ENTITY_ID"]
        entities = {}
        step_data = how_data["STEPS"]
        for step_num in sorted(step_data.keys()):
            for entity in step_data[step_num]["ENTITY_LIST"]:
                if entity["MEMBER_COUNT"] == 1:
                    virtual_id = f'Step {step_num}-{entity["VIRTUAL_ID"]}'
                    entities[virtual_id] = {
                        "ENTITY_ID": virtual_id,
                        "ENTITY_NAME": "foo",
                        "FEATURES": entity["FEATURES"],
                        "RECORDS": entity["RECORDS"],
                        "MATCH_INFO": step_data[step_num]["MATCH_INFO"],
                    }
        # entities, how_data = self.why_how(entity_id)

        kwargs["report_title"] = f"Columnar how for {self.fmt_entity_desc(how_data)}"
        kwargs["row1_title"] = "VIRTUAL_ID"
        if how_data["SUMMARY"]["REEVALUATION_MSG"]:
            kwargs["report_title"] += " " + colorize(how_data["SUMMARY"]["REEVALUATION_MSG"], "bad")

        return self.why_display(entities, **kwargs)

    # special functions

    def how_viewer(self, entity_id, **kwargs):
        how_data = sdk_wrapper.get_how_data(entity_id)
        how_view = kwargs["how_view"]
        while True:
            if how_view == "summary":
                view_report(sdk_wrapper.how_summary(how_data))
            elif how_view == "tree":
                view_report(sdk_wrapper.how_tree(how_data, **kwargs), **kwargs)
            elif how_view == "columnar":
                view_report(sdk_wrapper.how_columnar(how_data, **kwargs), **kwargs)

            response = get_char_with_prompt("\nView (S)ummary, (T)ree, (C)olumnar or <enter> if done...")
            if not response or response.upper().startswith("Q"):
                break
            response = response.upper()
            if response in self.how_views:
                how_view = self.how_views[response]

    def export_records(self, entity_list, **kwargs):
        max_degree = kwargs.get("degree", 0)
        get_flag_list = [
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_ENTITY_INCLUDE_RECORD_JSON_DATA",
        ]
        if max_degree > 0:
            get_flag_list.append("SZ_ENTITY_INCLUDE_ALL_RELATIONS")
        current_degree = 0
        current_entity_list = entity_list
        exported_entity_list = []
        record_list = []
        while current_degree <= max_degree:
            next_entity_list = []
            for entity_id in current_entity_list:
                exported_entity_list.append(entity_id)
                try:
                    json_data = self.call_sdk("get_entity_by_entity_id", get_flag_list, int(entity_id))
                except SzError as err:
                    print_message(err, "error")
                    continue
                record_list.extend([json.dumps(x["JSON_DATA"]) for x in json_data["RESOLVED_ENTITY"]["RECORDS"]])
                if "RELATED_ENTITIES" in json_data:
                    for related_data in json_data["RELATED_ENTITIES"]:
                        related_id = related_data["ENTITY_ID"]
                        if related_id not in exported_entity_list + next_entity_list:
                            next_entity_list.append(related_id)
            current_degree += 1
            if next_entity_list:
                current_entity_list = next_entity_list
            else:
                break
        return record_list


class EdaCmd(cmd.Cmd):

    def __init__(self, args):
        cmd.Cmd.__init__(self)
        self.__hidden_methods = "do_shell", "do_n", "do_p", "do_next", "do_previous"

        # Cmd module settings
        self.intro = "\nType help or ? to list commands.\n"
        self.prompt_str = "szeda"
        self.prompt_color = "info"
        self.prompt = colorize_cmd_prompt(self.prompt_str, self.prompt_color)

        readline.set_completer_delims(" ")
        self.histCheck()

        self.settings_file_name = f"{os.path.expanduser('~')}{os.path.sep}.sz_explorer_settings"
        if os.path.exists(self.settings_file_name):
            self.current_settings = json.load(open(self.settings_file_name))
        else:
            self.current_settings = {}

        self.configurable_settings_list = [
            {
                "setting": "color_scheme",
                "values": ["default", "light", "dark"],
                "description": "light works better on dark backgrounds and vice-versa",
            },
            {
                "setting": "show_relations_on_get",
                "values": ["tree", "grid", "none"],
                "description": "display relationships on get in tree or grid or not at all",
            },
            {
                "setting": "default_how_view",
                "values": ["tree", "summary", "columnar"],
                "description": "dictates which view comes up first",
            },
            {
                "setting": "auto_scroll",
                "values": ["off", "on"],
                "description": "automatically go into scrolling mode if table larger than screen",
            },
        ]
        for setting_data in self.configurable_settings_list:
            self.current_settings[setting_data["setting"]] = self.current_settings.get(
                setting_data["setting"], setting_data["values"][0]
            )
        self.do_set(f"color_scheme {self.current_settings['color_scheme']}")

        self.last_entity_id = 0
        self.last_search_request = []
        self.last_search_result = []

        self.eda_reports = EdaReports(default_how_view=self.current_settings["default_how_view"])
        if args.snapshot_json_file:
            self.current_settings["snapshot_json_file"] = args.snapshot_json_file
        if self.current_settings.get("snapshot_json_file"):
            if os.path.exists(self.current_settings.get("snapshot_json_file")):
                self.do_load(self.current_settings["snapshot_json_file"])
            else:
                self.current_settings["snapshot_json_file"] = None
        if args.snapshot_json_file:
            self.current_settings["audit_json_file"] = args.audit_json_file
        if self.current_settings.get("audit_json_file"):
            if os.path.exists(self.current_settings.get("audit_json_file")):
                self.do_load(self.current_settings["audit_json_file"])
            else:
                self.current_settings["audit_json_file"] = None

    def get_names(self):
        """hides functions from available list of Commands. Separate help sections for some"""
        return [n for n in dir(self.__class__) if n not in self.__hidden_methods]

    def completenames(self, text, *ignored):
        dotext = "do_" + text
        return [a[3:] for a in self.get_names() if a.lower().startswith(dotext.lower())]

    def emptyline(self):
        return

    def colorize(self, in_string, color_list="None"):
        return Colors.apply(in_string, color_list) if color_list else in_string

    def cmdloop(self):
        while True:
            try:
                cmd.Cmd.cmdloop(self)
                break
            except KeyboardInterrupt:
                ans = get_char_with_prompt("\nAre you sure you want to exit? ")
                if ans.upper().startswith("Y"):
                    break
            except TypeError as ex:
                print_message(str(ex), "error")
                _, _, traceback_ = sys.exc_info()
                for item in traceback.format_tb(traceback_):
                    print(item)

    def postloop(self):
        try:
            with open(self.settings_file_name, "w", encoding="utf-8") as f:
                json.dump(self.current_settings, f)
        except:
            pass

    # basic commands

    def do_quit(self, arg):
        # remove_from_history()
        return True

    def do_exit(self, arg):
        self.do_quit(self)
        return True

    def do_clear(self, arg):
        os.system("clear")
        eda_splash()

    def do_help(self, help_topic):
        if not help_topic:
            print(
                textwrap.dedent(
                    f"""\

            {colorize('Adhoc entity commands:', 'highlight2')}
                search {colorize('- search for entities by name and/or other attributes.', 'dim')}
                get {colorize('- get an entity by entity ID or record_id.', 'dim')}
                compare {colorize('- place two or more entities side by side for easier comparison.', 'dim')}
                how {colorize('- get a step by step replay of how an entity came together.', 'dim')}
                why {colorize('- see why entities or records either did or did not resolve.', 'dim')}
                tree {colorize("- see a tree view of an entity's relationships through 1 or 2 degrees.", 'dim')}
                export {colorize("- export the json records for an entity for debugging or correcting and reloading.", 'dim')}

            {colorize('Snapshot reports:', 'highlight2')} {colorize('(requires a json file generated by sz_snapshot)', 'italics')}
                data_source_summary {colorize('– shows how many duplicates were detected within each data source, as well as ', 'dim')}
                {colorize('the possible matches and relationships that were derived. For example, how many duplicate customers ', 'dim')}
                {colorize('there are, and are any of them related to each other.', 'dim')}
                cross_source_summary {colorize('– shows how many matches were made across data sources.  For example, how many ', 'dim')}
                {colorize('employees are related to customers.', 'dim')}
                entity_source_summary {colorize('– shows the number of entities by the set of data sources they can be found in.  For example, ', 'dim')}
                {colorize('how many entities are only in one data source, how many are only in these two data sources, etc.', 'dim')}
                entity_size_breakdown {colorize("– shows how many entities of what size were created.  For instance, some entities ", 'dim')}
                {colorize("are singletons, some might have connected 2 records, some 3, etc.  This report is primarily used to", 'dim')}
                {colorize("ensure there are no instances of over matching.   For instance, it’s ok for an entity to have hundreds", 'dim')}
                {colorize("of records as long as there are not too many different names, addresses, identifiers, etc.", 'dim')}
                principles_used {colorize('– shows what principles and match_keys are firing across all data sources.  For example, ', 'dim')}
                {colorize('how many name and address matches, how many address only, etc.', 'dim')}

            {colorize('Audit report:', 'highlight2')} {colorize('(requires a json file generated by sz_audit)', 'italics')}
                audit_summary {colorize("- shows the precision, recall and F1 scores with the ability to browse the entities that", 'dim')}
                {colorize("were split or merged.", 'dim')}

            {colorize('Other commands:', 'highlight2')}
                quick_look {colorize("- show the number of records in the repository by data source without a snapshot.", 'dim')}
                load {colorize("- load a snapshot or audit report json file.", 'dim')}
                score {colorize("- show the scores of any two names, addresses, identifiers, or combination thereof.", 'dim')}
                set {colorize("- various settings affecting how entities are displayed.", 'dim')}
                show_last_call {colorize("- shows the last request and response message sent to the Senzing SDK", 'dim')}

            {colorize('Senzing Knowledge Center:', 'dim')} {colorize('https://senzing.zendesk.com/hc/en-us', 'highlight2, underline')}
            {colorize('Senzing Support Request:', 'dim')} {colorize('https://senzing.zendesk.com/hc/en-us/requests/new', 'highlight2, underline')}

             """
                )
            )
        else:
            cmd.Cmd.do_help(self, help_topic)

    def help_knowledgeCenter(self):
        print(
            f"\nSenzing Knowledge Center: {colorize('https://senzing.zendesk.com/hc/en-us', 'highlight2, underline')}\n"
        )

    def help_support(self):
        print(
            f"\nSenzing Support Request: {colorize('https://senzing.zendesk.com/hc/en-us/requests/new', 'highlight2, underline')}\n"
        )

    def histCheck(self):

        file_name = f".{MODULE_NAME}_history"
        self.history_file_name = os.path.join(os.path.expanduser("~"), file_name)

        self.hist_disable = args.hist_disable
        self.histFileError = None
        self.histAvail = False

        if not self.hist_disable:

            if readline:

                # Try and open history in users home first for longevity
                try:
                    open(self.history_file_name, "a").close()
                except IOError as e:
                    self.histFileError = f"{e} - Couldn't use home, trying /tmp/..."

                # Can't use users home, try using /tmp/ for history useful at least in the session
                if self.histFileError:

                    self.history_file_name = f"/tmp/{file_name}"
                    try:
                        open(self.history_file_name, "a").close()
                    except IOError as e:
                        self.histFileError = f"{e} - User home dir and /tmp/ failed!"
                        return

                hist_size = 2000
                readline.read_history_file(self.history_file_name)
                readline.set_history_length(hist_size)
                atexit.register(readline.set_history_length, hist_size)
                atexit.register(readline.write_history_file, self.history_file_name)

                self.history_file_name = self.history_file_name
                self.histFileError = None
                self.histAvail = True

    def do_history(self, arg):

        if self.histAvail:
            print()
            for i in range(readline.get_current_history_length()):
                print(readline.get_history_item(i + 1))
            print()
        else:
            print_message("History isn't available in this session", "warning")

    def do_shell(self, line):
        """\nRun OS shell commands: !<command>\n"""
        if line:
            output = os.popen(line).read()
            print(f"\n{output}\n")

    def do_show_last_call(self, arg):
        view_report(sdk_wrapper.export_call_cache())

    def do_version(self, arg):
        print(f"\nSenzing SDK version {sdk_wrapper.sdk_version['BUILD_VERSION']}\n")

    def help_set(self):
        print(
            textwrap.dedent(
                f"""\

        {colorize('Syntax:', 'highlight2')}
            set <setting> <value>

        {colorize('settings:', 'highlight2')}
        """
            )
        )

        print(colorize(f"    {'setting':<23} {'[possible values]':<22} {'current':<13} {'description'}", "dim"))
        for setting_data in self.configurable_settings_list:
            current_value = colorize(self.current_settings[setting_data["setting"]], "bold")
            print(
                f"    {setting_data['setting']:<23} {'[' + ', '.join(setting_data['values']) + ']':<22} {current_value:<22} {colorize(setting_data['description'], 'dim')}"
            )
        print()

    def complete_set(self, text, line, begidx, endidx):
        possibles = []
        spaces = line.count(" ")
        if spaces <= 1:
            possibles = [x["setting"] for x in self.configurable_settings_list]
        elif spaces == 2:
            setting = line.split()[1]
            for setting_data in self.configurable_settings_list:
                if setting_data["setting"] == setting:
                    possibles = setting_data["values"]
        return [i for i in possibles if i.lower().startswith(text.lower())]

    def do_set(self, arg):
        if not arg:
            self.help_set()
            return

        settings_dict = {}
        for setting_data in self.configurable_settings_list:
            settings_dict[setting_data["setting"]] = setting_data["values"]

        if settings_dict:
            arg_list = arg.split()
            if (
                len(arg_list) != 2
                or (arg_list[0] not in settings_dict)
                or (arg_list[1] not in settings_dict[arg_list[0]])
            ):
                print_message("Invalid setting", "error")
                return

        self.current_settings[arg_list[0]] = arg_list[1]
        if arg_list[0] == "color_scheme":
            Colors.set_theme(arg_list[1])
        if arg_list[0] == "default_how_view":
            self.eda_reports.default_how_view = arg_list[1]

    # reports

    def help_load(self):
        print(
            textwrap.dedent(
                f"""\

        {colorize('Syntax:', 'highlight2')}
            load <filename>  {colorize('load a Senzing snapshot or audit json file for review', 'dim')}

        """
            )
        )

    def complete_load(self, text, line, begidx, endidx):
        before_arg = line.rfind(" ", 0, begidx)
        fixed = line[before_arg + 1 : begidx]  # fixed portion of the arg
        arg = line[before_arg + 1 : endidx]
        pattern = arg + "*"
        completions = []
        for path in glob.glob(pattern):
            if os.path.isdir(path) and path[-1] != os.sep:
                path = path + os.sep
            completions.append(path.replace(fixed, "", 1))
        return completions

    def do_load(self, arg):
        try:
            self.eda_reports.load_file(arg)
        except Exception as ex:
            print_message(ex, "error")
        else:
            json_data = json.load(open(arg))
            if json_data.get("SOURCE") == "sz_snapshot":
                self.current_settings["snapshot_json_file"] = arg
            elif json_data.get("SOURCE") == "sz_audit":
                self.current_settings["audit_json_file"] = arg
            print_message(f"Successfully loaded {arg}", "info")

    def help_quick_look(self):
        print("\nDisplays current data source stats without a snapshot\n")

    def do_quick_look(self, arg):
        if not sz_dbo:
            print_message("Direct database access is required, database drivers must be installed", "error")
            return
        tbl = eda_table()
        tbl.title = "Data source counts"
        tbl.columns = [
            {"name": "ID", "width": 5, "align": "center"},
            {"name": "DataSource", "width": 30, "align": "left"},
            {"name": "ActualRecordCount", "width": 20, "align": "right"},
            {"name": "DistinctRecordCount", "width": 20, "align": "right"},
        ]
        sql = (
            "select "
            " DSRC_ID, "
            " count(*) as RECORD_COUNT, "
            " count(distinct ENT_SRC_KEY) as UNIQUE_COUNT "
            "from DSRC_RECORD GROUP BY DSRC_ID"
        )
        tbl.rows = []
        actual_count = distinct_count = 0
        for row in sz_dbo.fetchAllDicts(sz_dbo.sqlExec(sql)):
            tbl.rows.append(
                [
                    colorize(row["DSRC_ID"], "row_title"),
                    colorize_dsrc(sdk_wrapper.dsrc_lookup[row["DSRC_ID"]]["DSRC_CODE"]),
                    "{:,}".format(row["RECORD_COUNT"]),
                    "{:,}".format(row["UNIQUE_COUNT"]),
                ]
            )
            actual_count += row["RECORD_COUNT"]
            distinct_count += row["UNIQUE_COUNT"]
        if len(tbl.rows) > 1:
            tbl.rows.append(
                [
                    "",
                    colorize("  Totals", "row_title"),
                    colorize("{:,}".format(actual_count), "row_title"),
                    colorize("{:,}".format(distinct_count), "row_title"),
                ]
            )
        view_report(tbl.render_table())

    def help_audit_summary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays audit statistics and examples.

        {colorize('Syntax:', 'highlight2')}
            audit_summary
        """
            )
        )

    def do_audit_summary(self, arg):
        try:
            self.eda_reports.audit_summary()
        except Exception as ex:
            print_exception(ex)

    def help_entity_size_breakdown(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the number of entities by how many records they contain.

        {colorize('Syntax:', 'highlight2')}
            entity_size_breakdown

        {colorize('review items:', 'highlight2')}
            Review items are suggestions of records to look at because they contain multiple names, addresses, dobs, etc.
            They may be overmatches or they may just be large entities with lots of values.

        """
            )
        )

    def do_entity_size_breakdown(self, arg):
        try:
            self.eda_reports.entity_size_breakdown()
        except Exception as ex:
            print_exception(ex)

    def complete_data_source_summary(self, text, line, begidx, endidx):
        possibles = sorted(self.eda_reports.snapshot_data.get("DATA_SOURCES", {}).keys())
        if text:
            return [i for i in possibles if i.startswith(text.upper())]
        return possibles

    def help_data_source_summary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the resolution statistics for each data source.

        {colorize('Syntax:', 'highlight2')}
            data_source_summary [dataSource]
            """
            )
        )

    def do_data_source_summary(self, arg):
        try:
            self.eda_reports.data_source_summary(arg)
        except Exception as ex:
            print_exception(ex)

    def help_cross_source_summary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the resolution statistics across data sources.

        {colorize('Syntax:', 'highlight2')}
            cross_source_summary [dataSource]
        """
            )
        )

    def complete_cross_source_summary(self, text, line, begidx, endidx):
        possibles = sorted(self.eda_reports.snapshot_data.get("DATA_SOURCES", {}).keys())
        if text:
            return [i for i in possibles if i.startswith(text.upper())]
        return possibles

    def do_cross_source_summary(self, arg):
        try:
            self.eda_reports.cross_source_summary(arg)
        except Exception as ex:
            print_exception(ex)

    def help_entity_source_summary(self):
        print(
            textwrap.dedent(
                f"""\

        Displays the number of entities resolved into data source groups.  For instance, the number of entities in
        dataSource1, the number of entities in dataSource2 and the number of entities in both.
        
        While similar to the cross_source_summary, it can also show entities in 3 or more data sources.  However, it
        can only show the matches, not the possible matches and relationships.

        {colorize('Syntax:', 'highlight2')}
            entity_source_summary [dataSource]
        """
            )
        )

    def complete_entity_source_summary(self, text, line, begidx, endidx):
        possibles = sorted(self.eda_reports.snapshot_data.get("DATA_SOURCES", {}).keys())
        if text:
            return [i for i in possibles if i.startswith(text.upper())]
        return possibles

    def do_entity_source_summary(self, arg):
        try:
            self.eda_reports.entity_source_summary(arg)
        except Exception as ex:
            print_exception(ex)

    def help_principles_used(self):
        print(
            textwrap.dedent(
                f"""\

        Displays which principles are firing and allows you to see examples.

        {colorize('Syntax:', 'highlight2')}
            principles_used

        """
            )
        )

    def do_principles_used(self, arg: str) -> None:
        try:
            self.eda_reports.principles_used_report()
        except Exception as ex:
            print_exception(ex)

    # adhoc commands

    def kwargs_from_arg(self, arg_str, kwarg_dict):
        prior_token = None
        remaining_tokens = []
        feature_list = []
        for token in arg_str.split():
            if token.upper() == "LEGACY":
                kwarg_dict["legacy"] = True
            elif token.upper() == "ALL":
                kwarg_dict["record_limit"] = 0
                kwarg_dict["attr_limit"] = 0
            elif token.upper() == "DETAIL":
                kwarg_dict["show_detail"] = True
            elif token.upper().startswith("FEATURE"):
                kwarg_dict["features_only"] = True
            elif token.upper() == "SEARCH":
                kwarg_dict["search"] = 0
            elif token.isdigit() and prior_token == "SEARCH":
                kwarg_dict["search"] = int(token)
            elif token.upper() in sdk_wrapper.ftype_code_lookup:
                feature_list.append(token)
            elif token.lower() in sdk_wrapper.how_views.values():
                kwarg_dict["how_view"] = token.lower()
            else:
                remaining_tokens.append(token)
            prior_token = token.upper()
        if feature_list:
            kwarg_dict["feature_list"] = feature_list
        if "search" in kwarg_dict:
            if not self.last_search_request:
                raise Exception("There is no prior search")
            elif (
                kwarg_dict["search"] != 0
                and kwarg_dict["search"] > len(self.last_search_result)
                and kwarg_dict.get("called_by", "") != "why"
            ):
                raise Exception("Invalid search index")

        arg_str = " ".join(remaining_tokens)
        return arg_str, kwarg_dict

    def help_feature_search(self):
        print(
            textwrap.dedent(
                f"""\

        finds entities by feature description or id

        {colorize('Syntax:', 'highlight2')}
            featureSearch id = 123
            featureSearch address = 123 first str
            featureSearch name like anderson

        {colorize('Warning:', 'bad')}
            featureSearch is intended to be used during smallish POCs to help find entities by feature ID or description when they are not returned by search.
            featureSearch can take a long time and return a lot of entities!

        """
            )
        )

    def do_feature_search(self, arg):
        if not arg:
            self.help_feature_search()
            return
        if not sz_dbo:
            print_message("Direct database access required", "error")
            return

        arg = arg.replace("=", " = ")
        ftype = operator = value = ""
        for token in arg.split():
            if not ftype:
                ftype = token.upper()
            elif not operator:
                operator = token.upper()
            else:
                value += token + " "
        value = value.strip()

        if not ftype or not operator or not value:
            print_message("Invalid syntax", "error")
            return

        if operator not in ("=", "LIKE"):
            print_message('Operator can only be "=" or "like"', "error")
            return

        feat_select = "select LIB_FEAT_ID, FTYPE_ID, FEAT_DESC from LIB_FEAT "
        stat_select = "select NUM_RES_ENT, NUM_RES_ENT_OOM, CANDIDATE_CAP_REACHED, SCORING_CAP_REACHED FROM RES_FEAT_STAT WHERE LIB_FEAT_ID = "

        if ftype == "ID":
            feat_select += f"where LIB_FEAT_ID = {value}"
        elif ftype in sdk_wrapper.ftype_code_lookup:
            ftype_id = sdk_wrapper.ftype_code_lookup[ftype]["FTYPE_ID"]
            if operator == "LIKE":
                if sz_dbo_uri.startswith("postgres"):
                    operator = "ILIKE"  # makes case insensitive
                elif sz_dbo_uri.startswith("sqlite"):
                    sz_dbo.sqlExec("PRAGMA case_sensitive_like=OFF")
                if "%" not in value:
                    value = "%" + value + "%"
            feat_select += f"where FTYPE_ID = {ftype_id} and FEAT_DESC {operator} '{value}'"
        else:
            print_message(f"{ftype} is not a feature", "error")
            return

        # print(feat_select)

        tbl = eda_table()
        tbl.columns = [
            {"name": "\nID", "width": 5, "align": "center"},
            {"name": "\nFeature", "width": 25, "align": "center"},
            {"name": "\nDescription", "width": 75, "align": "left"},
            {"name": "Estimated\nCount", "width": 10, "align": "center"},
            {"name": "Generic\nCandidate", "width": 20, "align": "center"},
            {"name": "Generic\nScoring", "width": 20, "align": "center"},
        ]
        tbl.rows = []
        feat_cache = {}
        feat_count = 0
        for row in sz_dbo.fetchAllRows(sz_dbo.sqlExec(feat_select)):
            feat_count += 1
            feat_id = row[0]
            ftype = sdk_wrapper.ftype_lookup[row[1]]["FTYPE_CODE"]
            feat_desc = row[2]
            feat_cache[feat_id] = feat_desc

            stat_row = sz_dbo.fetchRow(sz_dbo.sqlExec(stat_select + f" {feat_id}"))
            if not stat_row:
                stat_row = [0, 0, "U", "U"]

            tbl.rows.append(
                [
                    colorize(feat_id, "row_title"),
                    colorize_attr(ftype),
                    feat_desc,
                    f"{stat_row[0] * stat_row[1]:,}",
                    "Yes" if stat_row[2] == "Y" else "No",
                    "Yes" if stat_row[3] == "Y" else "No",
                ]
            )

        if feat_count == 0:
            print_message("No features Found!", "error")
            return

        tbl.title = f"{feat_count:,} Features found"
        report = tbl.render_table(super_header=True)

        tbl1 = eda_table()
        tbl1.columns = [
            {"name": "Index", "width": 5, "align": "center"},
            {"name": "Entity ID", "width": 15, "align": "center"},
            {"name": "Entity Name", "width": 75, "align": "left"},
            {"name": "Data Sources", "width": 50, "align": "left"},
            {"name": "Feature", "width": 25, "align": "left"},
            {"name": "Description", "width": 75, "align": "left"},
        ]
        get_flag_list = ["SZ_ENTITY_INCLUDE_ENTITY_NAME", "SZ_ENTITY_INCLUDE_RECORD_DATA"]
        entity_cnt = 0
        entity_cache = {}
        tbl1.rows = []
        for lib_feat_id, feat_desc in feat_cache.items():
            sql = f"select distinct RES_ENT_ID from RES_FEAT_EKEY where LIB_FEAT_ID = {lib_feat_id} order by RES_ENT_ID"
            for row in sz_dbo.fetchAllRows(sz_dbo.sqlExec(sql)):
                entity_id = row[0]
                if entity_id in entity_cache:
                    continue
                entity_cache[entity_id] = True
                entity_cnt += 1
                if entity_cnt <= 1000:
                    try:
                        json_data = sdk_wrapper.call_sdk("get_entity_by_entity_id", get_flag_list, entity_id)
                    except SzError as err:
                        print_message(err, "error")
                        continue
                    entity_name = json_data["RESOLVED_ENTITY"]["ENTITY_NAME"]
                    tbl1.rows.append(
                        [
                            colorize(entity_cnt, "row_title"),
                            colorize_entity(entity_id),
                            entity_name,
                            sdk_wrapper.fmt_record_list(json_data["RESOLVED_ENTITY"]["RECORDS"]),
                            colorize_attr(ftype),
                            feat_desc,
                        ]
                    )
        tbl1.title = f"{entity_cnt:,} Entities found"
        report += "\n" + tbl1.render_table()
        view_report(report)

    def help_search(self):
        print(
            textwrap.dedent(
                f"""\

        Search for an entity by its attributes.

        {colorize('Examples:', 'highlight2')}
            search universal exports
            search robert smith
            search robert smith | date_of_birth: 3/31/1954

        {colorize('Notes:', 'highlight2')}
            Searching by name alone may not locate a specific entity.  Try adding a date of birth, address, or phone 
            number if your record is not found by name alone.

            You can either use a valid Senzing json structure or a pipe delimited string of recognized attributes as 
            shown above.  The value before the first pipe is assumed to be name and use a colon to separate the 
            attribute name from its value.
            
        """
            )
        )

    def do_search(self, arg):
        if not arg:
            self.help_search()
            return
        try:
            if arg.startswith("{"):
                parm_data = dict_keys_upper(json.loads(arg))
            else:
                parm_data = {"FEATURES": []}
                for search_str in arg.split("|"):
                    if ":" in search_str:
                        str_split = [x.strip() for x in search_str.split(":")]
                        parm_data["FEATURES"].append({str_split[0].upper(): str_split[1]})
                    elif "=" in search_str:
                        str_split = [x.strip() for x in search_str.split("=")]
                        parm_data["FEATURES"].append({str_split[0].upper(): str_split[1]})
                    else:
                        parm_data["FEATURES"].append({"ASFULL_NAME_FULL": search_str})
                        parm_data["FEATURES"].append({"ASORG_NAME_ORG": search_str})
        except (ValueError, KeyError) as err:
            print_message(f"Invalid json parameter: {err}", "error")
            return

        print("\nSearching...")
        search_json = parm_data
        search_flag_list = [
            "SZ_SEARCH_INCLUDE_ALL_ENTITIES",
            "SZ_INCLUDE_FEATURE_SCORES",
            "SZ_ENTITY_INCLUDE_ENTITY_NAME",
            "SZ_ENTITY_INCLUDE_RECORD_DATA",
            "SZ_INCLUDE_MATCH_KEY_DETAILS",
            "SZ_SEARCH_INCLUDE_STATS",
            "SZ_ENTITY_INCLUDE_ALL_RELATIONS",
            "SZ_ENTITY_INCLUDE_RELATED_MATCHING_INFO",
        ]
        sdk_wrapper.begin_call_cache(inspect.stack()[0].function)
        try:
            json_data = sdk_wrapper.call_sdk("search_by_attributes", search_flag_list, json.dumps(search_json))
        except SzError as err:
            print_message(err, "error")
            return
        self.last_search_request = search_json
        tbl = eda_table()
        tbl.title = "Search Results"
        tbl.columns = [
            {"name": "Index", "width": 5, "align": "center"},
            {"name": "Entity ID", "width": 15, "align": "center"},
            {"name": "Entity Name", "width": 75, "align": "left"},
            {"name": "Data Sources", "width": 75, "align": "left"},
            {"name": "Match Key", "width": 75, "align": "left"},
            {"name": "Match Score", "width": 15, "align": "center"},
            {"name": "Relationships", "width": 15, "align": "left"},
        ]
        tbl.rows = []
        search_index = 0
        self.last_search_result = []
        matched_list = sdk_wrapper.reorder_search_results(json_data["RESOLVED_ENTITIES"])
        for matched_entity in matched_list:
            search_index += 1
            entity_data = matched_entity["ENTITY"]["RESOLVED_ENTITY"]
            relationships = matched_entity["ENTITY"]["RELATED_ENTITIES"]
            disclosed_count = len([x for x in relationships if x["IS_DISCLOSED"] > 0])
            derived_count = len(relationships) - disclosed_count
            rel_str = f"{derived_count} {colorize('derived', 'dim')}" if derived_count else ""
            rel_str += f"{disclosed_count} {colorize('disclosed', 'dim')}" if disclosed_count else ""
            tbl.rows.append(
                [
                    colorize(search_index, "dim"),
                    colorize_entity(entity_data["ENTITY_ID"]),
                    entity_data["ENTITY_NAME"],
                    sdk_wrapper.fmt_record_list(entity_data["RECORDS"]),
                    sdk_wrapper.fmt_match_key(matched_entity["MATCH_INFO"]),
                    matched_entity["MATCH_SCORE"],
                    rel_str,
                ]
            )
            self.last_search_result.append(str(entity_data["ENTITY_ID"]))

        if len(matched_list) > 0:
            tbl.title = f"{len(matched_list)} entities found..."
            view_report(tbl.render_table())
            return

        if json_data.get("SEARCH_STATISTICS"):
            candidate_stats = json_data["SEARCH_STATISTICS"][0]["CANDIDATE_KEYS"]["SUMMARY"]
            if candidate_stats["FOUND"] > 0:
                msg = (
                    "One or more entities were found but did not score high enough to be returned..."
                    "\nPlease include additional or more complete attributes in your search"
                )
            elif candidate_stats["GENERIC"] > 0:
                msg = (
                    "Too many entities would be returned..."
                    "\nPlease include additional attributes to narrow the search results"
                )
            elif candidate_stats["NOT_FOUND"] > 0:
                msg = (
                    "No entities at all were found..."
                    "\nPlease search by other attributes for this entity if you feel it should exist"
                )
            else:
                msg = "No search keys were even generated..." "\nPlease search by other attributes"
        else:  # older versions do not have statistics
            msg = (
                "No matches found or there were simply too many to return..."
                "\nPlease include additional search parameters if you feel this entity is in the database"
            )
        print(colorize(f"{LFTAB}{LFTAB.join(msg.split(LF))}{LF}", "caution"))

    def help_get_features(self):
        print(
            textwrap.dedent(
                f"""\

        Displays how a particular entity's features were parsed.

        {colorize('Syntax:', 'highlight2')}
            get_features <entity_id>
            get_features <entity_id> ADDRESS

        {colorize('Notes:', 'highlight2')}
            {colorize('Add a feature type code after the entity_id to filter for only those features', 'dim')}
        """
            )
        )

    def do_get_features(self, arg):
        if not arg:
            self.help_get_features()
            return
        self.do_get("features " + arg)

    def help_get(self):
        print(
            textwrap.dedent(
                f"""\

        Displays a particular entity by entity_id or by data_source and record_id.

        {colorize('Syntax:', 'highlight2')}
            get <entity_id>               {colorize("looks up an entity's resume by entity ID", 'dim')}
            get <dataSource> <recordID>   {colorize("looks up an entity's resume by data source and record ID", 'dim')}
            get search <search index>     {colorize("looks up an entity's resume by search index (requires a prior search)", 'dim')}

        {colorize('Notes:', 'highlight2')}
            {colorize('Add the keyword ', 'dim')}DETAIL{colorize(' to display each record in the entity separately.', 'dim')}
            {colorize('Add the keyword ', 'dim')}FEATURES{colorize(' to display how its features were parsed.', 'dim')}
            {colorize('Add the keyword ', 'dim')}ALL{colorize(' to display all the attributes of the entity if they are getting cut off.', 'dim')}
        """
            )
        )

    def do_get(self, arg, **kwargs):
        """get an entity resume"""
        if not arg:
            self.help_get()
            return
        kwargs["show_relations_on_get"] = self.current_settings["show_relations_on_get"]
        kwargs["show_detail"] = False

        try:
            arg, kwargs = self.kwargs_from_arg(arg, kwargs)
        except Exception as ex:
            print_message(ex, "error")
            return

        if "search" in kwargs:
            if kwargs["search"] == 0:
                arg = str(self.last_search_result[0])
            else:
                arg = str(self.last_search_result[kwargs["search"] - 1])

        arg_tokens = arg.split()
        if len(arg_tokens) not in (1, 2):
            print_message("Incorrect number of parameters", "warning")
            return
        if len(arg_tokens) == 1 and not arg_tokens[0].isnumeric():
            print_message("Entity ID must be numeric", "error")
            return
        sdk_wrapper.begin_call_cache(inspect.stack()[0].function)
        try:
            if kwargs.get("features_only"):
                report = sdk_wrapper.get_features(arg_tokens, **kwargs)
            else:
                report = sdk_wrapper.get_entity(arg_tokens, **kwargs)
        except SzError as err:
            print_message(err, "error")
            return
        except Exception as ex:
            print_exception(ex)
            return
        view_report(report)
        if len(arg_tokens) == 1:  # supports previous/next
            self.last_entity_id = int(arg_tokens[0])

    def find(self, operator, arg):
        starting_id = self.last_entity_id
        # data_source = None  # to support find a record in a data source
        arg_list = arg.split()
        for parm in arg_list:
            if parm.isdigit():
                starting_id = int(parm)
            # else:
            #    data_source = parm.upper()

        sql = f"select RES_ENT_ID from RES_ENT_OKEY where RES_ENT_ID {operator} ?"
        next_row = sz_dbo.fetchRow(sz_dbo.sqlExec(sz_dbo.sqlPrep(sql), starting_id))
        if not next_row:
            print_message("no more entities", "warning")
        else:
            self.do_get(str(next_row[0]))

    def do_next(self, arg):
        self.find(">", arg)

    def do_n(self, arg):
        remove_from_history()
        self.do_next(arg)

    def do_previous(self, arg):
        self.find("<", arg)

    def do_p(self, arg):
        remove_from_history()
        self.do_previous(arg)

    def help_compare(self):
        print(
            textwrap.dedent(
                f"""\

        Compares a set of entities by placing them side by side in a columnar format.

        {colorize('Syntax:', 'highlight2')}
            compare <entity_id1> <entity_id2>   {colorize('compares the listed entities', 'dim')}
            compare search                      {colorize('places all the search results side by side', 'dim')}
            compare search <top (n)>            {colorize('places the top (n) search results side by side', 'dim')}

        {colorize('Notes:', 'highlight2')}
            Comparing a single entity will compare that entity with all its relationships!

                """
            )
        )

    def do_compare(self, arg, **kwargs):
        """show entities side by side"""
        if not arg:
            self.help_compare()
            return
        try:
            arg, kwargs = self.kwargs_from_arg(arg, kwargs)
        except Exception as ex:
            print_message(ex, "error")
            return
        if "search" in kwargs:
            if kwargs["search"] == 0:
                entity_list = [str(x) for x in self.last_search_result]
            else:
                entity_list = [str(self.last_search_result[kwargs["search"] - 1])]
        elif "," in arg:
            entity_list = arg.split(",")
        else:
            entity_list = arg.split()
        try:
            sdk_wrapper.begin_call_cache(inspect.stack()[0].function)
            if len(entity_list) == 1:
                view_report(sdk_wrapper.compare_relationships(entity_list[0], **kwargs))
            else:
                view_report(sdk_wrapper.compare_entities(entity_list, **kwargs))
        except Exception as err:
            print_message(err, "error")

    def help_tree(self):
        print(
            textwrap.dedent(
                f"""\

        Displays an entity tree from a particular entity's point of view.

        {colorize('Syntax:', 'highlight2')}
            tree <entity_id>                  {colorize('displays the first degree relationships of an entity', 'dim')}
            tree <entity_id> degree <n>       {colorize('displays relationships of an entity out to <n> degrees', 'dim')}
            tree <entity_id> degree <n> all   {colorize('adding the "all" tag disables the default limit of 10 per category', 'dim')}
        """
            )
        )

    def do_tree(self, arg, **kwargs):
        """display entity relationships in a tree"""
        if not arg:
            self.help_tree()
            return

        root_entity_id = None
        kwargs["build_out_degree"] = 1
        kwargs["max_children"] = 25
        arg_list = arg.split()
        if arg_list[-1].upper() == "ALL":
            kwargs["max_children"] = 10000
            arg_list.pop(-1)
        if len(arg_list) in (1, 3):
            if arg_list[0].isdigit():
                root_entity_id = int(arg_list[0])
            if len(arg_list) == 3 and arg_list[1].upper() == "DEGREE" and arg_list[2].isdigit():
                kwargs["build_out_degree"] = int(arg_list[2])
        if not root_entity_id:
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return

        try:
            sdk_wrapper.begin_call_cache(inspect.stack()[0].function)
            view_report(sdk_wrapper.get_relationship_tree(root_entity_id, **kwargs))
        except SzError as err:
            print_message(err, "error")
            return
        except Exception as ex:
            print_exception(ex)
            return

    def help_why(self):
        print(
            textwrap.dedent(
                f"""\

        Shows the internal values and scores used to determine why a set of records resolved or only related.

        {colorize('Syntax:', 'highlight2')}
            why <entity_id1>                                            {colorize('actually runs a columnar how instead!', 'dim')}
            why <entity_id1> <entity_id2>                               {colorize('shows why two or more different entities did not resolve', 'dim')}
            why <data_source1> <record_id1> <data_source2> <record_id2> {colorize('shows if the two data source records could resolve or relate', 'dim')}
            why search [optional entity_id]                             {colorize('shows the features and keys generated by a search against any candidate entities', 'dim')}
            
        {colorize('Color legend:', 'highlight2')}
            {colorize('green', 'good')} indicates the values matched and contributed to the overall score
            {colorize('red', 'bad')} indicates the values did not match and hurt the overall score
            {colorize('yellow', 'caution')} indicates the values did not match but did not hurt the overall score
            {colorize('cyan', 'highlight2')} indicates the values only helped get the record on the candidate list
            {colorize('dimmed', 'dim')} values were ignored (see the bracket legend below)

        {colorize('Bracket legend:', 'highlight2')}
            [99] indicates how many entities share this value
            [~] indicates that this value was not used to find candidates as too many entities share it
            [!] indicates that this value was not not even scored as too many entities share it
            [#] indicates that this value was suppressed in favor of a more complete value\n
        """
            )
        )

    def do_why(self, arg, **kwargs):
        if not arg:
            self.help_why()
            return
        try:
            kwargs["called_by"] = "why"
            arg, kwargs = self.kwargs_from_arg(arg, kwargs)
        except Exception as ex:
            print_message(ex, "error")
            return
        if "," in arg:
            entity_list = arg.split(",")
        else:
            entity_list = arg.split()
        if not all(x.isnumeric() for x in entity_list) and not entity_list[0].upper() in sdk_wrapper.dsrc_code_lookup:
            print_message("invalid parameters, see help", "error")
            return
        sdk_wrapper.begin_call_cache(inspect.stack()[0].function)
        try:
            if "search" in kwargs:
                view_report(sdk_wrapper.why_search(self.last_search_request, **kwargs))
            elif len(entity_list) == 1:
                if "how_view" not in kwargs:
                    kwargs["how_view"] = self.current_settings["default_how_view"]
                self.do_how(entity_list[0], **kwargs)
            elif len(entity_list) == 2 and not kwargs.get("legacy"):
                view_report(sdk_wrapper.why_not(entity_list, **kwargs))
            elif len(entity_list) == 4 and entity_list[0].upper() in sdk_wrapper.dsrc_code_lookup:
                view_report(sdk_wrapper.why_records(entity_list, **kwargs))
            else:
                view_report(sdk_wrapper.why_not_many(entity_list, **kwargs))
        except SzError as err:
            print_message(err, "error")
            return

    def help_how(self):
        entity_id = colorize_entity("<entity_id>")
        print(
            textwrap.dedent(
                f"""\

            Shows shows how the records in a single entity came together.

            {colorize('Syntax:', 'highlight2')}
                how {entity_id}            {colorize('shows the default view (can be changed via set command)', 'dim')}
                how {entity_id} summary    {colorize('shows the summary view', 'dim')}
                how {entity_id} tree       {colorize('shows the decision tree view', 'dim')}
                how {entity_id} columnar   {colorize('shows the columnar view', 'dim')}

                """
            )
        )

    def do_how(self, arg, **kwargs):
        if not arg:
            self.help_how()
            return
        try:
            arg, kwargs = self.kwargs_from_arg(arg, kwargs)
        except Exception as ex:
            print_message(ex, "error")
            return
        if "how_view" not in kwargs:
            kwargs["how_view"] = self.current_settings["default_how_view"]
        if "search" in kwargs:
            if kwargs["search"] == 0:
                arg = str(self.last_search_result[0])
            else:
                arg = str(self.last_search_result[kwargs["search"] - 1])
        elif not arg.isdigit():
            print_message("Invalid parameter: expected a numeric entity ID", "warning")
            return

        sdk_wrapper.begin_call_cache(inspect.stack()[0].function)
        try:
            sdk_wrapper.how_viewer(int(arg), **kwargs)
        except SzError as err:
            print_message(err, "error")
        except Exception as ex:
            print_exception(ex)
            return

    def help_score(self):
        print(
            textwrap.dedent(
                f"""\

        Compares any two features and shows the scores returned.

        {colorize('Syntax:', 'highlight2')}
            score [{'{'}"name_last": "Smith", "name_first": "Joseph"{'}'}, {'{'}"name_last": "Smith", "name_first": "Joe"{'}'}]
            score [{'{'}"addr_full": "111 First St, Anytown, USA"{'}'}, {'{'}"addr_full": "111 First Street, Anytown"{'}'}]
            score [{'{'}"passport_number": "1231234", "passport_country": "US"{'}'}, {'{'}"passport_number": "1231234", "passport_country": "USA"{'}'}]

        {colorize('Notes:', 'highlight2')}
            Use the keyword "force" to force the two records to find each other by adding a trusted_id.
        """
            )
        )

    def do_score(self, arg):
        if not arg:
            self.help_score()
            return

        force_trusted_id = "FORCE" in [x.upper() for x in arg.split()]
        if force_trusted_id:
            arg = " ".join([x for x in arg.split() if x.upper() != "FORCE"])

        try:
            json_data = json.loads(arg)
        except (ValueError, KeyError) as err:
            print_message(f"Invalid json parameter: {err}", "error")
            return

        if not isinstance(json_data, list) or len(json_data) != 2:
            print_message("json parameter must be a list of two features to compare", "error")
            return

        record1json = dict_keys_upper(json_data[0])
        record2json = dict_keys_upper(json_data[1])

        # use the test data source and entity type
        record1json["RECORD_TYPE"] = "SCORE_TEST"
        record2json["RECORD_TYPE"] = "SCORE_TEST"

        if force_trusted_id:
            record1json["TRUSTED_ID_TYPE"] = "SCORE"
            record1json["TRUSTED_ID_NUMBER"] = "TEST"
            record2json["TRUSTED_ID_TYPE"] = "SCORE"
            record2json["TRUSTED_ID_NUMBER"] = "TEST"

        # add the records
        try:
            sdk_wrapper.sz_engine.add_record("TEST", "SCORE_RECORD_1", json.dumps(record1json))
            sdk_wrapper.sz_engine.add_record("TEST", "SCORE_RECORD_2", json.dumps(record2json))
        except SzError as err:
            print_message(err, "error")
            return

        self.do_why("TEST SCORE_RECORD_1 TEST SCORE_RECORD_2")

        # delete the two temporary records
        try:
            sdk_wrapper.sz_engine.delete_record("TEST", "SCORE_RECORD_1")
            sdk_wrapper.sz_engine.delete_record("TEST", "SCORE_RECORD_2")
        except SzError as err:
            print_message(err, "error")
            return

        return

    def help_export(self):
        print(
            textwrap.dedent(
                f"""\

        Exports the json records that make up the selected entities for debugging, reloading, etc.

        {colorize('Syntax:', 'highlight2')}
            export <entity_id>, <entity_id> degree <n> to <fileName> additive
            export search to <fileName>
            export search <search index> to <fileName>\n
        """
            )
        )

    def do_export(self, arg):
        if not arg:
            self.help_export()
            return
        entity_list = []
        degree = 0
        file_name = None
        additive = False
        token_list = arg.replace(",", " ").split()
        ignore_token = False
        for i, token in enumerate(token_list):
            if ignore_token:
                ignore_token = False
                continue
            next_token = token_list[i + 1] if i + 1 < len(token_list) else None
            if token.isdigit():
                entity_list.append(token)
            elif token.lower() == "degree" and next_token:
                if next_token.isdigit() and int(next_token) <= 3:
                    degree = int(next_token)
                    ignore_token = True
                else:
                    print_message("Degrees must be 3 or less", "error")
                    return
            elif token.lower() == "search":
                if not self.last_search_result:
                    print_message("No prior search result", "error")
                    return
                if next_token and next_token.isdigit():
                    entity_list.extend(self.last_search_result[0 : int(next_token)])
                    ignore_token = True
                else:
                    entity_list.extend(self.last_search_result)

            elif token.lower() == "additive":
                additive = True
            elif token.lower() == "to" and next_token:
                file_name = next_token
                ignore_token = True
        if len(entity_list) == 0:
            print_message("No entities specified", "warning")
            return
        if not file_name:
            file_name = f"{entity_list[0]}.jsonl" if len(entity_list) == 1 else "records.jsonl"

        json_lines = sdk_wrapper.export_records(entity_list, degree=degree)
        if json_lines:
            with open(file_name, "a" if additive else "w", encoding="utf-8") as f:
                f.write("\n".join(json_lines) + "\n")
            print_message(f"{len(json_lines)} records written to {file_name}", "info")


def dict_keys_upper(dict):
    return {k.upper(): v for k, v in dict.items()}


def remove_from_history(idx=0):
    if readline:
        if not idx:
            idx = readline.get_current_history_length() - 1
        readline.remove_history_item(idx)


def debug_print(_value, _desc="some variable"):
    print("-" * 20)
    print(_desc)
    if type(_value) in (list, dict):
        print(json.dumps(_value, indent=4))
    else:
        print(_value)
    get_char_with_prompt("press any key...")


def eda_splash():
    splash = Colors.apply("\n  ____|  __ \\     \\    \n", "DIM")
    splash += Colors.apply("  __|    |   |   _ \\   ", "DIM") + "Senzing\n"
    splash += Colors.apply("  |      |   |  ___ \\  ", "DIM") + "Exploratory Data Analysis\n"
    splash += Colors.apply(" _____| ____/ _/    _\\ \n", "DIM")
    print(splash)


if __name__ == "__main__":
    appPath = os.path.dirname(os.path.abspath(sys.argv[0]))

    # capture the command line arguments
    argParser = argparse.ArgumentParser()
    argParser.add_argument(
        "-c",
        "--config_file_name",
        help="Path and name of optional G2Module.ini file to use.",
    )
    argParser.add_argument(
        "-s",
        "--snapshot_json_file",
        help="the name of a json statistics file computed by sz_snapshot",
    )
    argParser.add_argument(
        "-a",
        "--audit_json_file",
        help="the name of a json statistics file computed by sz_audit",
    )
    argParser.add_argument(
        "-w",
        "--webapp_url",
        help="the url to the Senzing webapp if available",
    )
    argParser.add_argument(
        "-H",
        "--hist_disable",
        action="store_true",
        default=False,
        help="disable history file usage",
    )
    argParser.add_argument(
        "-t",
        "--debug_trace",
        action="store_true",
        default=False,
        help="output debug trace information",
    )
    args = argParser.parse_args()

    if args.snapshot_json_file and not os.path.exists(args.snapshot_json_file):
        print_message("Snapshot json file not found", "error")
        sys.exit(1)

    if args.audit_json_file and not os.path.exists(args.audit_json_file):
        print_message("Audit json file not found", "error")
        sys.exit(1)

    eda_splash()

    engine_config = get_engine_config(args.config_file_name)
    try:
        sdk_wrapper = EdaSdkWrapper(engine_config, debug_trace=args.debug_trace, webapp_url=args.webapp_url)
    except SzError as ex:
        print_message(ex, "error")
        sys.exit(1)

    try:
        sz_dbo_uri = json.loads(engine_config)["SQL"]["CONNECTION"]
        sz_dbo = SzDatabase(sz_dbo_uri)
    except Exception as err:
        print_message(err, "warning")
        sz_dbo = None

    EdaCmd(args).cmdloop()

    sys.exit()
